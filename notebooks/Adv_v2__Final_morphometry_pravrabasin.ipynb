{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYOxoQsIM8D3F+DWgXHnQc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"GkNPduQUJfJb"}},{"cell_type":"code","source":["import os\n","import zipfile\n","import glob\n","\n","# â”€â”€ USER INPUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","# â”‚  UPDATED for 3 Pour-Point Pravra Basin run                             â”‚\n","# â”‚  Zip file:  \"Morphomtery_layers-Final.zip\"                             â”‚\n","# â”‚  Subbasins: Pravrabasin.shp  (5 polygons â€” use as-is, or replace with â”‚\n","# â”‚             a 3-polygon shapefile named pravra3.shp when available)     â”‚\n","# â”‚  Pour pts:  Pourpoints_3.shp  (3 points â€” confirmed in zip)           â”‚\n","# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","ZIP_PATH    = \"/content/Morphomtery layers-Final.zip\"   # â† Updated zip name\n","EXTRACT_DIR = \"/content/watershed_data/\"\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","def extract_zip(zip_path, extract_dir):\n","    \"\"\"Extract zip file and list contents.\"\"\"\n","    os.makedirs(extract_dir, exist_ok=True)\n","    if not os.path.exists(zip_path):\n","        raise FileNotFoundError(\n","            f\"ZIP not found at {zip_path}. \"\n","            \"Please upload your zip file to Colab first.\"\n","        )\n","    with zipfile.ZipFile(zip_path, 'r') as z:\n","        z.extractall(extract_dir)\n","        names = z.namelist()\n","    print(f\"âœ… Extracted {len(names)} files to {extract_dir}\")\n","    return names\n","\n","\n","def discover_files(extract_dir):\n","    \"\"\"\n","    Auto-detect required GIS layers from extracted directory.\n","    Returns a dict of file paths.\n","    \"\"\"\n","    files = {}\n","\n","    # Walk all subdirectories\n","    all_files = []\n","    for root, dirs, fnames in os.walk(extract_dir):\n","        for f in fnames:\n","            all_files.append(os.path.join(root, f))\n","\n","    print(\"\\nğŸ“‚ All extracted files:\")\n","    for f in all_files:\n","        print(f\"   {f}\")\n","\n","    # â”€â”€ RASTERS (.tif / .img / .asc) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    rasters = [f for f in all_files if f.lower().endswith(('.tif', '.tiff', '.img', '.asc'))]\n","\n","    # Keyword-based auto-detection (case-insensitive)\n","    for r in rasters:\n","        base = os.path.basename(r).lower()\n","        if any(k in base for k in ['dem', 'srtm', 'elevation', 'filled', 'fill']):\n","            files['dem'] = r\n","        elif any(k in base for k in ['flowdir', 'flow_dir', 'fdir', 'direction']):\n","            files['flow_dir'] = r\n","        elif any(k in base for k in ['flowacc', 'flow_acc', 'facc', 'accumulation']):\n","            files['flow_acc'] = r\n","        elif any(k in base for k in ['strahler', 'streamorder', 'stream_order', 'order']):\n","            files['stream_order_raster'] = r\n","        elif any(k in base for k in ['slope']):\n","            files['slope'] = r\n","        elif any(k in base for k in ['aspect']):\n","            files['aspect'] = r\n","\n","    # â”€â”€ VECTORS (.shp) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    shapefiles = [f for f in all_files if f.lower().endswith('.shp')]\n","\n","    for s in shapefiles:\n","        base = os.path.basename(s).lower()\n","        if any(k in base for k in ['subbasin', 'sub_basin', 'watershed', 'basin', 'catchment', 'pravra']):\n","            files['Subbasins'] = s\n","        elif any(k in base for k in ['stream', 'river', 'channel', 'network', 'drainage', 'steam']):\n","            if 'order' in base or 'steam' in base:\n","                files['stream_order_shp'] = s\n","                files['streams'] = s   # SteamOrder.shp doubles as streams\n","            else:\n","                files['streams'] = s\n","        elif any(k in base for k in ['pour', 'outlet', 'point']):\n","            files['pour_points'] = s\n","        elif any(k in base for k in ['order']):\n","            files['stream_order_shp'] = s\n","\n","    # â”€â”€ FALLBACK: if stream_order_shp not found, use streams â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    if 'stream_order_shp' not in files and 'streams' in files:\n","        files['stream_order_shp'] = files['streams']\n","\n","    print(\"\\nğŸ—ºï¸  Auto-detected layers:\")\n","    for key, val in files.items():\n","        print(f\"   {key:25s} â†’ {val}\")\n","\n","    missing = []\n","    required = ['dem', 'Subbasins', 'streams', 'flow_dir', 'flow_acc'] # Changed 'subbasins' to 'Subbasins'\n","    for req in required:\n","        if req not in files:\n","            missing.append(req)\n","\n","    if missing:\n","        print(f\"\\nâš ï¸  Could not auto-detect: {missing}\")\n","        print(\"   Please set paths manually in SECTION 2 â€” DATA PATHS.\")\n","    else:\n","        print(\"\\nâœ… All required layers detected.\")\n","\n","    return files\n","\n","\n","# â”€â”€ RUN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","if __name__ == \"__main__\":\n","    extract_zip(ZIP_PATH, EXTRACT_DIR)\n","    DETECTED_FILES = discover_files(EXTRACT_DIR)\n","\n","    # Print for copy-paste into Section 2\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"ğŸ“‹ Copy these paths into SECTION 2 â€” DATA PATHS:\")\n","    print(\"=\"*60)\n","    for k, v in DETECTED_FILES.items():\n","        print(f'  \"{k}\": r\"{v}\",')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJci7JJzJJyT","executionInfo":{"status":"ok","timestamp":1771995527646,"user_tz":-330,"elapsed":160,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"61385aa6-1e37-4fe2-f096-41a127820329"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Extracted 63 files to /content/watershed_data/\n","\n","ğŸ“‚ All extracted files:\n","   /content/watershed_data/StreamOrder.tif\n","   /content/watershed_data/Flowthreshould.tif.vat.cpg\n","   /content/watershed_data/SteamOrder.prj\n","   /content/watershed_data/StreamOrder.tif.aux.xml\n","   /content/watershed_data/Filled DEM.tif.aux.xml\n","   /content/watershed_data/Pourpoints_3.shp\n","   /content/watershed_data/pravra3.shp\n","   /content/watershed_data/SteamOrder.cpg\n","   /content/watershed_data/pravra3.shx\n","   /content/watershed_data/Pravrabasin.dbf\n","   /content/watershed_data/StreamOrder.tif.vat.cpg\n","   /content/watershed_data/Filled DEM.tfw\n","   /content/watershed_data/streams.dbf\n","   /content/watershed_data/Flowthreshould.tif.ovr\n","   /content/watershed_data/Pravrabasin.shp\n","   /content/watershed_data/pravra3.cpg\n","   /content/watershed_data/StreamOrder.tif.vat.dbf\n","   /content/watershed_data/FlowAccumilation.tfw\n","   /content/watershed_data/streams.sbn\n","   /content/watershed_data/Flowthreshould.tif.aux.xml\n","   /content/watershed_data/SteamOrder.shx\n","   /content/watershed_data/Flow Direction.tif\n","   /content/watershed_data/Flow Direction.tif.ovr\n","   /content/watershed_data/Pourpoints_3.shx\n","   /content/watershed_data/Pourpoints_3.prj\n","   /content/watershed_data/pravra3.dbf\n","   /content/watershed_data/Flow Direction.tif.aux.xml\n","   /content/watershed_data/StreamOrder.tfw\n","   /content/watershed_data/Pourpoints_3.dbf\n","   /content/watershed_data/Pravrabasin.shx\n","   /content/watershed_data/streams.shp\n","   /content/watershed_data/streams.cpg\n","   /content/watershed_data/pravra3.sbn\n","   /content/watershed_data/pravra3.sbx\n","   /content/watershed_data/streams.shp.xml\n","   /content/watershed_data/SteamOrder.shp\n","   /content/watershed_data/FlowAccumilation.tif.ovr\n","   /content/watershed_data/FlowAccumilation.tif\n","   /content/watershed_data/streams.sbx\n","   /content/watershed_data/SteamOrder.shp.xml\n","   /content/watershed_data/Pourpoints_3.cpg\n","   /content/watershed_data/Filled DEM.tif.ovr\n","   /content/watershed_data/SteamOrder.sbx\n","   /content/watershed_data/Flowthreshould.tif\n","   /content/watershed_data/streams.prj\n","   /content/watershed_data/StreamOrder.tif.ovr\n","   /content/watershed_data/Flow Direction.tfw\n","   /content/watershed_data/Flow Direction.tif.vat.cpg\n","   /content/watershed_data/FlowAccumilation.tif.aux.xml\n","   /content/watershed_data/Pravrabasin.shp.xml\n","   /content/watershed_data/Pourpoints_3.sbn\n","   /content/watershed_data/Pravrabasin.sbx\n","   /content/watershed_data/Pravrabasin.sbn\n","   /content/watershed_data/Flowthreshould.tfw\n","   /content/watershed_data/Pravrabasin.prj\n","   /content/watershed_data/pravra3.prj\n","   /content/watershed_data/Flowthreshould.tif.vat.dbf\n","   /content/watershed_data/SteamOrder.sbn\n","   /content/watershed_data/Pourpoints_3.sbx\n","   /content/watershed_data/SteamOrder.dbf\n","   /content/watershed_data/Flow Direction.tif.vat.dbf\n","   /content/watershed_data/Filled DEM.tif\n","   /content/watershed_data/Pravrabasin.cpg\n","\n","ğŸ—ºï¸  Auto-detected layers:\n","   stream_order_raster       â†’ /content/watershed_data/StreamOrder.tif\n","   flow_dir                  â†’ /content/watershed_data/Flow Direction.tif\n","   flow_acc                  â†’ /content/watershed_data/FlowAccumilation.tif\n","   dem                       â†’ /content/watershed_data/Filled DEM.tif\n","   pour_points               â†’ /content/watershed_data/Pourpoints_3.shp\n","   Subbasins                 â†’ /content/watershed_data/Pravrabasin.shp\n","   streams                   â†’ /content/watershed_data/SteamOrder.shp\n","   stream_order_shp          â†’ /content/watershed_data/SteamOrder.shp\n","\n","âœ… All required layers detected.\n","\n","============================================================\n","ğŸ“‹ Copy these paths into SECTION 2 â€” DATA PATHS:\n","============================================================\n","  \"stream_order_raster\": r\"/content/watershed_data/StreamOrder.tif\",\n","  \"flow_dir\": r\"/content/watershed_data/Flow Direction.tif\",\n","  \"flow_acc\": r\"/content/watershed_data/FlowAccumilation.tif\",\n","  \"dem\": r\"/content/watershed_data/Filled DEM.tif\",\n","  \"pour_points\": r\"/content/watershed_data/Pourpoints_3.shp\",\n","  \"Subbasins\": r\"/content/watershed_data/Pravrabasin.shp\",\n","  \"streams\": r\"/content/watershed_data/SteamOrder.shp\",\n","  \"stream_order_shp\": r\"/content/watershed_data/SteamOrder.shp\",\n"]}]},{"cell_type":"markdown","source":["=============================================================================\n","SECTION 1 â€” ENVIRONMENT SETUP & LIBRARY IMPORTS\n","=============================================================================\n","Run in Google Colab. Installs missing packages and imports all libraries.\n","============================================================================="],"metadata":{"id":"NddZ7blMJLLw"}},{"cell_type":"code","source":["import subprocess, sys\n","\n","def pip_install(*pkgs):\n","    \"\"\"Silent pip install with error catching.\"\"\"\n","    for pkg in pkgs:\n","        try:\n","            subprocess.check_call(\n","                [sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"],\n","                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n","            )\n","            print(f\"  âœ… {pkg}\")\n","        except Exception as e:\n","            print(f\"  âš ï¸  {pkg} â€” install failed ({e}), will try to continue\")\n","\n","print(\"ğŸ“¦ Installing packages...\")\n","pip_install(\n","    \"geopandas\",\n","    \"rasterio\",\n","    \"rasterstats\",\n","    \"shapely\",\n","    \"fiona\",\n","    \"pyproj\",\n","    \"richdem\",\n","    \"numpy\",\n","    \"pandas\",\n","    \"scipy\",\n","    \"scikit-learn\",\n","    \"statsmodels\",\n","    \"seaborn\",\n","    \"plotly\",\n","    \"matplotlib\",\n","    \"mapclassify\",\n","    \"contextily\",\n","    \"joypy\",\n","    \"xarray\",\n","    \"rioxarray\",\n","    \"earthpy\",\n","    \"tqdm\",\n","    \"openpyxl\",\n",")\n","\n","print(\"\\nğŸ“š Importing libraries...\")\n","\n","# â”€â”€ STANDARD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","import os\n","import warnings\n","import traceback\n","import zipfile\n","import json\n","from pathlib import Path\n","from tqdm import tqdm\n","\n","warnings.filterwarnings('ignore')\n","\n","# â”€â”€ GEOSPATIAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","import geopandas as gpd\n","import rasterio\n","from rasterio.transform import rowcol, xy\n","from rasterio.warp import calculate_default_transform, reproject, Resampling\n","from rasterio.mask import mask as rio_mask\n","from rasterio.features import geometry_mask\n","import rasterio.plot\n","import fiona\n","from shapely.geometry import (Point, LineString, MultiLineString,\n","                               Polygon, MultiPolygon, box)\n","from shapely.ops import unary_union, linemerge\n","from pyproj import CRS, Transformer\n","from rasterstats import zonal_stats\n","\n","# â”€â”€ RICHDEM (optional, graceful fallback) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","try:\n","    import richdem as rd\n","    RICHDEM_OK = True\n","    print(\"  âœ… richdem available\")\n","except ImportError:\n","    RICHDEM_OK = False\n","    print(\"  âš ï¸  richdem not available â€” slope/aspect computed via numpy\")\n","\n","# â”€â”€ NUMERICAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","import numpy as np\n","import pandas as pd\n","from scipy import stats\n","from scipy.spatial.distance import cdist\n","from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n","\n","# â”€â”€ SKLEARN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","\n","# â”€â”€ STATSMODELS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","import statsmodels.api as sm\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","\n","# â”€â”€ VISUALIZATION â€” MATPLOTLIB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import matplotlib.ticker as mticker\n","import matplotlib.colors as mcolors\n","from matplotlib.colors import LightSource, LinearSegmentedColormap, Normalize\n","from matplotlib.patches import FancyArrowPatch, FancyBboxPatch\n","import matplotlib.patheffects as pe\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","import seaborn as sns\n","\n","# â”€â”€ VISUALIZATION â€” PLOTLY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","# â”€â”€ OPTIONAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","try:\n","    import joypy\n","    JOYPY_OK = True\n","except ImportError:\n","    JOYPY_OK = False\n","    print(\"  âš ï¸  joypy not available â€” ridge plots skipped\")\n","\n","try:\n","    import earthpy.spatial as es\n","    EARTHPY_OK = True\n","except ImportError:\n","    EARTHPY_OK = False\n","\n","try:\n","    import xarray as xr\n","    import rioxarray\n","    RIOXARRAY_OK = True\n","except ImportError:\n","    RIOXARRAY_OK = False\n","\n","# â”€â”€ GLOBAL SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","pd.set_option('display.max_columns', 30)\n","pd.set_option('display.width', 200)\n","pd.set_option('display.float_format', '{:.4f}'.format)\n","plt.rcParams.update({\n","    'figure.dpi': 150,\n","    'font.family': 'DejaVu Sans',\n","    'axes.labelsize': 11,\n","    'axes.titlesize': 13,\n","    'legend.fontsize': 10,\n","})\n","\n","# â”€â”€ OUTPUT DIRECTORIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","OUT_DIR      = \"/content/morphometric_outputs/\"\n","MAPS_DIR     = os.path.join(OUT_DIR, \"maps/\")\n","PLOTS_DIR    = os.path.join(OUT_DIR, \"plots/\")\n","TABLES_DIR   = os.path.join(OUT_DIR, \"tables/\")\n","SHAPES_DIR   = os.path.join(OUT_DIR, \"shapefiles/\")\n","REPORT_DIR   = os.path.join(OUT_DIR, \"report/\")\n","\n","for d in [OUT_DIR, MAPS_DIR, PLOTS_DIR, TABLES_DIR, SHAPES_DIR, REPORT_DIR]:\n","    os.makedirs(d, exist_ok=True)\n","\n","print(\"\\nâœ… All libraries imported successfully.\")\n","print(f\"ğŸ“ Output directory: {OUT_DIR}\")\n","\n","# â”€â”€ VERSION REPORT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(f\"\\n{'='*50}\")\n","print(f\"  geopandas  : {gpd.__version__}\")\n","print(f\"  rasterio   : {rasterio.__version__}\")\n","print(f\"  numpy      : {np.__version__}\")\n","print(f\"  pandas     : {pd.__version__}\")\n","print(f\"  plotly     : {__import__('plotly').__version__}\")\n","print(f\"{'='*50}\")\n","\n","import subprocess, sys"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XW2Oij2gLQ_j","executionInfo":{"status":"ok","timestamp":1771995852837,"user_tz":-330,"elapsed":118462,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"d48c32df-4529-4b19-dda5-9229fd90089e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“¦ Installing packages...\n","  âœ… geopandas\n","  âœ… rasterio\n","  âœ… rasterstats\n","  âœ… shapely\n","  âœ… fiona\n","  âœ… pyproj\n","  âš ï¸  richdem â€” install failed (Command '['/usr/bin/python3', '-m', 'pip', 'install', 'richdem', '-q']' returned non-zero exit status 1.), will try to continue\n","  âœ… numpy\n","  âœ… pandas\n","  âœ… scipy\n","  âœ… scikit-learn\n","  âœ… statsmodels\n","  âœ… seaborn\n","  âœ… plotly\n","  âœ… matplotlib\n","  âœ… mapclassify\n","  âœ… contextily\n","  âœ… joypy\n","  âœ… xarray\n","  âœ… rioxarray\n","  âœ… earthpy\n","  âœ… tqdm\n","  âœ… openpyxl\n","\n","ğŸ“š Importing libraries...\n","  âš ï¸  richdem not available â€” slope/aspect computed via numpy\n","\n","âœ… All libraries imported successfully.\n","ğŸ“ Output directory: /content/morphometric_outputs/\n","\n","==================================================\n","  geopandas  : 1.1.2\n","  rasterio   : 1.5.0\n","  numpy      : 2.0.2\n","  pandas     : 2.2.2\n","  plotly     : 5.24.1\n","==================================================\n"]}]},{"cell_type":"code","source":["# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n","# â”‚  SECTION 2 â€” DATA PATHS (Updated for 3-Pour-Point Pravra Basin Run)        â”‚\n","# â”‚                                                                             â”‚\n","# â”‚  Subbasins : Pravrabasin.shp  â† contains 5 polygons as confirmed by DBF   â”‚\n","# â”‚              If you have a 3-polygon delineation, replace path with:       â”‚\n","# â”‚              r\"/content/watershed_data/pravra3.shp\"                        â”‚\n","# â”‚  Pour Pts  : Pourpoints_3.shp â† 3 points confirmed âœ…                     â”‚\n","# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","\n","# â”€â”€ â–¼â–¼â–¼  EDIT THESE PATHS  â–¼â–¼â–¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","DATA_PATHS = {\n","    \"dem\"              : r\"/content/watershed_data/Filled DEM.tif\",\n","    # â”€â”€ SUBBASINS: Using Pravrabasin.shp (5 polygons found in zip).\n","    #    Replace path below with pravra3.shp once you have the 3-polygon version.\n","    \"subbasins\"        : r\"/content/watershed_data/Subbasins.shp\",\n","    # â”€â”€ STREAMS: SteamOrder.shp is the polyline stream-order layer\n","    \"streams\"          : r\"/content/watershed_data/SteamOrder.shp\",\n","    \"stream_order_shp\" : r\"/content/watershed_data/SteamOrder.shp\",\n","    \"flow_dir\"         : r\"/content/watershed_data/Flow Direction.tif\",\n","    \"flow_acc\"         : r\"/content/watershed_data/FlowAccumilation.tif\",\n","    # â”€â”€ POUR POINTS: Updated from old Pourpoints-Pravrabasin.shp â†’ Pourpoints_3.shp\n","    \"pour_points\"      : r\"/content/watershed_data/Pourpoints_3.shp\",\n","}\n","# â”€â”€ â–²â–²â–²  EDIT ABOVE  â–²â–²â–² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","# N_SUBBASINS is now set dynamically from the actual shapefile (see load step below).\n","# Override here ONLY if you want a strict assertion check:\n","#   N_SUBBASINS = 3    â† set to 3 when pravra3.shp (3-polygon file) is ready\n","#   N_SUBBASINS = 5    â† current Pravrabasin.shp has 5 polygons\n","N_SUBBASINS = None   # None = auto-detect from shapefile (recommended)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  HELPER FUNCTIONS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","def detect_utm_epsg(lon, lat):\n","    \"\"\"Return appropriate UTM EPSG code for a given lon/lat.\"\"\"\n","    zone = int((lon + 180) / 6) + 1\n","    if lat >= 0:\n","        return f\"EPSG:326{zone:02d}\"\n","    else:\n","        return f\"EPSG:327{zone:02d}\"\n","\n","\n","def get_raster_info(path):\n","    \"\"\"Return dict of raster metadata.\"\"\"\n","    with rasterio.open(path) as src:\n","        return {\n","            \"crs\"        : src.crs,\n","            \"res\"        : src.res,\n","            \"nodata\"     : src.nodata,\n","            \"shape\"      : (src.height, src.width),\n","            \"bounds\"     : src.bounds,\n","            \"dtype\"      : src.dtypes[0],\n","            \"count\"      : src.count,\n","            \"transform\"  : src.transform,\n","        }\n","\n","\n","def reproject_raster(src_path, dst_path, target_crs):\n","    \"\"\"Reproject a raster to target CRS and save.\"\"\"\n","    with rasterio.open(src_path) as src:\n","        transform, width, height = calculate_default_transform(\n","            src.crs, target_crs, src.width, src.height, *src.bounds\n","        )\n","        kwargs = src.meta.copy()\n","        kwargs.update({\n","            'crs'       : target_crs,\n","            'transform' : transform,\n","            'width'     : width,\n","            'height'    : height,\n","        })\n","        with rasterio.open(dst_path, 'w', **kwargs) as dst:\n","            for i in range(1, src.count + 1):\n","                reproject(\n","                    source=rasterio.band(src, i),\n","                    destination=rasterio.band(dst, i),\n","                    src_transform=src.transform,\n","                    src_crs=src.crs,\n","                    dst_transform=transform,\n","                    dst_crs=target_crs,\n","                    resampling=Resampling.bilinear,\n","                )\n","    return dst_path\n","\n","\n","def fix_geometries(gdf, layer_name=\"layer\"):\n","    \"\"\"Fix invalid geometries and remove nulls.\"\"\"\n","    before = len(gdf)\n","    gdf = gdf[~gdf.geometry.is_empty & gdf.geometry.notna()].copy()\n","    gdf['geometry'] = gdf['geometry'].apply(\n","        lambda g: g.buffer(0) if not g.is_valid else g\n","    )\n","    gdf = gdf[gdf.geometry.is_valid].copy()\n","    print(f\"  {layer_name}: {before} â†’ {len(gdf)} features (after geometry fix)\")\n","    return gdf.reset_index(drop=True)\n","\n","\n","def explode_multipart(gdf, layer_name=\"layer\"):\n","    \"\"\"Explode multipart geometries to single-part.\"\"\"\n","    before = len(gdf)\n","    gdf = gdf.explode(index_parts=False).reset_index(drop=True)\n","    if len(gdf) != before:\n","        print(f\"  {layer_name}: Exploded multipart â†’ {len(gdf)} parts\")\n","    return gdf\n","\n","\n","def snap_pour_points(pour_pts_gdf, flow_acc_path, snap_distance_m=300):\n","    \"\"\"\n","    Snap pour points to the highest flow accumulation cell\n","    within snap_distance_m (in metres, projected CRS assumed).\n","    Returns GeoDataFrame with snapped geometries.\n","    \"\"\"\n","    with rasterio.open(flow_acc_path) as src:\n","        fa_data  = src.read(1).astype(float)\n","        nodata   = src.nodata if src.nodata is not None else -9999\n","        fa_data[fa_data == nodata] = np.nan\n","        transform = src.transform\n","        res        = src.res[0]  # metres per pixel\n","\n","    snap_cells = int(snap_distance_m / res)\n","    snapped_pts = []\n","\n","    for idx, row in pour_pts_gdf.iterrows():\n","        px_c, px_r = ~transform * (row.geometry.x, row.geometry.y)\n","        px_c, px_r = int(px_c), int(px_r)\n","\n","        r0 = max(0, px_r - snap_cells)\n","        r1 = min(fa_data.shape[0], px_r + snap_cells + 1)\n","        c0 = max(0, px_c - snap_cells)\n","        c1 = min(fa_data.shape[1], px_c + snap_cells + 1)\n","\n","        window = fa_data[r0:r1, c0:c1]\n","        if np.all(np.isnan(window)):\n","            snapped_pts.append(row.geometry)\n","            continue\n","\n","        local_max = np.nanargmax(window)\n","        local_r, local_c = np.unravel_index(local_max, window.shape)\n","        global_r = r0 + local_r\n","        global_c = c0 + local_c\n","\n","        snap_x, snap_y = xy(transform, global_r, global_c)\n","        snapped_pts.append(Point(snap_x, snap_y))\n","\n","    result = pour_pts_gdf.copy()\n","    result['geometry']       = snapped_pts\n","    result['snap_distance_m'] = [\n","        row.geometry.distance(snapped_pts[i])\n","        for i, (_, row) in enumerate(pour_pts_gdf.iterrows())\n","    ]\n","    return result\n","\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  LOAD & VALIDATE\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"=\" * 60)\n","print(\"SECTION 2 â€” DATA LOADING & PREPROCESSING\")\n","print(\"=\" * 60)\n","\n","# â”€â”€ 1. Load DEM info first to determine UTM zone â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\n[1/6] Reading DEM metadata...\")\n","assert os.path.exists(DATA_PATHS['dem']), f\"DEM not found: {DATA_PATHS['dem']}\"\n","dem_info = get_raster_info(DATA_PATHS['dem'])\n","print(f\"  CRS      : {dem_info['crs']}\")\n","print(f\"  Res      : {dem_info['res']} m\")\n","print(f\"  Shape    : {dem_info['shape']}\")\n","print(f\"  Bounds   : {dem_info['bounds']}\")\n","print(f\"  No-data  : {dem_info['nodata']}\")\n","\n","# Determine if geographic or projected\n","src_crs = CRS.from_user_input(dem_info['crs'])\n","if src_crs.is_geographic:\n","    # Compute centroid lon/lat for UTM zone\n","    b = dem_info['bounds']\n","    cen_lon = (b.left + b.right) / 2\n","    cen_lat = (b.bottom + b.top) / 2\n","    UTM_EPSG = detect_utm_epsg(cen_lon, cen_lat)\n","    print(f\"  DEM is geographic â†’ will reproject to {UTM_EPSG}\")\n","    NEEDS_REPROJECT = True\n","else:\n","    UTM_EPSG = str(dem_info['crs'])\n","    print(f\"  DEM is already projected: {UTM_EPSG}\")\n","    NEEDS_REPROJECT = False\n","\n","TARGET_CRS = CRS.from_epsg(int(UTM_EPSG.split(\":\")[1]))\n","\n","# â”€â”€ 2. Reproject rasters if needed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\n[2/6] Reprojecting rasters...\")\n","RASTER_KEYS = ['dem', 'flow_dir', 'flow_acc']\n","RASTERS = {}\n","\n","for key in RASTER_KEYS:\n","    src_path = DATA_PATHS[key]\n","    assert os.path.exists(src_path), f\"Missing: {src_path}\"\n","    info = get_raster_info(src_path)\n","    if NEEDS_REPROJECT and CRS.from_user_input(info['crs']).is_geographic:\n","        dst_path = os.path.join(OUT_DIR, f\"{key}_utm.tif\")\n","        reproject_raster(src_path, dst_path, TARGET_CRS)\n","        RASTERS[key] = dst_path\n","        print(f\"  âœ… Reprojected {key}\")\n","    else:\n","        RASTERS[key] = src_path\n","        print(f\"  âœ… {key} OK (already projected)\")\n","\n","# Optional stream order raster\n","if os.path.exists(DATA_PATHS.get('stream_order_raster', '')):\n","    so_path = DATA_PATHS['stream_order_raster']\n","    so_info = get_raster_info(so_path)\n","    if NEEDS_REPROJECT and CRS.from_user_input(so_info['crs']).is_geographic:\n","        dst = os.path.join(OUT_DIR, \"stream_order_utm.tif\")\n","        reproject_raster(so_path, dst, TARGET_CRS)\n","        RASTERS['stream_order_raster'] = dst\n","    else:\n","        RASTERS['stream_order_raster'] = so_path\n","\n","# â”€â”€ 3. Load & validate vector layers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\n[3/6] Loading vector layers...\")\n","\n","# Subbasins\n","gdf_sub = gpd.read_file(DATA_PATHS['subbasins'])\n","gdf_sub = fix_geometries(gdf_sub, \"subbasins\")\n","gdf_sub = gdf_sub.to_crs(UTM_EPSG)\n","\n","# â”€â”€ Dynamic N_SUBBASINS: auto-detect from the loaded shapefile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","if N_SUBBASINS is None:\n","    N_SUBBASINS = len(gdf_sub)\n","    print(f\"  â„¹ï¸  N_SUBBASINS auto-detected: {N_SUBBASINS} polygons in {DATA_PATHS['subbasins']}\")\n","else:\n","    if len(gdf_sub) != N_SUBBASINS:\n","        print(f\"  âš ï¸  Warning: Expected {N_SUBBASINS} subbasins but shapefile has {len(gdf_sub)}.\")\n","        print(f\"       Using actual count: {len(gdf_sub)}\")\n","        print(f\"       â†’ If you want exactly 3 subbasins, replace subbasins path with pravra3.shp\")\n","        N_SUBBASINS = len(gdf_sub)\n","    else:\n","        print(f\"  âœ… Subbasin count verified: {N_SUBBASINS}\")\n","\n","print(f\"  âœ… Subbasins: {len(gdf_sub)} | CRS: {gdf_sub.crs}\")\n","\n","# Ensure unique basin ID â€” try to detect from existing columns\n","if 'basin_id' not in gdf_sub.columns:\n","    # Try to use 'name' column if present (Pravrabasin.shp has 'name' field)\n","    if 'name' in gdf_sub.columns and gdf_sub['name'].notna().all():\n","        # Extract subbasin name from the 'AreaSqkm' column which has \"Subbasin-X\"\n","        # Try AreaSqkm field first (Pravrabasin.shp stores subbasin names there)\n","        if 'AreaSqkm' in gdf_sub.columns:\n","            names = gdf_sub['AreaSqkm'].astype(str).str.extract(r'(Subbasin-\\d+)')[0]\n","            if names.notna().sum() == len(gdf_sub):\n","                gdf_sub['basin_id'] = names\n","            else:\n","                gdf_sub['basin_id'] = [f\"SB{i+1}\" for i in range(len(gdf_sub))]\n","        else:\n","            gdf_sub['basin_id'] = [f\"SB{i+1}\" for i in range(len(gdf_sub))]\n","    else:\n","        gdf_sub['basin_id'] = [f\"SB{i+1}\" for i in range(len(gdf_sub))]\n","print(f\"  Basin IDs: {gdf_sub['basin_id'].tolist()}\")\n","\n","# Streams\n","gdf_streams = gpd.read_file(DATA_PATHS['streams'])\n","gdf_streams = fix_geometries(gdf_streams, \"streams\")\n","gdf_streams = explode_multipart(gdf_streams, \"streams\")\n","gdf_streams = gdf_streams.to_crs(UTM_EPSG)\n","print(f\"  âœ… Streams: {len(gdf_streams)} segments | CRS: {gdf_streams.crs}\")\n","\n","# Stream order shapefile\n","gdf_so = gpd.read_file(DATA_PATHS['stream_order_shp'])\n","gdf_so = fix_geometries(gdf_so, \"stream_order\")\n","gdf_so = explode_multipart(gdf_so, \"stream_order\")\n","gdf_so = gdf_so.to_crs(UTM_EPSG)\n","\n","# Detect stream order column\n","ORDER_COL = 'grid_code'  # SteamOrder.shp uses 'grid_code' for Strahler order (confirmed in DBF)\n","\n","if ORDER_COL is None:\n","    raise ValueError(\n","        f\"Cannot detect stream order column. Columns: {gdf_so.columns.tolist()}\\n\"\n","        \"Please set ORDER_COL manually below.\"\n","    )\n","print(f\"  âœ… Stream order col detected: '{ORDER_COL}' \"\n","      f\"| Orders: {sorted(gdf_so[ORDER_COL].unique())}\")\n","\n","gdf_so[ORDER_COL] = gdf_so[ORDER_COL].astype(int)\n","MAX_ORDER = int(gdf_so[ORDER_COL].max())\n","\n","# Pour points (optional but important for snapping)\n","POUR_POINTS_OK = False\n","if os.path.exists(DATA_PATHS.get('pour_points', '')):\n","    gdf_pp = gpd.read_file(DATA_PATHS['pour_points'])\n","    gdf_pp = gdf_pp.to_crs(UTM_EPSG)\n","    print(f\"  âœ… Pour points: {len(gdf_pp)}\")\n","    print(\"  Snapping pour points to max flow accumulation...\")\n","    gdf_pp = snap_pour_points(gdf_pp, RASTERS['flow_acc'], snap_distance_m=300)\n","    print(f\"  Snap distances (m): {gdf_pp['snap_distance_m'].round(1).tolist()}\")\n","    gdf_pp.to_file(os.path.join(SHAPES_DIR, \"pour_points_snapped.shp\"))\n","    POUR_POINTS_OK = True\n","else:\n","    gdf_pp = None\n","    print(\"  âš ï¸  Pour points file not found â€” skipping snap\")\n","\n","# â”€â”€ 4. Validate DEM resolution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(f\"\\n[4/6] Validating DEM resolution...\")\n","dem_info_utm = get_raster_info(RASTERS['dem'])\n","res_x, res_y = dem_info_utm['res']\n","if 20 <= res_x <= 35:\n","    print(f\"  âœ… DEM resolution: {res_x:.1f} x {res_y:.1f} m â‰ˆ 30 m SRTM âœ“\")\n","else:\n","    print(f\"  âš ï¸  DEM resolution: {res_x:.1f} x {res_y:.1f} m (not standard 30 m â€” continuing anyway)\")\n","\n","# â”€â”€ 5. Read raster arrays into memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\n[5/6] Reading raster arrays...\")\n","\n","with rasterio.open(RASTERS['dem']) as src:\n","    DEM_ARR       = src.read(1).astype(np.float32)\n","    DEM_NODATA    = src.nodata if src.nodata is not None else -9999.0\n","    DEM_TRANSFORM = src.transform\n","    DEM_CRS       = src.crs\n","    DEM_BOUNDS    = src.bounds\n","    DEM_RES       = src.res[0]\n","    DEM_ARR[DEM_ARR == DEM_NODATA] = np.nan\n","\n","with rasterio.open(RASTERS['flow_dir']) as src:\n","    FDIR_ARR    = src.read(1).astype(np.float32)\n","    FDIR_NODATA = src.nodata if src.nodata is not None else -9999.0\n","    FDIR_ARR[FDIR_ARR == FDIR_NODATA] = np.nan\n","\n","with rasterio.open(RASTERS['flow_acc']) as src:\n","    FACC_ARR    = src.read(1).astype(np.float32)\n","    FACC_NODATA = src.nodata if src.nodata is not None else -9999.0\n","    FACC_ARR[FACC_ARR == FACC_NODATA] = np.nan\n","\n","print(f\"  DEM  shape: {DEM_ARR.shape} | min={np.nanmin(DEM_ARR):.1f} max={np.nanmax(DEM_ARR):.1f} m\")\n","print(f\"  FDIR shape: {FDIR_ARR.shape}\")\n","print(f\"  FACC shape: {FACC_ARR.shape}\")\n","\n","# â”€â”€ 6. Compute slope & aspect if not provided â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\n[6/6] Computing slope and aspect...\")\n","\n","def compute_slope_aspect_numpy(dem, res_m):\n","    \"\"\"Compute slope (degrees) and aspect (degrees) using numpy gradient.\"\"\"\n","    # Smooth first to reduce noise\n","    from scipy.ndimage import uniform_filter\n","    dem_sm = np.where(np.isnan(dem), 0, dem)\n","    dz_dy, dz_dx = np.gradient(dem_sm, res_m, res_m)\n","    slope_rad = np.arctan(np.sqrt(dz_dx**2 + dz_dy**2))\n","    slope_deg = np.degrees(slope_rad)\n","    aspect_deg = np.degrees(np.arctan2(-dz_dx, dz_dy)) % 360\n","    slope_deg[np.isnan(dem)] = np.nan\n","    aspect_deg[np.isnan(dem)] = np.nan\n","    return slope_deg.astype(np.float32), aspect_deg.astype(np.float32)\n","\n","\n","if RICHDEM_OK:\n","    try:\n","        rda = rd.rdarray(np.where(np.isnan(DEM_ARR), -9999, DEM_ARR), no_data=-9999)\n","        rda.projection = DEM_CRS.to_wkt()\n","        rda.geotransform = (DEM_TRANSFORM.c, DEM_TRANSFORM.a, 0,\n","                            DEM_TRANSFORM.f, 0, DEM_TRANSFORM.e)\n","        SLOPE_ARR  = np.array(rd.TerrainAttribute(rda, attrib='slope_degrees')).astype(np.float32)\n","        ASPECT_ARR = np.array(rd.TerrainAttribute(rda, attrib='aspect')).astype(np.float32)\n","        SLOPE_ARR[np.isnan(DEM_ARR)]  = np.nan\n","        ASPECT_ARR[np.isnan(DEM_ARR)] = np.nan\n","        print(\"  âœ… Slope & aspect from richdem\")\n","    except Exception as e:\n","        print(f\"  âš ï¸  richdem failed ({e}) â€” using numpy\")\n","        SLOPE_ARR, ASPECT_ARR = compute_slope_aspect_numpy(DEM_ARR, DEM_RES)\n","else:\n","    SLOPE_ARR, ASPECT_ARR = compute_slope_aspect_numpy(DEM_ARR, DEM_RES)\n","    print(\"  âœ… Slope & aspect from numpy gradient\")\n","\n","# Save slope & aspect to disk\n","def save_raster(arr, path, template_path):\n","    with rasterio.open(template_path) as src:\n","        meta = src.meta.copy()\n","    meta.update({'dtype': 'float32', 'nodata': -9999.0, 'count': 1})\n","    arr_save = np.where(np.isnan(arr), -9999.0, arr)\n","    with rasterio.open(path, 'w', **meta) as dst:\n","        dst.write(arr_save.astype(np.float32), 1)\n","\n","save_raster(SLOPE_ARR,  os.path.join(OUT_DIR, \"slope.tif\"),  RASTERS['dem'])\n","save_raster(ASPECT_ARR, os.path.join(OUT_DIR, \"aspect.tif\"), RASTERS['dem'])\n","RASTERS['slope']  = os.path.join(OUT_DIR, \"slope.tif\")\n","RASTERS['aspect'] = os.path.join(OUT_DIR, \"aspect.tif\")\n","\n","# â”€â”€ HILLSHADE (used as background in all maps) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"  Computing hillshade for map backgrounds...\")\n","ls = LightSource(azdeg=315, altdeg=45)\n","dem_filled = np.where(np.isnan(DEM_ARR), np.nanmean(DEM_ARR), DEM_ARR)\n","HILLSHADE   = ls.hillshade(dem_filled, vert_exag=1.5, dx=DEM_RES, dy=DEM_RES)\n","HILLSHADE[np.isnan(DEM_ARR)] = np.nan\n","print(\"  âœ… Hillshade computed\")\n","\n","# â”€â”€ SPATIAL INDEX (for fast spatial joins) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\nâœ… SECTION 2 complete.\")\n","print(f\"  Subbasins    : {len(gdf_sub)}\")\n","print(f\"  Stream segs  : {len(gdf_streams)}\")\n","print(f\"  Stream orders: {sorted(gdf_so[ORDER_COL].unique())}\")\n","print(f\"  UTM CRS      : {UTM_EPSG}\")\n","print(f\"  DEM range    : {np.nanmin(DEM_ARR):.1f} â€“ {np.nanmax(DEM_ARR):.1f} m\")\n","print(f\"  Slope range  : {np.nanmin(SLOPE_ARR):.1f}Â° â€“ {np.nanmax(SLOPE_ARR):.1f}Â°\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tm63QYKOLkAs","executionInfo":{"status":"ok","timestamp":1771995942779,"user_tz":-330,"elapsed":627,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"3cf30a02-9e46-4cab-8b2e-3b743b8599a9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","SECTION 2 â€” DATA LOADING & PREPROCESSING\n","============================================================\n","\n","[1/6] Reading DEM metadata...\n","  CRS      : EPSG:32643\n","  Res      : (30.0, 30.0) m\n","  Shape    : (666, 962)\n","  Bounds   : BoundingBox(left=356736.128843744, bottom=2153126.894693779, right=385596.128843744, top=2173106.894693779)\n","  No-data  : 32767.0\n","  DEM is already projected: EPSG:32643\n","\n","[2/6] Reprojecting rasters...\n","  âœ… dem OK (already projected)\n","  âœ… flow_dir OK (already projected)\n","  âœ… flow_acc OK (already projected)\n","\n","[3/6] Loading vector layers...\n","  subbasins: 3 â†’ 3 features (after geometry fix)\n","  â„¹ï¸  N_SUBBASINS auto-detected: 3 polygons in /content/watershed_data/Subbasins.shp\n","  âœ… Subbasins: 3 | CRS: EPSG:32643\n","  Basin IDs: ['SB1', 'SB2', 'SB3']\n","  streams: 3610 â†’ 3610 features (after geometry fix)\n","  âœ… Streams: 3610 segments | CRS: EPSG:32643\n","  stream_order: 3610 â†’ 3610 features (after geometry fix)\n","  âœ… Stream order col detected: 'grid_code' | Orders: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6)]\n","  âœ… Pour points: 3\n","  Snapping pour points to max flow accumulation...\n","  Snap distances (m): [24.2, 341.0, 326.0]\n","\n","[4/6] Validating DEM resolution...\n","  âœ… DEM resolution: 30.0 x 30.0 m â‰ˆ 30 m SRTM âœ“\n","\n","[5/6] Reading raster arrays...\n","  DEM  shape: (666, 962) | min=584.0 max=1537.0 m\n","  FDIR shape: (666, 962)\n","  FACC shape: (666, 962)\n","\n","[6/6] Computing slope and aspect...\n","  âœ… Slope & aspect from numpy gradient\n","  Computing hillshade for map backgrounds...\n","  âœ… Hillshade computed\n","\n","âœ… SECTION 2 complete.\n","  Subbasins    : 3\n","  Stream segs  : 3610\n","  Stream orders: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6)]\n","  UTM CRS      : EPSG:32643\n","  DEM range    : 584.0 â€“ 1537.0 m\n","  Slope range  : 0.0Â° â€“ 88.4Â°\n"]}]},{"cell_type":"markdown","source":["=============================================================================\n","SECTION 3 â€” MORPHOMETRIC PARAMETER CALCULATION\n","=============================================================================\n","Computes all linear, areal, and relief morphometric parameters\n","per subbasin following Horton (1945), Strahler (1952, 1964),\n","Schumm (1956), and Miller (1953).\n","=========================================================================\n","\n","\n","\n"],"metadata":{"id":"yZmTbHnYMQZn"}},{"cell_type":"code","source":["print(\"=\" * 60)\n","print(\"SECTION 3 â€” MORPHOMETRIC PARAMETER CALCULATION\")\n","print(\"=\" * 60)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. LINEAR ASPECTS  (stream order statistics)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[A] Computing Linear Aspects...\")\n","\n","def compute_linear_aspects(gdf_streams_clipped, order_col, basin_id):\n","    \"\"\"\n","    Compute stream order statistics for one subbasin.\n","    Returns per-order DataFrame and summary ratios.\n","    \"\"\"\n","    rows = []\n","    orders = sorted(gdf_streams_clipped[order_col].unique())\n","\n","    for u in orders:\n","        segs = gdf_streams_clipped[gdf_streams_clipped[order_col] == u]\n","        nu   = len(segs)\n","        lu   = segs.geometry.length.sum()\n","        lsm  = lu / nu if nu > 0 else 0\n","        rows.append({'basin_id': basin_id, 'order': u,\n","                     'Nu': nu, 'Lu': lu, 'Lsm': lsm})\n","\n","    df = pd.DataFrame(rows).set_index('order')\n","\n","    # Bifurcation ratio Rb = Nu / Nu+1\n","    df['Rb'] = np.nan\n","    for i in range(len(df) - 1):\n","        o1, o2 = orders[i], orders[i+1]\n","        if df.loc[o2, 'Nu'] > 0:\n","            df.loc[o1, 'Rb'] = df.loc[o1, 'Nu'] / df.loc[o2, 'Nu']\n","\n","    # Stream length ratio RL = Lsm(u) / Lsm(u-1)\n","    df['RL'] = np.nan\n","    for i in range(1, len(df)):\n","        o_prev, o_curr = orders[i-1], orders[i]\n","        if df.loc[o_prev, 'Lsm'] > 0:\n","            df.loc[o_curr, 'RL'] = df.loc[o_curr, 'Lsm'] / df.loc[o_prev, 'Lsm']\n","\n","    # Mean bifurcation ratio (arithmetic)\n","    Rb_vals = df['Rb'].dropna()\n","    Rbm = Rb_vals.mean() if len(Rb_vals) > 0 else np.nan\n","\n","    # Weighted mean bifurcation ratio (Strahler, 1957)\n","    wRbm = np.nan\n","    if len(Rb_vals) > 0:\n","        weights = []\n","        for i in range(len(orders) - 1):\n","            o1, o2 = orders[i], orders[i+1]\n","            if not np.isnan(df.loc[o1, 'Rb']):\n","                weights.append(df.loc[o1, 'Nu'] + df.loc[o2, 'Nu'])\n","            else:\n","                weights.append(0)\n","        wts = np.array(weights)\n","        rb_wts = Rb_vals.values\n","        if wts.sum() > 0:\n","            wRbm = np.average(rb_wts, weights=wts[:len(rb_wts)])\n","\n","    return df.reset_index(), Rbm, wRbm\n","\n","\n","# Spatial join: streams to subbasins\n","gdf_so_sub = gpd.sjoin(\n","    gdf_so[[ORDER_COL, 'geometry']],\n","    gdf_sub[['basin_id', 'geometry']],\n","    how='left', predicate='within'\n",")\n","# Fallback: intersects for streams spanning boundaries\n","gdf_so_inter = gpd.sjoin(\n","    gdf_so[[ORDER_COL, 'geometry']],\n","    gdf_sub[['basin_id', 'geometry']],\n","    how='left', predicate='intersects'\n",")\n","gdf_so_sub = gdf_so_sub.dropna(subset=['basin_id'])\n","if len(gdf_so_sub) == 0:\n","    gdf_so_sub = gdf_so_inter.dropna(subset=['basin_id'])\n","\n","LINEAR_PER_ORDER = {}   # basin_id â†’ DataFrame\n","LINEAR_SUMMARY   = []   # one row per basin\n","\n","for bid in gdf_sub['basin_id']:\n","    segs = gdf_so_sub[gdf_so_sub['basin_id'] == bid]\n","    if len(segs) == 0:\n","        print(f\"  âš ï¸  No stream segments found for basin {bid}\")\n","        continue\n","    df_lin, Rbm, wRbm = compute_linear_aspects(segs, ORDER_COL, bid)\n","    LINEAR_PER_ORDER[bid] = df_lin\n","\n","    total_N = df_lin['Nu'].sum()\n","    total_L = df_lin['Lu'].sum()\n","    max_ord = df_lin['order'].max()\n","\n","    LINEAR_SUMMARY.append({\n","        'basin_id'       : bid,\n","        'total_streams_N': total_N,\n","        'total_length_m' : total_L,\n","        'max_order'      : max_ord,\n","        'Rbm'            : round(Rbm, 4),\n","        'wRbm'           : round(wRbm, 4) if not np.isnan(wRbm) else np.nan,\n","    })\n","    print(f\"  {bid}: {total_N} streams | max order {max_ord} | Rbm={Rbm:.3f}\")\n","\n","df_linear_summary = pd.DataFrame(LINEAR_SUMMARY).set_index('basin_id')\n","print(\"\\n  Stream Order Summary (all basins):\")\n","for bid, df in LINEAR_PER_ORDER.items():\n","    print(f\"\\n  [{bid}]\")\n","    print(df[['order','Nu','Lu','Lsm','Rb','RL']].to_string(index=False))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. AREAL ASPECTS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[B] Computing Areal Aspects...\")\n","\n","def longest_flow_path(basin_geom, facc_arr, transform, res_m):\n","    \"\"\"\n","    Approximate basin length (Lb) using the longest flow path concept:\n","    distance from centroid to pour point approximated as sqrt(A / 1.128)\n","    (Hack, 1957) as fallback.  Actual longest flow path would require\n","    full D8 tracing â€” approximation is acceptable for published studies.\n","    \"\"\"\n","    area = basin_geom.area          # mÂ²\n","    lb   = np.sqrt(area / 1.128)   # Hack approximation\n","    return lb\n","\n","\n","AREAL = []\n","\n","for _, row in gdf_sub.iterrows():\n","    bid   = row['basin_id']\n","    geom  = row.geometry\n","\n","    A  = geom.area          # mÂ²\n","    P  = geom.length        # m\n","    Lb = longest_flow_path(geom, FACC_ARR, DEM_TRANSFORM, DEM_RES)\n","\n","    # Streams inside basin\n","    segs = gdf_so_sub[gdf_so_sub['basin_id'] == bid]\n","    total_stream_length = segs.geometry.length.sum() if len(segs) > 0 else 0\n","    Nu_total = len(segs)\n","\n","    # ----- parameters -----\n","    A_km2   = A   / 1e6\n","    P_km    = P   / 1e3\n","    Lb_km   = Lb  / 1e3\n","    L_km    = total_stream_length / 1e3\n","\n","    Dd = L_km  / A_km2 if A_km2 > 0 else np.nan   # Drainage density  [km/kmÂ²]\n","    Fs = Nu_total / A_km2 if A_km2 > 0 else np.nan # Stream frequency  [streams/kmÂ²]\n","    T  = Nu_total / P_km  if P_km  > 0 else np.nan # Texture ratio\n","    Ff = A_km2   / (Lb_km**2)     if Lb_km > 0 else np.nan  # Form factor (Horton,1932)\n","    Re = (2 / Lb_km) * np.sqrt(A_km2 / np.pi) if Lb_km > 0 else np.nan  # Elongation ratio\n","    Rc = (4 * np.pi * A_km2) / (P_km**2)  if P_km > 0 else np.nan       # Circularity ratio\n","    Cc = P_km / (2 * np.sqrt(np.pi * A_km2)) if A_km2 > 0 else np.nan   # Compactness coeff\n","    Lg = 1 / (2 * Dd)   if Dd and Dd > 0 else np.nan   # Length of overland flow\n","    C  = 1 / Dd          if Dd and Dd > 0 else np.nan   # Constant of channel maintenance\n","\n","    AREAL.append({\n","        'basin_id'              : bid,\n","        'Area_km2'              : round(A_km2, 4),\n","        'Perimeter_km'          : round(P_km, 4),\n","        'Basin_Length_km'       : round(Lb_km, 4),\n","        'Total_Stream_Length_km': round(L_km, 4),\n","        'Stream_Count'          : Nu_total,\n","        'Drainage_Density_Dd'   : round(Dd, 4) if not np.isnan(Dd) else np.nan,\n","        'Stream_Frequency_Fs'   : round(Fs, 4) if not np.isnan(Fs) else np.nan,\n","        'Texture_Ratio_T'       : round(T,  4) if not np.isnan(T)  else np.nan,\n","        'Form_Factor_Ff'        : round(Ff, 4) if not np.isnan(Ff) else np.nan,\n","        'Elongation_Ratio_Re'   : round(Re, 4) if not np.isnan(Re) else np.nan,\n","        'Circularity_Ratio_Rc'  : round(Rc, 4) if not np.isnan(Rc) else np.nan,\n","        'Compactness_Cc'        : round(Cc, 4) if not np.isnan(Cc) else np.nan,\n","        'LengthOverlandFlow_Lg' : round(Lg, 4) if not np.isnan(Lg) else np.nan,\n","        'ChannelMaintenance_C'  : round(C,  4) if not np.isnan(C)  else np.nan,\n","    })\n","\n","    print(f\"  {bid}: A={A_km2:.2f} kmÂ² | Dd={Dd:.3f} km/kmÂ² | \"\n","          f\"Re={Re:.3f} | Rc={Rc:.3f} | Ff={Ff:.3f}\")\n","\n","df_areal = pd.DataFrame(AREAL).set_index('basin_id')\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. RELIEF ASPECTS  (DEM zonal statistics)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[C] Computing Relief Aspects...\")\n","\n","def hypsometric_integral(dem_clipped):\n","    \"\"\"\n","    Compute hypsometric integral (HI) = (mean_elev - min_elev) / (max_elev - min_elev)\n","    Also returns arrays for hypsometric curve: (relative_area, relative_elevation)\n","    \"\"\"\n","    vals = dem_clipped[~np.isnan(dem_clipped)].flatten()\n","    if len(vals) < 10:\n","        return np.nan, None, None\n","    mn, mx, mu = vals.min(), vals.max(), vals.mean()\n","    rng = mx - mn\n","    if rng == 0:\n","        return np.nan, None, None\n","    HI = (mu - mn) / rng\n","    # Curve: relative elevation h/H vs relative area a/A\n","    thresholds   = np.percentile(vals, np.linspace(0, 100, 101))\n","    rel_elev     = (thresholds - mn) / rng          # h/H  (0â†’1)\n","    rel_area     = 1 - np.linspace(0, 1, 101)       # a/A  (1â†’0)\n","    return HI, rel_area, rel_elev\n","\n","\n","def terrain_ruggedness_index(dem_arr):\n","    \"\"\"\n","    TRI (Riley et al., 1999): mean absolute difference from center cell\n","    to 8 neighbours.\n","    \"\"\"\n","    from scipy.ndimage import generic_filter\n","    def _tri_kernel(x):\n","        centre = x[4]\n","        if np.isnan(centre):\n","            return np.nan\n","        diffs = x - centre\n","        diffs[4] = 0\n","        valid = diffs[~np.isnan(diffs)]\n","        return np.sqrt(np.sum(valid**2)) if len(valid) > 0 else np.nan\n","    tri = generic_filter(dem_arr.astype(float), _tri_kernel, size=3, mode='reflect')\n","    tri[np.isnan(dem_arr)] = np.nan\n","    return tri\n","\n","\n","def melton_ruggedness(h_m, a_km2):\n","    \"\"\"Melton (1965) ruggedness index MRN = H / sqrt(A).\"\"\"\n","    return h_m / np.sqrt(a_km2) if a_km2 > 0 else np.nan\n","\n","\n","# Compute TRI once for full DEM\n","print(\"  Computing TRI (this may take 30â€“60 sec on large DEMs)...\")\n","TRI_ARR = terrain_ruggedness_index(DEM_ARR)\n","save_raster(TRI_ARR, os.path.join(OUT_DIR, \"tri.tif\"), RASTERS['dem'])\n","\n","RELIEF   = []\n","HYPS     = {}   # basin_id â†’ (rel_area, rel_elev)\n","\n","for _, row in gdf_sub.iterrows():\n","    bid  = row['basin_id']\n","    geom = [row.geometry.__geo_interface__]\n","\n","    # Mask DEM to subbasin\n","    with rasterio.open(RASTERS['dem']) as src:\n","        try:\n","            arr_masked, _ = rio_mask(src, geom, crop=True, nodata=np.nan)\n","            dem_clip = arr_masked[0].astype(np.float32)\n","            dem_clip[dem_clip == src.nodata] = np.nan\n","        except Exception:\n","            dem_clip = DEM_ARR.copy()\n","\n","    # Mask slope to subbasin\n","    with rasterio.open(RASTERS['slope']) as src:\n","        try:\n","            s_masked, _ = rio_mask(src, geom, crop=True, nodata=np.nan)\n","            slope_clip = s_masked[0].astype(np.float32)\n","            slope_clip[slope_clip == -9999.0] = np.nan\n","        except Exception:\n","            slope_clip = SLOPE_ARR.copy()\n","\n","    # Mask TRI\n","    with rasterio.open(os.path.join(OUT_DIR, \"tri.tif\")) as src:\n","        try:\n","            t_masked, _ = rio_mask(src, geom, crop=True, nodata=np.nan)\n","            tri_clip = t_masked[0].astype(np.float32)\n","            tri_clip[tri_clip == -9999.0] = np.nan\n","        except Exception:\n","            tri_clip = TRI_ARR.copy()\n","\n","    valid_dem   = dem_clip[~np.isnan(dem_clip)]\n","    valid_slope = slope_clip[~np.isnan(slope_clip)]\n","    valid_tri   = tri_clip[~np.isnan(tri_clip)]\n","\n","    if len(valid_dem) == 0:\n","        print(f\"  âš ï¸  {bid}: no valid DEM cells\")\n","        continue\n","\n","    elev_min  = float(valid_dem.min())\n","    elev_max  = float(valid_dem.max())\n","    elev_mean = float(valid_dem.mean())\n","    H         = elev_max - elev_min              # Basin relief (m)\n","    A_km2     = df_areal.loc[bid, 'Area_km2']\n","    Lb_km     = df_areal.loc[bid, 'Basin_Length_km']\n","    P_km      = df_areal.loc[bid, 'Perimeter_km']\n","\n","    Rh  = H / (Lb_km * 1000) if Lb_km > 0 else np.nan   # Relief ratio\n","    Rr  = H / P_km            if P_km  > 0 else np.nan   # Relative relief\n","    Dd  = df_areal.loc[bid, 'Drainage_Density_Dd']\n","    Rn  = H * Dd / 1000       if not np.isnan(Dd) else np.nan  # Ruggedness number\n","    MRN = melton_ruggedness(H, A_km2)                           # Melton ruggedness\n","\n","    # Hypsometric integral\n","    HI, rel_area, rel_elev = hypsometric_integral(dem_clip)\n","    if rel_area is not None:\n","        HYPS[bid] = (rel_area, rel_elev)\n","\n","    # Slope statistics\n","    slope_mean = float(np.nanmean(valid_slope))\n","    slope_std  = float(np.nanstd(valid_slope))\n","    slope_skew = float(stats.skew(valid_slope))\n","\n","    # TRI stats\n","    tri_mean = float(np.nanmean(valid_tri))\n","\n","    RELIEF.append({\n","        'basin_id'         : bid,\n","        'Elev_Min_m'       : round(elev_min,  2),\n","        'Elev_Max_m'       : round(elev_max,  2),\n","        'Elev_Mean_m'      : round(elev_mean, 2),\n","        'Basin_Relief_H_m' : round(H,         2),\n","        'Relief_Ratio_Rh'  : round(Rh,        6) if not np.isnan(Rh) else np.nan,\n","        'Relative_Relief'  : round(Rr,        4) if not np.isnan(Rr) else np.nan,\n","        'Ruggedness_Rn'    : round(Rn,        4) if not np.isnan(Rn) else np.nan,\n","        'Melton_MRN'       : round(MRN,       4) if not np.isnan(MRN) else np.nan,\n","        'Hypsometric_HI'   : round(HI,        4) if not np.isnan(HI) else np.nan,\n","        'Slope_Mean_deg'   : round(slope_mean, 3),\n","        'Slope_Std_deg'    : round(slope_std,  3),\n","        'Slope_Skewness'   : round(slope_skew, 4),\n","        'TRI_Mean'         : round(tri_mean,   3),\n","    })\n","\n","    print(f\"  {bid}: H={H:.0f}m | Rh={Rh:.5f} | HI={HI:.3f} | \"\n","          f\"Rn={Rn:.3f} | Slope_mean={slope_mean:.2f}Â°\")\n","\n","df_relief = pd.DataFrame(RELIEF).set_index('basin_id')\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  D. MASTER MORPHOMETRIC TABLE\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[D] Assembling master morphometric table...\")\n","\n","df_master = df_areal.join(df_relief, how='left')\n","df_master = df_master.join(df_linear_summary, how='left')\n","\n","# Add stream order per-basin summary\n","for bid in gdf_sub['basin_id']:\n","    if bid in LINEAR_PER_ORDER:\n","        df_lin = LINEAR_PER_ORDER[bid]\n","        for _, r in df_lin.iterrows():\n","            col = f\"Nu_order{int(r['order'])}\"\n","            df_master.loc[bid, col] = r['Nu']\n","            col = f\"Lu_order{int(r['order'])}_km\"\n","            df_master.loc[bid, col] = round(r['Lu'] / 1000, 4)\n","\n","# â”€â”€ Interpretation flags â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","def interpret_elongation(Re):\n","    if pd.isna(Re):       return \"Unknown\"\n","    if Re >= 0.9:         return \"Circular\"\n","    if Re >= 0.8:         return \"Oval\"\n","    if Re >= 0.7:         return \"Less Elongated\"\n","    if Re >= 0.5:         return \"Elongated\"\n","    return \"More Elongated\"\n","\n","def interpret_circularity(Rc):\n","    if pd.isna(Rc):      return \"Unknown\"\n","    if Rc >= 0.75:       return \"Circular/Young\"\n","    if Rc >= 0.50:       return \"Intermediate\"\n","    return \"Elongated/Old\"\n","\n","def interpret_HI(HI):\n","    if pd.isna(HI):      return \"Unknown\"\n","    if HI > 0.60:        return \"Monadnock (Young/Convex)\"\n","    if HI > 0.35:        return \"Mature (Equilibrium)\"\n","    return \"Peneplain (Old/Concave)\"\n","\n","df_master['Shape_Class']    = df_master['Elongation_Ratio_Re'].apply(interpret_elongation)\n","df_master['Circ_Class']     = df_master['Circularity_Ratio_Rc'].apply(interpret_circularity)\n","df_master['Hyps_Class']     = df_master['Hypsometric_HI'].apply(interpret_HI)\n","\n","# Save\n","csv_path = os.path.join(TABLES_DIR, \"morphometric_master_table.csv\")\n","df_master.to_csv(csv_path)\n","print(f\"  âœ… Master table saved: {csv_path}\")\n","\n","print(\"\\n\" + \"â”€\"*60)\n","print(\"  MASTER MORPHOMETRIC TABLE (first 10 rows/all params):\")\n","print(\"â”€\"*60)\n","print(df_master.to_string())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eD0qGPmrMHpe","executionInfo":{"status":"ok","timestamp":1771995997219,"user_tz":-330,"elapsed":13269,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"457b9a61-86a9-4a26-de82-5775502da906"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","SECTION 3 â€” MORPHOMETRIC PARAMETER CALCULATION\n","============================================================\n","\n","[A] Computing Linear Aspects...\n","  SB1: 1453 streams | max order 6 | Rbm=2.520\n","  SB2: 528 streams | max order 5 | Rbm=1.796\n","  SB3: 1618 streams | max order 6 | Rbm=1.763\n","\n","  Stream Order Summary (all basins):\n","\n","  [SB1]\n"," order  Nu          Lu      Lsm     Rb     RL\n","     1 726 205258.4154 282.7251 2.0393    NaN\n","     2 356  90099.8694 253.0895 2.0819 0.8952\n","     3 171  46390.9950 271.2924 1.1875 1.0719\n","     4 144  29365.6030 203.9278 3.2000 0.7517\n","     5  45   7702.0835 171.1574 4.0909 0.8393\n","     6  11   2573.0866 233.9170    NaN 1.3667\n","\n","  [SB2]\n"," order  Nu         Lu      Lsm     Rb     RL\n","     1 269 68134.3848 253.2877 2.2417    NaN\n","     2 120 31291.0933 260.7591 1.6901 1.0295\n","     3  71 18227.4807 256.7251 1.7317 0.9845\n","     4  41 11344.9386 276.7058 1.5185 1.0778\n","     5  27  8300.0782 307.4103    NaN 1.1110\n","\n","  [SB3]\n"," order  Nu          Lu      Lsm     Rb     RL\n","     1 827 234901.7470 284.0408 2.4985    NaN\n","     2 331  96697.0023 292.1360 1.5045 1.0285\n","     3 220  53369.5352 242.5888 2.1782 0.8304\n","     4 101  24494.5395 242.5202 2.1042 0.9997\n","     5  48  12164.2414 253.4217 0.5275 1.0450\n","     6  91  25184.5686 276.7535    NaN 1.0921\n","\n","[B] Computing Areal Aspects...\n","  SB1: A=116.99 kmÂ² | Dd=3.260 km/kmÂ² | Re=1.198 | Rc=0.304 | Ff=1.128\n","  SB2: A=45.19 kmÂ² | Dd=3.038 km/kmÂ² | Re=1.198 | Rc=0.311 | Ff=1.128\n","  SB3: A=149.97 kmÂ² | Dd=2.979 km/kmÂ² | Re=1.198 | Rc=0.309 | Ff=1.128\n","\n","[C] Computing Relief Aspects...\n","  Computing TRI (this may take 30â€“60 sec on large DEMs)...\n","  SB1: H=953m | Rh=0.09358 | HI=0.262 | Rn=3.107 | Slope_mean=13.85Â°\n","  SB2: H=953m | Rh=0.15056 | HI=0.262 | Rn=2.895 | Slope_mean=13.93Â°\n","  SB3: H=953m | Rh=0.08265 | HI=0.262 | Rn=2.839 | Slope_mean=12.13Â°\n","\n","[D] Assembling master morphometric table...\n","  âœ… Master table saved: /content/morphometric_outputs/tables/morphometric_master_table.csv\n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","  MASTER MORPHOMETRIC TABLE (first 10 rows/all params):\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","          Area_km2  Perimeter_km  Basin_Length_km  Total_Stream_Length_km  Stream_Count  Drainage_Density_Dd  Stream_Frequency_Fs  Texture_Ratio_T  Form_Factor_Ff  Elongation_Ratio_Re  Circularity_Ratio_Rc  Compactness_Cc  LengthOverlandFlow_Lg  ChannelMaintenance_C  Elev_Min_m  Elev_Max_m  Elev_Mean_m  Basin_Relief_H_m  Relief_Ratio_Rh  Relative_Relief  Ruggedness_Rn  Melton_MRN  Hypsometric_HI  Slope_Mean_deg  Slope_Std_deg  Slope_Skewness  TRI_Mean  total_streams_N  total_length_m  max_order    Rbm   wRbm  Nu_order1  Lu_order1_km  Nu_order2  Lu_order2_km  Nu_order3  Lu_order3_km  Nu_order4  Lu_order4_km  Nu_order5  Lu_order5_km  Nu_order6  Lu_order6_km Shape_Class     Circ_Class               Hyps_Class\n","basin_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n","SB1       116.9859       69.5188          10.1839                381.3901          1453               3.2601              12.4203          20.9008          1.1280               1.1984                0.3042          1.8131                 0.1534                0.3067    584.0000   1537.0000     833.5800          953.0000           0.0936          13.7085         3.1069     88.1102          0.2619         13.8520        12.9940          1.4301   21.6340             1453     381390.0528          6 2.5199 2.0801   726.0000      205.2584   356.0000       90.0999   171.0000       46.3910   144.0000       29.3656    45.0000        7.7021    11.0000        2.5731    Circular  Elongated/Old  Peneplain (Old/Concave)\n","SB2        45.1921       42.7535           6.3296                137.2980           528               3.0381              11.6835          12.3499          1.1280               1.1984                0.3107          1.7941                 0.1646                0.3292    584.0000   1537.0000     833.5800          953.0000           0.1506          22.2906         2.8953    141.7626          0.2619         13.9250        10.9820          1.4394   20.5910              528     137297.9756          5 1.7955 1.9632   269.0000       68.1344   120.0000       31.2911    71.0000       18.2275    41.0000       11.3449    27.0000        8.3001        NaN           NaN    Circular  Elongated/Old  Peneplain (Old/Concave)\n","SB3       149.9694       78.0458          11.5305                446.8116          1618               2.9794              10.7889          20.7314          1.1280               1.1984                0.3094          1.7978                 0.1678                0.3356    584.0000   1537.0000     833.5800          953.0000           0.0827          12.2108         2.8394     77.8201          0.2619         12.1300         9.0790          1.8321   17.6630             1618     446811.6341          6 1.7626 2.0743   827.0000      234.9017   331.0000       96.6970   220.0000       53.3695   101.0000       24.4945    48.0000       12.1642    91.0000       25.1846    Circular  Elongated/Old  Peneplain (Old/Concave)\n"]}]},{"cell_type":"markdown","source":["=============================================================================\n","SECTION 4 â€” PUBLICATION-GRADE MAPS\n","=============================================================================\n","Generates 9 maps, all with:\n","  â€¢ Hillshade background\n","  â€¢ DMS (Â°â€²â€³) grid\n","  â€¢ North arrow\n","  â€¢ Scale bar\n","  â€¢ Subbasin boundaries overlay\n","  â€¢ Stream network overlay\n","  â€¢ Colourbar / legend\n","  â€¢ Title\n","\n","Maps produced:\n","  1. Elevation (DEM)\n","  2. Slope\n","  3. Aspect\n","  4. Flow Direction\n","  5. Flow Accumulation\n","  6. Stream Order (Strahler)\n","  7. Drainage Density\n","  8. Contour\n","  9. Pour Points (snapped) on DEM\n","============================================================================="],"metadata":{"id":"gKw5z9cWMu82"}},{"cell_type":"code","source":["print(\"=\" * 60)\n","print(\"SECTION 4 â€” MAP GENERATION\")\n","print(\"=\" * 60)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  SHARED MAP UTILITIES\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","from pyproj import Transformer as PyTransformer\n","\n","# Transform from UTM â†’ WGS84 for grid labelling\n","_to_geo = PyTransformer.from_crs(UTM_EPSG, \"EPSG:4326\", always_xy=True)\n","\n","\n","def dd_to_dms(dd, is_lat=True):\n","    \"\"\"Decimal degrees â†’ DMS string.\"\"\"\n","    hemi = (\"N\" if dd >= 0 else \"S\") if is_lat else (\"E\" if dd >= 0 else \"W\")\n","    dd = abs(dd)\n","    deg = int(dd)\n","    mins_full = (dd - deg) * 60\n","    mins = int(mins_full)\n","    secs = (mins_full - mins) * 60\n","    return f\"{deg}Â°{mins:02d}â€²{secs:04.1f}â€³{hemi}\"\n","\n","\n","def get_dms_ticks(utm_extent, n=5):\n","    \"\"\"\n","    Return (x_utm_ticks, x_labels, y_utm_ticks, y_labels)\n","    for DMS-formatted grid lines.\n","    utm_extent = (xmin, xmax, ymin, ymax) in UTM metres\n","    \"\"\"\n","    xmin, xmax, ymin, ymax = utm_extent\n","    # Sample grid corners in geographic\n","    corners_utm = [\n","        (xmin, ymin), (xmax, ymin), (xmin, ymax), (xmax, ymax),\n","    ]\n","    lon_all, lat_all = [], []\n","    for xu, yu in corners_utm:\n","        lo, la = _to_geo.transform(xu, yu)\n","        lon_all.append(lo)\n","        lat_all.append(la)\n","    lon_min, lon_max = min(lon_all), max(lon_all)\n","    lat_min, lat_max = min(lat_all), max(lat_all)\n","\n","    # Nicely spaced geographic ticks\n","    lon_ticks_geo = np.linspace(lon_min, lon_max, n)\n","    lat_ticks_geo = np.linspace(lat_min, lat_max, n)\n","\n","    # Convert back to UTM for pyplot ticks\n","    from pyproj import Transformer as T2\n","    _to_utm = T2.from_crs(\"EPSG:4326\", UTM_EPSG, always_xy=True)\n","    x_ticks_utm = [_to_utm.transform(lo, (lat_min + lat_max) / 2)[0] for lo in lon_ticks_geo]\n","    y_ticks_utm = [_to_utm.transform((lon_min + lon_max) / 2, la)[1] for la in lat_ticks_geo]\n","\n","    x_labels = [dd_to_dms(lo, is_lat=False) for lo in lon_ticks_geo]\n","    y_labels = [dd_to_dms(la, is_lat=True)  for la in lat_ticks_geo]\n","\n","    return x_ticks_utm, x_labels, y_ticks_utm, y_labels\n","\n","\n","def compute_utm_extent():\n","    \"\"\"Return (xmin, xmax, ymin, ymax) from DEM bounds.\"\"\"\n","    b = DEM_BOUNDS\n","    return b.left, b.right, b.bottom, b.top\n","\n","\n","def add_north_arrow(ax, x=0.96, y=0.94, size=0.045):\n","    \"\"\"Add a north arrow to axes using annotation.\"\"\"\n","    ax.annotate(\n","        '', xy=(x, y), xycoords='axes fraction',\n","        xytext=(x, y - size * 2),\n","        textcoords='axes fraction',\n","        arrowprops=dict(arrowstyle='->', color='black', lw=2),\n","        annotation_clip=False,\n","    )\n","    ax.text(x, y + 0.005, 'N', transform=ax.transAxes,\n","            ha='center', va='bottom', fontsize=13,\n","            fontweight='bold', color='black',\n","            path_effects=[pe.withStroke(linewidth=3, foreground='white')])\n","\n","\n","def add_scale_bar(ax, extent_m, frac=0.2, y_pos=0.04, x_pos=0.05):\n","    \"\"\"\n","    Add a scale bar. extent_m = (xmin, xmax, ymin, ymax) in metres.\n","    \"\"\"\n","    xmin, xmax = extent_m[0], extent_m[1]\n","    width_m = (xmax - xmin) * frac\n","\n","    # Round to nice number\n","    magnitude = 10 ** np.floor(np.log10(width_m))\n","    width_m   = round(width_m / magnitude) * magnitude\n","\n","    # In axes fraction\n","    total_m = xmax - xmin\n","    bar_frac = width_m / total_m\n","\n","    label_km = f\"{width_m/1000:.0f} km\" if width_m >= 1000 else f\"{width_m:.0f} m\"\n","\n","    ax.annotate(\n","        '', xy=(x_pos + bar_frac, y_pos), xycoords='axes fraction',\n","        xytext=(x_pos, y_pos), textcoords='axes fraction',\n","        arrowprops=dict(arrowstyle='<->', color='black', lw=2),\n","        annotation_clip=False,\n","    )\n","    ax.text(x_pos + bar_frac / 2, y_pos + 0.02,\n","            label_km, transform=ax.transAxes,\n","            ha='center', va='bottom', fontsize=9, color='black',\n","            path_effects=[pe.withStroke(linewidth=2, foreground='white')])\n","\n","\n","def apply_dms_grid(ax, utm_extent, n_ticks=5):\n","    \"\"\"Apply DMS-labelled grid to axes.\"\"\"\n","    x_ticks, x_labels, y_ticks, y_labels = get_dms_ticks(utm_extent, n=n_ticks)\n","    ax.set_xticks(x_ticks)\n","    ax.set_xticklabels(x_labels, rotation=25, ha='right', fontsize=7.5)\n","    ax.set_yticks(y_ticks)\n","    ax.set_yticklabels(y_labels, fontsize=7.5)\n","    ax.grid(True, linestyle='--', linewidth=0.4, color='grey', alpha=0.6)\n","    ax.tick_params(direction='in', top=True, right=True, length=4)\n","\n","\n","def base_axes(title, figsize=(11, 9)):\n","    \"\"\"Create figure/axes with hillshade background.\"\"\"\n","    fig, ax = plt.subplots(figsize=figsize)\n","    utm_extent = compute_utm_extent()\n","    # Hillshade background\n","    ax.imshow(\n","        HILLSHADE,\n","        extent=[utm_extent[0], utm_extent[1], utm_extent[2], utm_extent[3]],\n","        origin='upper', cmap='Greys', alpha=0.45,\n","        aspect='auto', zorder=0,\n","    )\n","    ax.set_xlim(utm_extent[0], utm_extent[1])\n","    ax.set_ylim(utm_extent[2], utm_extent[3])\n","    ax.set_title(title, fontsize=14, fontweight='bold', pad=10)\n","    ax.set_xlabel(\"Longitude\", fontsize=10)\n","    ax.set_ylabel(\"Latitude\",  fontsize=10)\n","    return fig, ax, utm_extent\n","\n","\n","def overlay_boundaries(ax, alpha_sub=0.9, alpha_str=0.5):\n","    \"\"\"Overlay subbasin boundaries and stream network.\"\"\"\n","    gdf_sub.boundary.plot(ax=ax, edgecolor='black', linewidth=1.2,\n","                          zorder=10, label='Subbasin boundary')\n","    if len(gdf_streams) > 0:\n","        gdf_streams.plot(ax=ax, color='royalblue', linewidth=0.8,\n","                         alpha=alpha_str, zorder=9, label='Stream network')\n","\n","\n","def finalize_and_save(fig, ax, utm_extent, filename, n_ticks=5):\n","    \"\"\"Apply grid, north arrow, scale bar, tight layout, save.\"\"\"\n","    apply_dms_grid(ax, utm_extent, n_ticks)\n","    add_north_arrow(ax)\n","    add_scale_bar(ax, utm_extent)\n","    plt.tight_layout()\n","    out_path = os.path.join(MAPS_DIR, filename)\n","    fig.savefig(out_path, dpi=200, bbox_inches='tight')\n","    plt.close(fig)\n","    print(f\"  âœ… Saved: {out_path}\")\n","    return out_path\n","\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  MAP HELPER â€” raster_to_plot array\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","def raster_extent():\n","    b = DEM_BOUNDS\n","    return [b.left, b.right, b.bottom, b.top]\n","\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  1. ELEVATION MAP\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[1/9] Elevation map...\")\n","fig, ax, utm_ext = base_axes(\"Elevation Map â€” SRTM 30 m DEM\")\n","cmap_elev = plt.get_cmap('terrain')\n","im = ax.imshow(\n","    DEM_ARR,\n","    extent=raster_extent(), origin='upper',\n","    cmap=cmap_elev, alpha=0.75, zorder=1,\n","    vmin=np.nanpercentile(DEM_ARR, 2), vmax=np.nanpercentile(DEM_ARR, 98),\n",")\n","overlay_boundaries(ax)\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"3%\", pad=0.07)\n","cb  = plt.colorbar(im, cax=cax)\n","cb.set_label(\"Elevation (m)\", fontsize=10)\n","ax.legend(loc='lower left', fontsize=8, framealpha=0.8)\n","finalize_and_save(fig, ax, utm_ext, \"01_elevation.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  2. SLOPE MAP\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"[2/9] Slope map...\")\n","fig, ax, utm_ext = base_axes(\"Slope Map (degrees)\")\n","im = ax.imshow(\n","    SLOPE_ARR,\n","    extent=raster_extent(), origin='upper',\n","    cmap='YlOrRd', alpha=0.75, zorder=1,\n","    vmin=0, vmax=np.nanpercentile(SLOPE_ARR, 98),\n",")\n","overlay_boundaries(ax)\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"3%\", pad=0.07)\n","cb  = plt.colorbar(im, cax=cax)\n","cb.set_label(\"Slope (Â°)\", fontsize=10)\n","finalize_and_save(fig, ax, utm_ext, \"02_slope.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  3. ASPECT MAP\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"[3/9] Aspect map...\")\n","fig, ax, utm_ext = base_axes(\"Aspect Map (degrees from North)\")\n","cmap_aspect = plt.get_cmap('hsv')\n","im = ax.imshow(\n","    ASPECT_ARR,\n","    extent=raster_extent(), origin='upper',\n","    cmap=cmap_aspect, alpha=0.75, zorder=1,\n","    vmin=0, vmax=360,\n",")\n","overlay_boundaries(ax)\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"3%\", pad=0.07)\n","cb  = plt.colorbar(im, cax=cax)\n","cb.set_ticks([0, 45, 90, 135, 180, 225, 270, 315, 360])\n","cb.set_ticklabels(['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N'])\n","cb.set_label(\"Aspect\", fontsize=10)\n","finalize_and_save(fig, ax, utm_ext, \"03_aspect.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  4. FLOW DIRECTION MAP\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"[4/9] Flow direction map...\")\n","fig, ax, utm_ext = base_axes(\"Flow Direction Map (D8 encoding)\")\n","# D8: 1=E,2=SE,4=S,8=SW,16=W,32=NW,64=N,128=NE\n","d8_labels = {1:'E',2:'SE',4:'S',8:'SW',16:'W',32:'NW',64:'N',128:'NE'}\n","unique_d8 = [v for v in sorted(d8_labels.keys()) if v in np.unique(FDIR_ARR[~np.isnan(FDIR_ARR)])]\n","colors_d8  = plt.cm.tab10(np.linspace(0, 1, 8))\n","d8_cmap    = mcolors.ListedColormap(colors_d8[:len(unique_d8)])\n","d8_bounds  = [unique_d8[0] - 0.5] + [v + 0.5 for v in unique_d8]\n","d8_norm    = mcolors.BoundaryNorm(d8_bounds, d8_cmap.N)\n","\n","im = ax.imshow(\n","    FDIR_ARR,\n","    extent=raster_extent(), origin='upper',\n","    cmap=d8_cmap, norm=d8_norm, alpha=0.70, zorder=1,\n",")\n","overlay_boundaries(ax)\n","patches_d8 = [mpatches.Patch(color=colors_d8[i], label=d8_labels.get(unique_d8[i], str(unique_d8[i])))\n","              for i in range(len(unique_d8))]\n","ax.legend(handles=patches_d8, loc='lower left', fontsize=7,\n","          title='Flow Dir.', title_fontsize=8, framealpha=0.8, ncol=2)\n","finalize_and_save(fig, ax, utm_ext, \"04_flow_direction.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  5. FLOW ACCUMULATION MAP\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"[5/9] Flow accumulation map...\")\n","fig, ax, utm_ext = base_axes(\"Flow Accumulation Map (logâ‚â‚€ scale)\")\n","fa_log = np.log10(np.where(FACC_ARR > 0, FACC_ARR, np.nan))\n","im = ax.imshow(\n","    fa_log,\n","    extent=raster_extent(), origin='upper',\n","    cmap='Blues', alpha=0.80, zorder=1,\n",")\n","overlay_boundaries(ax)\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"3%\", pad=0.07)\n","cb  = plt.colorbar(im, cax=cax)\n","cb.set_label(\"logâ‚â‚€(Flow Accum.)\", fontsize=10)\n","finalize_and_save(fig, ax, utm_ext, \"05_flow_accumulation.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  6. STREAM ORDER MAP (Strahler)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"[6/9] Stream order map...\")\n","fig, ax, utm_ext = base_axes(\"Strahler Stream Order Map\")\n","# Hillshade already in base_axes\n","overlay_boundaries(ax, alpha_str=0)   # suppress default streams\n","\n","orders_list = sorted(gdf_so[ORDER_COL].unique())\n","order_cmap  = plt.cm.get_cmap('plasma_r', len(orders_list))\n","order_colors = {o: order_cmap(i) for i, o in enumerate(orders_list)}\n","lw_map       = {o: 0.5 + (o - 1) * 0.6 for o in orders_list}\n","\n","for o in orders_list:\n","    segs = gdf_so[gdf_so[ORDER_COL] == o]\n","    segs.plot(ax=ax, color=order_colors[o], linewidth=lw_map[o],\n","              zorder=5 + o, label=f\"Order {o}\")\n","\n","gdf_sub.boundary.plot(ax=ax, edgecolor='black', linewidth=1.2, zorder=15)\n","ax.legend(loc='lower left', fontsize=8, framealpha=0.85, title='Strahler Order')\n","finalize_and_save(fig, ax, utm_ext, \"06_stream_order.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  7. DRAINAGE DENSITY MAP\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"[7/9] Drainage density map...\")\n","fig, ax, utm_ext = base_axes(\"Drainage Density Map (km/kmÂ²)\")\n","gdf_dd = gdf_sub.merge(\n","    df_master[['Drainage_Density_Dd']].reset_index(),\n","    on='basin_id', how='left'\n",")\n","gdf_dd.plot(\n","    column='Drainage_Density_Dd', ax=ax,\n","    cmap='YlGnBu', legend=True, alpha=0.75, zorder=2,\n","    legend_kwds={'label': 'Drainage Density (km/kmÂ²)', 'shrink': 0.7},\n","    edgecolor='black', linewidth=1.0,\n",")\n","# Basin labels\n","for _, r in gdf_dd.iterrows():\n","    cx, cy = r.geometry.centroid.x, r.geometry.centroid.y\n","    ax.text(cx, cy, f\"{r['basin_id']}\\n{r['Drainage_Density_Dd']:.2f}\",\n","            ha='center', va='center', fontsize=8, fontweight='bold',\n","            color='white',\n","            path_effects=[pe.withStroke(linewidth=2, foreground='black')])\n","\n","gdf_streams.plot(ax=ax, color='royalblue', linewidth=0.7, alpha=0.6, zorder=5)\n","finalize_and_save(fig, ax, utm_ext, \"07_drainage_density.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  8. CONTOUR MAP\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"[8/9] Contour map...\")\n","fig, ax, utm_ext = base_axes(\"Topographic Contour Map\")\n","\n","b = DEM_BOUNDS\n","dem_range = np.nanmax(DEM_ARR) - np.nanmin(DEM_ARR)\n","interval  = max(10, round(dem_range / 20, -1))   # smart interval\n","\n","x_c = np.linspace(b.left,   b.right,  DEM_ARR.shape[1])\n","y_c = np.linspace(b.bottom, b.top,    DEM_ARR.shape[0])[::-1]  # origin='upper'\n","XX, YY = np.meshgrid(x_c, y_c)\n","\n","contour_levels = np.arange(\n","    round(np.nanmin(DEM_ARR) / interval) * interval,\n","    np.nanmax(DEM_ARR) + interval,\n","    interval,\n",")\n","major_levels = contour_levels[::4]\n","\n","dem_filled_c = np.where(np.isnan(DEM_ARR), np.nanmean(DEM_ARR), DEM_ARR)\n","cs_minor = ax.contour(XX, YY, dem_filled_c, levels=contour_levels,\n","                       colors='saddlebrown', linewidths=0.4, alpha=0.5, zorder=3)\n","cs_major = ax.contour(XX, YY, dem_filled_c, levels=major_levels,\n","                       colors='saddlebrown', linewidths=1.0, alpha=0.85, zorder=4)\n","ax.clabel(cs_major, inline=True, fontsize=6.5, fmt='%d m')\n","\n","overlay_boundaries(ax)\n","ax.text(0.02, 0.02, f\"Contour interval: {interval:.0f} m\",\n","        transform=ax.transAxes, fontsize=8, style='italic',\n","        bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n","finalize_and_save(fig, ax, utm_ext, \"08_contour.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  9. POUR POINTS ON DEM\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"[9/9] Pour points map...\")\n","fig, ax, utm_ext = base_axes(\"Pour Points (Snapped) on DEM\")\n","im = ax.imshow(\n","    DEM_ARR,\n","    extent=raster_extent(), origin='upper',\n","    cmap='terrain', alpha=0.65, zorder=1,\n","    vmin=np.nanpercentile(DEM_ARR, 2), vmax=np.nanpercentile(DEM_ARR, 98),\n",")\n","overlay_boundaries(ax)\n","\n","if POUR_POINTS_OK and gdf_pp is not None:\n","    gdf_pp.plot(ax=ax, color='red', markersize=80, zorder=20,\n","                label='Snapped pour points', marker='v', edgecolor='white', linewidth=0.8)\n","    for idx, r in gdf_pp.iterrows():\n","        label = str(r.get('basin_id', idx))\n","        ax.annotate(\n","            label,\n","            xy=(r.geometry.x, r.geometry.y),\n","            xytext=(5, 5), textcoords='offset points',\n","            fontsize=8, color='red', fontweight='bold',\n","            path_effects=[pe.withStroke(linewidth=2, foreground='white')],\n","        )\n","\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"3%\", pad=0.07)\n","cb  = plt.colorbar(im, cax=cax)\n","cb.set_label(\"Elevation (m)\", fontsize=10)\n","ax.legend(loc='lower left', fontsize=8, framealpha=0.85)\n","finalize_and_save(fig, ax, utm_ext, \"09_pour_points.png\")\n","\n","print(f\"\\nâœ… All 9 maps saved to: {MAPS_DIR}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3dfAq_eYMHn8","executionInfo":{"status":"ok","timestamp":1771996229798,"user_tz":-330,"elapsed":71737,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"99db3e47-4955-4fae-d471-92731e4c19e4"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","SECTION 4 â€” MAP GENERATION\n","============================================================\n","\n","[1/9] Elevation map...\n","  âœ… Saved: /content/morphometric_outputs/maps/01_elevation.png\n","[2/9] Slope map...\n","  âœ… Saved: /content/morphometric_outputs/maps/02_slope.png\n","[3/9] Aspect map...\n","  âœ… Saved: /content/morphometric_outputs/maps/03_aspect.png\n","[4/9] Flow direction map...\n","  âœ… Saved: /content/morphometric_outputs/maps/04_flow_direction.png\n","[5/9] Flow accumulation map...\n","  âœ… Saved: /content/morphometric_outputs/maps/05_flow_accumulation.png\n","[6/9] Stream order map...\n","  âœ… Saved: /content/morphometric_outputs/maps/06_stream_order.png\n","[7/9] Drainage density map...\n","  âœ… Saved: /content/morphometric_outputs/maps/07_drainage_density.png\n","[8/9] Contour map...\n","  âœ… Saved: /content/morphometric_outputs/maps/08_contour.png\n","[9/9] Pour points map...\n","  âœ… Saved: /content/morphometric_outputs/maps/09_pour_points.png\n","\n","âœ… All 9 maps saved to: /content/morphometric_outputs/maps/\n"]}]},{"cell_type":"markdown","source":["\"\"\"\n","=============================================================================\n","SECTION 5 â€” STATISTICAL ANALYSIS\n","=============================================================================\n","Descriptive stats, correlation matrix, VIF, PCA, clustering.\n","=============================================================================\n","\"\"\""],"metadata":{"id":"fM43-J2EM8QX"}},{"cell_type":"code","source":["print(\"=\" * 60)\n","print(\"SECTION 5 â€” STATISTICAL ANALYSIS\")\n","print(\"=\" * 60)\n","\n","# â”€â”€ Select numeric morphometric columns for analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","STAT_COLS = [\n","    'Area_km2', 'Perimeter_km', 'Basin_Length_km',\n","    'Drainage_Density_Dd', 'Stream_Frequency_Fs', 'Texture_Ratio_T',\n","    'Form_Factor_Ff', 'Elongation_Ratio_Re', 'Circularity_Ratio_Rc',\n","    'Compactness_Cc', 'LengthOverlandFlow_Lg', 'ChannelMaintenance_C',\n","    'Basin_Relief_H_m', 'Relief_Ratio_Rh', 'Relative_Relief',\n","    'Ruggedness_Rn', 'Melton_MRN', 'Hypsometric_HI',\n","    'Slope_Mean_deg', 'TRI_Mean', 'Rbm',\n","]\n","# Keep only columns that actually exist in df_master\n","STAT_COLS = [c for c in STAT_COLS if c in df_master.columns]\n","df_stat   = df_master[STAT_COLS].copy().astype(float)\n","df_stat.dropna(axis=1, how='all', inplace=True)\n","STAT_COLS = df_stat.columns.tolist()\n","\n","print(f\"  Parameters for analysis: {len(STAT_COLS)}\")\n","print(f\"  Subbasins: {len(df_stat)}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. DESCRIPTIVE STATISTICS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[A] Descriptive Statistics...\")\n","\n","desc_extra = df_stat.agg([\n","    'mean', 'median', 'std',\n","    lambda x: (x.std()/x.mean()*100) if x.mean() != 0 else np.nan,  # CV%\n","    lambda x: float(stats.skew(x.dropna())),\n","    lambda x: float(stats.kurtosis(x.dropna())),\n","])\n","desc_extra.index = ['Mean', 'Median', 'Std', 'CV%', 'Skewness', 'Kurtosis']\n","desc_full = pd.concat([df_stat.describe(), desc_extra])\n","\n","csv_path = os.path.join(TABLES_DIR, \"descriptive_statistics.csv\")\n","desc_full.to_csv(csv_path)\n","print(f\"  âœ… Saved: {csv_path}\")\n","print(desc_full.to_string())\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. CORRELATION MATRICES\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[B] Correlation Matrices (Pearson + Spearman)...\")\n","\n","# Pearson\n","corr_pearson  = df_stat.corr(method='pearson')\n","corr_spearman = df_stat.corr(method='spearman')\n","\n","# Heatmap â€” Pearson\n","fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n","for ax_corr, corr_mat, title in [\n","    (axes[0], corr_pearson,  \"Pearson Correlation\"),\n","    (axes[1], corr_spearman, \"Spearman Correlation\"),\n","]:\n","    mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n","    sns.heatmap(\n","        corr_mat, mask=mask, ax=ax_corr,\n","        cmap='RdYlBu_r', center=0, vmin=-1, vmax=1,\n","        annot=True, fmt='.2f', annot_kws={'size': 7},\n","        linewidths=0.5, square=True, cbar_kws={'shrink': 0.7},\n","    )\n","    ax_corr.set_title(title, fontsize=13, fontweight='bold')\n","    ax_corr.set_xticklabels(ax_corr.get_xticklabels(), rotation=45,\n","                              ha='right', fontsize=7.5)\n","    ax_corr.set_yticklabels(ax_corr.get_yticklabels(), fontsize=7.5)\n","\n","plt.tight_layout()\n","fig.savefig(os.path.join(PLOTS_DIR, \"correlation_heatmap.png\"), dpi=180, bbox_inches='tight')\n","plt.close(fig)\n","print(\"  âœ… Correlation heatmap saved\")\n","\n","corr_pearson.to_csv(os.path.join(TABLES_DIR, \"correlation_pearson.csv\"))\n","corr_spearman.to_csv(os.path.join(TABLES_DIR, \"correlation_spearman.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. VARIANCE INFLATION FACTOR\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[C] VIF Analysis...\")\n","# Require at least 2 samples per predictor â€” only feasible if n > n_params\n","if len(df_stat) > len(STAT_COLS):\n","    df_vif    = df_stat.dropna()\n","    X_vif     = sm.add_constant(df_vif)\n","    vif_data  = pd.DataFrame({\n","        'Feature': df_vif.columns,\n","        'VIF'    : [variance_inflation_factor(X_vif.values, i + 1)\n","                    for i in range(len(df_vif.columns))]\n","    }).sort_values('VIF', ascending=False)\n","    print(vif_data.to_string(index=False))\n","    vif_data.to_csv(os.path.join(TABLES_DIR, \"vif.csv\"), index=False)\n","else:\n","    print(f\"  âš ï¸  VIF skipped: n_basins ({len(df_stat)}) â‰¤ n_params ({len(STAT_COLS)})\")\n","    vif_data = pd.DataFrame(columns=['Feature', 'VIF'])\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  D. PCA\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[D] Principal Component Analysis...\")\n","\n","# Standardize\n","scaler    = StandardScaler()\n","df_scaled = df_stat.fillna(df_stat.median())\n","X_scaled  = scaler.fit_transform(df_scaled)\n","\n","pca      = PCA()\n","scores   = pca.fit_transform(X_scaled)\n","n_comp   = len(pca.explained_variance_ratio_)\n","\n","# Scree data\n","exp_var      = pca.explained_variance_ratio_ * 100\n","cum_var      = np.cumsum(exp_var)\n","n_comp_95    = np.searchsorted(cum_var, 95) + 1\n","\n","print(f\"  Total components: {n_comp}\")\n","print(f\"  Components to explain 95% variance: {n_comp_95}\")\n","for i in range(min(n_comp, 5)):\n","    print(f\"  PC{i+1}: {exp_var[i]:.2f}%  (cumulative: {cum_var[i]:.2f}%)\")\n","\n","# â”€â”€ Scree plot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n","\n","ax1.bar(range(1, n_comp + 1), exp_var, color='steelblue', alpha=0.8, label='Individual')\n","ax1.plot(range(1, n_comp + 1), cum_var, 'ro-', ms=5, label='Cumulative')\n","ax1.axhline(95, color='green', linestyle='--', lw=1.2, label='95% threshold')\n","ax1.set_xlabel(\"Principal Component\")\n","ax1.set_ylabel(\"Explained Variance (%)\")\n","ax1.set_title(\"Scree Plot â€” PCA\")\n","ax1.legend()\n","ax1.set_xlim(0.5, n_comp + 0.5)\n","\n","# â”€â”€ Biplot (PC1 vs PC2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","pc1_scores = scores[:, 0]\n","pc2_scores = scores[:, 1] if n_comp > 1 else np.zeros(len(scores))\n","\n","ax2.scatter(pc1_scores, pc2_scores, c='darkorange', s=120, zorder=5, edgecolors='black')\n","for i, bid in enumerate(df_stat.index):\n","    ax2.annotate(bid, (pc1_scores[i], pc2_scores[i]),\n","                 textcoords='offset points', xytext=(6, 3), fontsize=9)\n","\n","# Loading vectors\n","loadings = pca.components_.T\n","scale    = max(abs(pc1_scores).max(), abs(pc2_scores).max())\n","for j, feat in enumerate(STAT_COLS):\n","    ax2.annotate(\n","        '', xy=(loadings[j, 0] * scale * 0.5, loadings[j, 1] * scale * 0.5),\n","        xytext=(0, 0),\n","        arrowprops=dict(arrowstyle='->', color='royalblue', lw=1.2)\n","    )\n","    ax2.text(loadings[j, 0] * scale * 0.55, loadings[j, 1] * scale * 0.55,\n","             feat, fontsize=6.5, color='royalblue', ha='center')\n","\n","ax2.set_xlabel(f\"PC1 ({exp_var[0]:.1f}%)\")\n","ax2.set_ylabel(f\"PC2 ({exp_var[1]:.1f}%)\" if n_comp > 1 else \"PC2\")\n","ax2.set_title(\"PCA Biplot (PC1 vs PC2)\")\n","ax2.axhline(0, color='grey', lw=0.5, linestyle='--')\n","ax2.axvline(0, color='grey', lw=0.5, linestyle='--')\n","\n","plt.tight_layout()\n","fig.savefig(os.path.join(PLOTS_DIR, \"pca_scree_biplot.png\"), dpi=180, bbox_inches='tight')\n","plt.close(fig)\n","print(\"  âœ… PCA scree + biplot saved\")\n","\n","# Save loadings\n","df_loadings = pd.DataFrame(\n","    pca.components_[:min(n_comp, 5)].T,\n","    index=STAT_COLS,\n","    columns=[f\"PC{i+1}\" for i in range(min(n_comp, 5))],\n",")\n","df_loadings.to_csv(os.path.join(TABLES_DIR, \"pca_loadings.csv\"))\n","\n","df_scores_df = pd.DataFrame(\n","    scores[:, :min(n_comp, 5)],\n","    index=df_stat.index,\n","    columns=[f\"PC{i+1}\" for i in range(min(n_comp, 5))],\n",")\n","df_scores_df.to_csv(os.path.join(TABLES_DIR, \"pca_scores.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  E. CLUSTER ANALYSIS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[E] Cluster Analysis...\")\n","\n","if len(df_scaled) >= 3:\n","    # â”€â”€ Hierarchical â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    Z = linkage(X_scaled, method='ward')\n","    fig, ax = plt.subplots(figsize=(10, 5))\n","    dendrogram(Z, labels=df_stat.index.tolist(), ax=ax, color_threshold=0.7 * max(Z[:, 2]))\n","    ax.set_title(\"Hierarchical Clustering Dendrogram (Ward linkage)\")\n","    ax.set_xlabel(\"Subbasin\")\n","    ax.set_ylabel(\"Distance\")\n","    plt.tight_layout()\n","    fig.savefig(os.path.join(PLOTS_DIR, \"hierarchical_dendrogram.png\"), dpi=180, bbox_inches='tight')\n","    plt.close(fig)\n","\n","    # â”€â”€ K-means â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    k_range = range(2, min(len(df_scaled), 4))\n","    sil_scores = []\n","    for k in k_range:\n","        km  = KMeans(n_clusters=k, random_state=42, n_init=10)\n","        lbs = km.fit_predict(X_scaled)\n","        if len(set(lbs)) > 1:\n","            sil_scores.append(silhouette_score(X_scaled, lbs))\n","        else:\n","            sil_scores.append(-1)\n","\n","    best_k = k_range.start + int(np.argmax(sil_scores))\n","    print(f\"  Best k (silhouette): {best_k}\")\n","\n","    km_final = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n","    CLUSTER_LABELS = km_final.fit_predict(X_scaled)\n","    df_master['Cluster'] = CLUSTER_LABELS\n","\n","    # Visualise clusters in PC space\n","    fig, ax = plt.subplots(figsize=(8, 6))\n","    scatter = ax.scatter(\n","        pc1_scores, pc2_scores,\n","        c=CLUSTER_LABELS, cmap='Set1', s=180, edgecolors='black', zorder=5\n","    )\n","    for i, bid in enumerate(df_stat.index):\n","        ax.annotate(bid, (pc1_scores[i], pc2_scores[i]),\n","                    textcoords='offset points', xytext=(6, 3), fontsize=9)\n","    plt.colorbar(scatter, ax=ax, label='Cluster')\n","    ax.set_xlabel(f\"PC1 ({exp_var[0]:.1f}%)\")\n","    ax.set_ylabel(f\"PC2 ({exp_var[1]:.1f}%)\" if n_comp > 1 else \"PC2\")\n","    ax.set_title(f\"K-means Clustering (k={best_k}) in PCA Space\")\n","    plt.tight_layout()\n","    fig.savefig(os.path.join(PLOTS_DIR, \"kmeans_clusters.png\"), dpi=180, bbox_inches='tight')\n","    plt.close(fig)\n","    print(f\"  âœ… Cluster analysis complete (k={best_k})\")\n","else:\n","    print(f\"  âš ï¸  Clustering skipped: only {len(df_scaled)} basins (need â‰¥ 3)\")\n","    CLUSTER_LABELS = np.zeros(len(df_stat), dtype=int)\n","    df_master['Cluster'] = CLUSTER_LABELS\n","\n","print(\"\\nâœ… SECTION 5 complete.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kD2-r60LNB-e","executionInfo":{"status":"ok","timestamp":1771996237039,"user_tz":-330,"elapsed":7237,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"e662696f-3235-4a94-e0f7-04ec0f32e263"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","SECTION 5 â€” STATISTICAL ANALYSIS\n","============================================================\n","  Parameters for analysis: 21\n","  Subbasins: 3\n","\n","[A] Descriptive Statistics...\n","  âœ… Saved: /content/morphometric_outputs/tables/descriptive_statistics.csv\n","          Area_km2  Perimeter_km  Basin_Length_km  Drainage_Density_Dd  Stream_Frequency_Fs  Texture_Ratio_T  Form_Factor_Ff  Elongation_Ratio_Re  Circularity_Ratio_Rc  Compactness_Cc  LengthOverlandFlow_Lg  ChannelMaintenance_C  Basin_Relief_H_m  Relief_Ratio_Rh  Relative_Relief  Ruggedness_Rn  Melton_MRN  Hypsometric_HI  Slope_Mean_deg  TRI_Mean     Rbm\n","count       3.0000        3.0000           3.0000               3.0000               3.0000           3.0000          3.0000               3.0000                3.0000          3.0000                 3.0000                3.0000            3.0000           3.0000           3.0000         3.0000      3.0000          3.0000          3.0000    3.0000  3.0000\n","mean      104.0491       63.4394           9.3480               3.0925              11.6309          17.9940          1.1280               1.1984                0.3081          1.8017                 0.1619                0.3238          953.0000           0.1089          16.0700         2.9472    102.5643          0.2619         13.3023   19.9627  2.0260\n","std        53.5732       18.4148           2.6993               0.1481               0.8170           4.8887          0.0000               0.0000                0.0034          0.0101                 0.0076                0.0152            0.0000           0.0365           5.4390         0.1411     34.3344          0.0000          1.0159    2.0587  0.4280\n","min        45.1921       42.7535           6.3296               2.9794              10.7889          12.3499          1.1280               1.1984                0.3042          1.7941                 0.1534                0.3067          953.0000           0.0827          12.2108         2.8394     77.8201          0.2619         12.1300   17.6630  1.7626\n","25%        81.0890       56.1362           8.2568               3.0088              11.2362          16.5406          1.1280               1.1984                0.3068          1.7959                 0.1590                0.3179          953.0000           0.0881          12.9596         2.8674     82.9651          0.2619         12.9910   19.1270  1.7791\n","50%       116.9859       69.5188          10.1839               3.0381              11.6835          20.7314          1.1280               1.1984                0.3094          1.7978                 0.1646                0.3292          953.0000           0.0936          13.7085         2.8953     88.1102          0.2619         13.8520   20.5910  1.7955\n","75%       133.4777       73.7823          10.8572               3.1491              12.0519          20.8161          1.1280               1.1984                0.3100          1.8054                 0.1662                0.3324          953.0000           0.1221          17.9995         3.0011    114.9364          0.2619         13.8885   21.1125  2.1577\n","max       149.9694       78.0458          11.5305               3.2601              12.4203          20.9008          1.1280               1.1984                0.3107          1.8131                 0.1678                0.3356          953.0000           0.1506          22.2906         3.1069    141.7626          0.2619         13.9250   21.6340  2.5199\n","Mean      104.0491       63.4394           9.3480               3.0925              11.6309          17.9940          1.1280               1.1984                0.3081          1.8017                 0.1619                0.3238          953.0000           0.1089          16.0700         2.9472    102.5643          0.2619         13.3023   19.9627  2.0260\n","Median    116.9859       69.5188          10.1839               3.0381              11.6835          20.7314          1.1280               1.1984                0.3094          1.7978                 0.1646                0.3292          953.0000           0.0936          13.7085         2.8953     88.1102          0.2619         13.8520   20.5910  1.7955\n","Std        53.5732       18.4148           2.6993               0.1481               0.8170           4.8887          0.0000               0.0000                0.0034          0.0101                 0.0076                0.0152            0.0000           0.0365           5.4390         0.1411     34.3344          0.0000          1.0159    2.0587  0.4280\n","CV%        51.4884       29.0275          28.8760               4.7875               7.0241          27.1684          0.0000               0.0000                1.1164          0.5591                 4.6694                4.6873            0.0000          33.4763          33.8459         4.7876     33.4760          0.0000          7.6372   10.3128 21.1276\n","Skewness   -0.4178       -0.5404          -0.5143               0.5841              -0.1178          -0.7062             NaN                  NaN               -0.5952          0.6013                -0.5673               -0.5683               NaN           0.6363           0.6473         0.5843      0.6363             NaN         -0.7030   -0.5085  0.7024\n","Kurtosis   -1.5000       -1.5000          -1.5000              -1.5000              -1.5000          -1.5000             NaN                  NaN               -1.5000         -1.5000                -1.5000               -1.5000               NaN          -1.5000          -1.5000        -1.5000     -1.5000             NaN         -1.5000   -1.5000 -1.5000\n","\n","[B] Correlation Matrices (Pearson + Spearman)...\n","  âœ… Correlation heatmap saved\n","\n","[C] VIF Analysis...\n","  âš ï¸  VIF skipped: n_basins (3) â‰¤ n_params (21)\n","\n","[D] Principal Component Analysis...\n","  Total components: 3\n","  Components to explain 95% variance: 2\n","  PC1: 53.84%  (cumulative: 53.84%)\n","  PC2: 46.16%  (cumulative: 100.00%)\n","  PC3: 0.00%  (cumulative: 100.00%)\n","  âœ… PCA scree + biplot saved\n","\n","[E] Cluster Analysis...\n","  Best k (silhouette): 2\n","  âœ… Cluster analysis complete (k=2)\n","\n","âœ… SECTION 5 complete.\n"]}]},{"cell_type":"markdown","source":["=============================================================================\n","SECTION 6 â€” WATERSHED PRIORITIZATION FRAMEWORK\n","=============================================================================\n","Method 1: Compound Parameter Ranking\n","Method 2: Entropy Weight Method\n","Method 3: PCA-Based Priority\n","Kendall's tau comparison + bar charts.\n","============================================================================="],"metadata":{"id":"xYHbyPNdNVuf"}},{"cell_type":"code","source":["print(\"=\" * 60)\n","print(\"SECTION 6 â€” WATERSHED PRIORITIZATION\")\n","print(\"=\" * 60)\n","\n","# â”€â”€ Erosion-sensitive parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# Direct relation with erosion (higher = more erosion prone â†’ higher rank = worse)\n","DIRECT_PARAMS = {\n","    'Drainage_Density_Dd' : 'Dd',\n","    'Stream_Frequency_Fs' : 'Fs',\n","    'Rbm'                 : 'Rb',\n","    'Ruggedness_Rn'       : 'Rn',\n","    'Relief_Ratio_Rh'     : 'Rh',\n","    'Hypsometric_HI'      : 'HI',\n","    'Melton_MRN'          : 'MRN',\n","}\n","# Inverse relation (higher = less erosion prone â†’ lower rank = worse)\n","INVERSE_PARAMS = {\n","    'Elongation_Ratio_Re' : 'Re',\n","    'Circularity_Ratio_Rc': 'Rc',\n","    'Form_Factor_Ff'      : 'Ff',\n","}\n","\n","# Keep only params actually in df_master\n","DIRECT_AVAIL  = {k: v for k, v in DIRECT_PARAMS.items()  if k in df_master.columns}\n","INVERSE_AVAIL = {k: v for k, v in INVERSE_PARAMS.items() if k in df_master.columns}\n","ALL_PRIORITY_COLS = list(DIRECT_AVAIL.keys()) + list(INVERSE_AVAIL.keys())\n","\n","df_pri = df_master[ALL_PRIORITY_COLS].copy().astype(float).fillna(df_master[ALL_PRIORITY_COLS].median())\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  METHOD 1 â€” COMPOUND PARAMETER RANKING\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[Method 1] Compound Parameter Ranking...\")\n","\n","df_rank = pd.DataFrame(index=df_pri.index)\n","\n","for col in DIRECT_AVAIL:\n","    # rank: highest value â†’ rank 1 (most erosion prone)\n","    df_rank[col] = df_pri[col].rank(ascending=False, method='min')\n","\n","for col in INVERSE_AVAIL:\n","    # rank: lowest value â†’ rank 1 (most erosion prone)\n","    df_rank[col] = df_pri[col].rank(ascending=True, method='min')\n","\n","df_rank['CF_M1'] = df_rank.mean(axis=1)\n","df_rank['Rank_M1'] = df_rank['CF_M1'].rank(ascending=True, method='min').astype(int)\n","\n","# Priority classes\n","n = len(df_rank)\n","thresholds = np.percentile(df_rank['CF_M1'], [33, 66])\n","df_rank['Priority_M1'] = df_rank['CF_M1'].apply(\n","    lambda x: 'High' if x <= thresholds[0] else ('Moderate' if x <= thresholds[1] else 'Low')\n",")\n","\n","print(df_rank[['CF_M1', 'Rank_M1', 'Priority_M1']].to_string())\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  METHOD 2 â€” ENTROPY WEIGHT METHOD\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[Method 2] Entropy Weight Method...\")\n","\n","def entropy_weight_score(df, direct_cols, inverse_cols):\n","    \"\"\"\n","    1. Normalise each parameter (0â€“1)\n","    2. Compute Shannon entropy for each parameter\n","    3. Derive weights from entropy divergence\n","    4. Compute weighted score per subbasin\n","    \"\"\"\n","    df_norm = pd.DataFrame(index=df.index)\n","    for col in direct_cols:\n","        mn, mx = df[col].min(), df[col].max()\n","        df_norm[col] = (df[col] - mn) / (mx - mn + 1e-12)  # 0=best 1=worst\n","    for col in inverse_cols:\n","        mn, mx = df[col].min(), df[col].max()\n","        # Invert: low value = high risk â†’ normalise inverted\n","        df_norm[col] = 1 - (df[col] - mn) / (mx - mn + 1e-12)\n","\n","    # Entropy for each criterion\n","    n, m   = df_norm.shape\n","    weights = []\n","    for col in df_norm.columns:\n","        p = df_norm[col] / (df_norm[col].sum() + 1e-12)\n","        p = p.clip(lower=1e-12)  # avoid log(0)\n","        e = -np.sum(p * np.log(p)) / np.log(n + 1e-12)\n","        d = 1 - e\n","        weights.append(d)\n","\n","    weights = np.array(weights)\n","    weights /= (weights.sum() + 1e-12)   # normalise to sum=1\n","\n","    # Weighted score\n","    score = (df_norm.values * weights).sum(axis=1)\n","    return score, dict(zip(df_norm.columns, weights))\n","\n","\n","score_m2, ew_weights = entropy_weight_score(\n","    df_pri, list(DIRECT_AVAIL.keys()), list(INVERSE_AVAIL.keys())\n",")\n","df_rank['Score_M2'] = score_m2\n","df_rank['Rank_M2']  = pd.Series(score_m2, index=df_pri.index).rank(\n","    ascending=False, method='min'\n",").astype(int)\n","\n","thresh_m2 = np.percentile(score_m2, [66, 33])\n","df_rank['Priority_M2'] = df_rank['Score_M2'].apply(\n","    lambda x: 'High' if x >= thresh_m2[0] else ('Moderate' if x >= thresh_m2[1] else 'Low')\n",")\n","\n","print(\"  Entropy weights:\")\n","for k, w in sorted(ew_weights.items(), key=lambda x: -x[1]):\n","    print(f\"    {k}: {w:.4f}\")\n","print(df_rank[['Score_M2', 'Rank_M2', 'Priority_M2']].to_string())\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  METHOD 3 â€” PCA-BASED PRIORITY\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[Method 3] PCA-Based Priority...\")\n","\n","# Re-run PCA on priority parameters only\n","scaler_p   = StandardScaler()\n","X_p        = scaler_p.fit_transform(df_pri.fillna(df_pri.median()))\n","pca_p      = PCA()\n","scores_p   = pca_p.fit_transform(X_p)\n","exp_var_p  = pca_p.explained_variance_ratio_\n","\n","# Composite score: weighted sum of PC scores by explained variance\n","n_retain = min(3, len(exp_var_p))\n","weights_p = exp_var_p[:n_retain] / exp_var_p[:n_retain].sum()\n","\n","# Sign convention: check if PC1 aligns with erosion risk\n","# (higher PC1 loading on Dd/Rn = higher risk = positive score)\n","pc1_loadings = pd.Series(pca_p.components_[0], index=ALL_PRIORITY_COLS)\n","direct_sign  = np.sign(pc1_loadings[list(DIRECT_AVAIL.keys())].mean())\n","if direct_sign < 0:\n","    scores_p = -scores_p   # flip sign\n","\n","pca_composite = (scores_p[:, :n_retain] * weights_p).sum(axis=1)\n","df_rank['Score_M3'] = pca_composite\n","df_rank['Rank_M3']  = pd.Series(pca_composite, index=df_pri.index).rank(\n","    ascending=False, method='min'\n",").astype(int)\n","\n","thresh_m3 = np.percentile(pca_composite, [66, 33])\n","df_rank['Priority_M3'] = df_rank['Score_M3'].apply(\n","    lambda x: 'High' if x >= thresh_m3[0] else ('Moderate' if x >= thresh_m3[1] else 'Low')\n",")\n","print(df_rank[['Score_M3', 'Rank_M3', 'Priority_M3']].to_string())\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  COMPARISON â€” KENDALL's TAU\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[Comparison] Kendall's tau agreement analysis...\")\n","\n","r12, p12 = stats.kendalltau(df_rank['Rank_M1'], df_rank['Rank_M2'])\n","r13, p13 = stats.kendalltau(df_rank['Rank_M1'], df_rank['Rank_M3'])\n","r23, p23 = stats.kendalltau(df_rank['Rank_M2'], df_rank['Rank_M3'])\n","\n","df_kendall = pd.DataFrame({\n","    'Comparison': ['M1 vs M2', 'M1 vs M3', 'M2 vs M3'],\n","    'Kendall_tau': [r12, r13, r23],\n","    'p_value'    : [p12, p13, p23],\n","    'Agreement'  : ['Strong' if abs(r) > 0.7 else 'Moderate' if abs(r) > 0.4 else 'Weak'\n","                    for r in [r12, r13, r23]],\n","})\n","print(df_kendall.to_string(index=False))\n","\n","# â”€â”€ Ranking comparison bar chart â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","\n","basins  = df_rank.index.tolist()\n","x       = np.arange(len(basins))\n","width   = 0.28\n","\n","ax1.bar(x - width, df_rank['Rank_M1'], width, label='Method 1 (Compound)',  color='steelblue')\n","ax1.bar(x,         df_rank['Rank_M2'], width, label='Method 2 (Entropy)',   color='darkorange')\n","ax1.bar(x + width, df_rank['Rank_M3'], width, label='Method 3 (PCA-based)', color='green')\n","ax1.set_xticks(x)\n","ax1.set_xticklabels(basins)\n","ax1.set_ylabel(\"Rank (1 = Highest Priority)\")\n","ax1.set_title(\"Prioritization Rank Comparison Across Methods\")\n","ax1.legend()\n","ax1.invert_yaxis()   # rank 1 at top\n","\n","# Priority colour map\n","priority_map = {'High': '#d73027', 'Moderate': '#fee090', 'Low': '#4575b4'}\n","for i, bid in enumerate(basins):\n","    for j, (col, method) in enumerate([\n","        ('Priority_M1', 'M1'), ('Priority_M2', 'M2'), ('Priority_M3', 'M3')\n","    ]):\n","        ax2.bar(i * 4 + j, 1,\n","                color=priority_map.get(df_rank.loc[bid, col], 'grey'),\n","                edgecolor='black', linewidth=0.7)\n","        ax2.text(i * 4 + j, 0.5, df_rank.loc[bid, col][:1],\n","                 ha='center', va='center', fontsize=9, fontweight='bold')\n","\n","ax2.set_xticks([i * 4 + 1 for i in range(len(basins))])\n","ax2.set_xticklabels(basins)\n","ax2.set_title(\"Priority Class by Method\")\n","legend_patches = [mpatches.Patch(color=v, label=k) for k, v in priority_map.items()]\n","ax2.legend(handles=legend_patches, loc='upper right')\n","ax2.set_yticks([])\n","\n","plt.tight_layout()\n","fig.savefig(os.path.join(PLOTS_DIR, \"prioritization_comparison.png\"), dpi=180, bbox_inches='tight')\n","plt.close(fig)\n","\n","# â”€â”€ Save outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","ranking_table = df_rank[['CF_M1','Rank_M1','Priority_M1',\n","                          'Score_M2','Rank_M2','Priority_M2',\n","                          'Score_M3','Rank_M3','Priority_M3']].copy()\n","ranking_table.to_csv(os.path.join(TABLES_DIR, \"prioritization_ranking.csv\"))\n","df_kendall.to_csv(os.path.join(TABLES_DIR, \"kendall_tau.csv\"), index=False)\n","\n","# Save priority shapefile\n","gdf_priority = gdf_sub.merge(\n","    ranking_table.reset_index(), on='basin_id', how='left'\n",")\n","gdf_priority.to_file(os.path.join(SHAPES_DIR, \"subbasins_priority.shp\"))\n","\n","print(f\"\\n  âœ… Priority shapefile saved: {SHAPES_DIR}subbasins_priority.shp\")\n","print(\"\\nâœ… SECTION 6 complete.\")\n","print(\"\\n  FINAL RANKING TABLE:\")\n","print(ranking_table.to_string())"],"metadata":{"id":"ubHL8PgpNG_U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771996427851,"user_tz":-330,"elapsed":994,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"473d16af-87a4-475a-c924-76b6ea4c44dc"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","SECTION 6 â€” WATERSHED PRIORITIZATION\n","============================================================\n","\n","[Method 1] Compound Parameter Ranking...\n","          CF_M1  Rank_M1 Priority_M1\n","basin_id                            \n","SB1      1.2000        1        High\n","SB2      1.6000        2    Moderate\n","SB3      2.3000        3         Low\n","\n","[Method 2] Entropy Weight Method...\n","  Entropy weights:\n","    Hypsometric_HI: 0.1898\n","    Rbm: 0.1599\n","    Melton_MRN: 0.1202\n","    Relief_Ratio_Rh: 0.1202\n","    Circularity_Ratio_Rc: 0.1119\n","    Ruggedness_Rn: 0.1102\n","    Drainage_Density_Dd: 0.1102\n","    Stream_Frequency_Fs: 0.0775\n","    Elongation_Ratio_Re: 0.0000\n","    Form_Factor_Ff: 0.0000\n","          Score_M2  Rank_M2 Priority_M2\n","basin_id                               \n","SB1         0.6084        1        High\n","SB2         0.3360        2    Moderate\n","SB3         0.0224        3         Low\n","\n","[Method 3] PCA-Based Priority...\n","          Score_M3  Rank_M3 Priority_M3\n","basin_id                               \n","SB1         2.1533        1        High\n","SB2        -0.5111        2    Moderate\n","SB3        -1.6422        3         Low\n","\n","[Comparison] Kendall's tau agreement analysis...\n","Comparison  Kendall_tau  p_value Agreement\n","  M1 vs M2       1.0000   0.3333    Strong\n","  M1 vs M3       1.0000   0.3333    Strong\n","  M2 vs M3       1.0000   0.3333    Strong\n","\n","  âœ… Priority shapefile saved: /content/morphometric_outputs/shapefiles/subbasins_priority.shp\n","\n","âœ… SECTION 6 complete.\n","\n","  FINAL RANKING TABLE:\n","          CF_M1  Rank_M1 Priority_M1  Score_M2  Rank_M2 Priority_M2  Score_M3  Rank_M3 Priority_M3\n","basin_id                                                                                          \n","SB1      1.2000        1        High    0.6084        1        High    2.1533        1        High\n","SB2      1.6000        2    Moderate    0.3360        2    Moderate   -0.5111        2    Moderate\n","SB3      2.3000        3         Low    0.0224        3         Low   -1.6422        3         Low\n"]}]},{"cell_type":"markdown","source":["=============================================================================\n","SECTION 7 â€” ADVANCED PLOTLY INTERACTIVE VISUALIZATIONS\n","=============================================================================\n","All figures saved as interactive HTML + static PNG.\n","=============================================================================\n","\"\"\""],"metadata":{"id":"FiuXP0jNNzfG"}},{"cell_type":"code","source":["print(\"=\" * 60)\n","print(\"SECTION 7 â€” PLOTLY INTERACTIVE VISUALIZATION SUITE\")\n","print(\"=\" * 60)\n","\n","HTML_DIR = os.path.join(PLOTS_DIR, \"html/\")\n","os.makedirs(HTML_DIR, exist_ok=True)\n","\n","\n","def save_fig(fig, name):\n","    \"\"\"Save Plotly figure as HTML and static PNG.\"\"\"\n","    html_path = os.path.join(HTML_DIR, f\"{name}.html\")\n","    fig.write_html(html_path, include_plotlyjs='cdn')\n","    print(f\"  âœ… {name}.html\")\n","    return html_path\n","\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  1. HORTON'S LAWS â€” Stream Number & Stream Length\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[1] Horton's Law plots...\")\n","\n","for bid, df_lin in LINEAR_PER_ORDER.items():\n","    if df_lin.empty or len(df_lin) < 2:\n","        continue\n","    orders   = df_lin['order'].values\n","    Nu_vals  = df_lin['Nu'].values.astype(float)\n","    Lu_vals  = (df_lin['Lu'].values / 1000).astype(float)  # km\n","\n","    # Regression on log scale (exclude zeros)\n","    mask_n = Nu_vals > 0\n","    log_Nu = np.log10(Nu_vals[mask_n])\n","    log_u  = np.log10(orders[mask_n])\n","    if len(log_u) > 1:\n","        slope_n, intercept_n, r_n, p_n, _ = stats.linregress(log_u, log_Nu)\n","        r2_n = r_n ** 2\n","    else:\n","        slope_n, intercept_n, r2_n = 0, 0, 0\n","\n","    mask_l = Lu_vals > 0\n","    log_Lu = np.log10(Lu_vals[mask_l])\n","    if len(log_u[mask_l[:len(log_u)]]) > 1:\n","        slope_l, intercept_l, r_l, _, _ = stats.linregress(\n","            log_u[:len(log_Lu)], log_Lu\n","        )\n","        r2_l = r_l ** 2\n","    else:\n","        slope_l, intercept_l, r2_l = 0, 0, 0\n","\n","    fig = make_subplots(rows=1, cols=2,\n","                        subplot_titles=[\n","                            f\"Stream Number Law â€” {bid}\",\n","                            f\"Stream Length Law â€” {bid}\"\n","                        ])\n","\n","    # Stream number\n","    fig.add_trace(go.Scatter(\n","        x=orders[mask_n], y=Nu_vals[mask_n], mode='markers+lines',\n","        name='Stream Number', marker=dict(size=10, color='royalblue'),\n","        hovertemplate='Order %{x}: %{y} streams',\n","    ), row=1, col=1)\n","    fit_x = np.linspace(orders.min(), orders.max(), 50)\n","    fit_y = 10 ** (intercept_n + slope_n * np.log10(fit_x))\n","    fig.add_trace(go.Scatter(\n","        x=fit_x, y=fit_y, mode='lines',\n","        name=f'Regression (RÂ²={r2_n:.3f})',\n","        line=dict(color='firebrick', dash='dash'),\n","    ), row=1, col=1)\n","\n","    # Stream length\n","    fig.add_trace(go.Scatter(\n","        x=orders[mask_l], y=Lu_vals[mask_l], mode='markers+lines',\n","        name='Stream Length (km)', marker=dict(size=10, color='darkorange'),\n","        hovertemplate='Order %{x}: %{y:.2f} km',\n","    ), row=1, col=2)\n","    if r2_l > 0:\n","        fit_yl = 10 ** (intercept_l + slope_l * np.log10(fit_x))\n","        fig.add_trace(go.Scatter(\n","            x=fit_x, y=fit_yl, mode='lines',\n","            name=f'Regression (RÂ²={r2_l:.3f})',\n","            line=dict(color='green', dash='dash'),\n","        ), row=1, col=2)\n","\n","    fig.update_xaxes(type='log', title_text='Stream Order (log)', row=1, col=1)\n","    fig.update_yaxes(type='log', title_text='Stream Number (log)', row=1, col=1)\n","    fig.update_xaxes(type='log', title_text='Stream Order (log)', row=1, col=2)\n","    fig.update_yaxes(type='log', title_text='Stream Length km (log)', row=1, col=2)\n","    fig.update_layout(title=f\"Horton's Laws â€” {bid}\", template='plotly_white',\n","                      height=500, showlegend=True)\n","    save_fig(fig, f\"01_hortons_law_{bid}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  2. RADAR CHART â€” Morphometric Signature per Subbasin\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[2] Radar charts...\")\n","\n","radar_params = [\n","    'Drainage_Density_Dd', 'Stream_Frequency_Fs', 'Form_Factor_Ff',\n","    'Elongation_Ratio_Re', 'Circularity_Ratio_Rc', 'Ruggedness_Rn',\n","    'Hypsometric_HI', 'Relief_Ratio_Rh', 'Rbm',\n","]\n","radar_params = [p for p in radar_params if p in df_master.columns]\n","\n","df_radar = df_master[radar_params].copy().astype(float)\n","# Normalise 0-1 for radar\n","df_radar_norm = (df_radar - df_radar.min()) / (df_radar.max() - df_radar.min() + 1e-12)\n","\n","fig = go.Figure()\n","categories = [p.split('_')[-1] for p in radar_params]\n","colors_r   = px.colors.qualitative.Set2\n","\n","for i, (bid, row) in enumerate(df_radar_norm.iterrows()):\n","    vals = row.tolist()\n","    vals += [vals[0]]  # close polygon\n","    fig.add_trace(go.Scatterpolar(\n","        r=vals, theta=categories + [categories[0]],\n","        fill='toself', name=bid,\n","        line_color=colors_r[i % len(colors_r)],\n","        opacity=0.6,\n","        hovertemplate=bid + '<br>%{theta}: %{r:.3f}',\n","    ))\n","\n","fig.update_layout(\n","    polar=dict(radialaxis=dict(visible=True, range=[0, 1])),\n","    title=\"Morphometric Signature Radar Chart â€” All Subbasins\",\n","    template='plotly_white', height=600,\n",")\n","save_fig(fig, \"02_radar_morphometric\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  3. SCATTER MATRIX\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[3] Scatter matrix...\")\n","scatter_cols = [c for c in ['Drainage_Density_Dd', 'Stream_Frequency_Fs',\n","                              'Elongation_Ratio_Re', 'Basin_Relief_H_m',\n","                              'Ruggedness_Rn', 'Hypsometric_HI']\n","                if c in df_master.columns]\n","df_sc = df_master[scatter_cols].reset_index()\n","fig   = px.scatter_matrix(\n","    df_sc, dimensions=scatter_cols, color='basin_id',\n","    title=\"Scatter Matrix â€” Key Morphometric Parameters\",\n","    labels={c: c.split('_')[-1] for c in scatter_cols},\n","    template='plotly_white',\n",")\n","fig.update_traces(diagonal_visible=False, showupperhalf=False)\n","save_fig(fig, \"03_scatter_matrix\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  4. 3D SCATTER â€” Dd vs Relief vs Area\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[4] 3D scatter...\")\n","if all(c in df_master.columns for c in ['Drainage_Density_Dd', 'Basin_Relief_H_m', 'Area_km2']):\n","    df3d = df_master[['Drainage_Density_Dd', 'Basin_Relief_H_m', 'Area_km2']].reset_index()\n","    fig  = px.scatter_3d(\n","        df3d, x='Drainage_Density_Dd', y='Basin_Relief_H_m', z='Area_km2',\n","        color='basin_id', text='basin_id',\n","        title=\"3D Scatter: Drainage Density vs Relief vs Area\",\n","        labels={'Drainage_Density_Dd': 'Dd (km/kmÂ²)',\n","                'Basin_Relief_H_m': 'Relief (m)',\n","                'Area_km2': 'Area (kmÂ²)'},\n","        template='plotly_white', size_max=18,\n","    )\n","    save_fig(fig, \"04_3d_scatter\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  5. HISTOGRAM DISTRIBUTIONS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[5] Histogram distributions...\")\n","hist_cols = [c for c in STAT_COLS if c in df_master.columns][:9]\n","fig = make_subplots(rows=3, cols=3, subplot_titles=hist_cols)\n","for i, col in enumerate(hist_cols):\n","    r, c_idx = divmod(i, 3)\n","    fig.add_trace(\n","        go.Histogram(x=df_master[col].dropna(), name=col,\n","                     marker_color=px.colors.qualitative.Set1[i % 9],\n","                     nbinsx=10),\n","        row=r+1, col=c_idx+1,\n","    )\n","fig.update_layout(title=\"Parameter Distributions\", template='plotly_white',\n","                  height=800, showlegend=False)\n","save_fig(fig, \"05_histograms\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  6. BOX PLOTS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[6] Box plots...\")\n","df_melt = df_master[STAT_COLS[:10]].reset_index().melt(id_vars='basin_id')\n","fig     = px.box(\n","    df_melt, x='variable', y='value', color='variable',\n","    title=\"Box Plot â€” Morphometric Parameters\",\n","    template='plotly_white', points='all',\n","    labels={'variable': 'Parameter', 'value': 'Value'},\n",")\n","fig.update_xaxes(tickangle=45)\n","save_fig(fig, \"06_boxplots\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  7. HYPSOMETRIC CURVES\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[7] Hypsometric curves...\")\n","if HYPS:\n","    fig = go.Figure()\n","    colors_h = px.colors.qualitative.Plotly\n","    for i, (bid, (rel_area, rel_elev)) in enumerate(HYPS.items()):\n","        hi_val = df_master.loc[bid, 'Hypsometric_HI'] if 'Hypsometric_HI' in df_master.columns else np.nan\n","        fig.add_trace(go.Scatter(\n","            x=rel_area, y=rel_elev, mode='lines',\n","            name=f\"{bid} (HI={hi_val:.3f})\" if not np.isnan(hi_val) else bid,\n","            line=dict(color=colors_h[i % len(colors_h)], width=2),\n","            hovertemplate='Rel. Area: %{x:.2f}<br>Rel. Elev: %{y:.2f}',\n","        ))\n","    # Reference lines\n","    fig.add_trace(go.Scatter(\n","        x=[0, 1], y=[0.5, 0.5], mode='lines',\n","        name='HI = 0.5 (Equilibrium)', line=dict(dash='dash', color='grey'),\n","    ))\n","    fig.update_layout(\n","        title=\"Hypsometric Curves â€” All Subbasins\",\n","        xaxis_title=\"Relative Area (a/A)\",\n","        yaxis_title=\"Relative Elevation (h/H)\",\n","        template='plotly_white', height=550,\n","    )\n","    save_fig(fig, \"07_hypsometric_curves\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  8. PLOTLY CORRELATION HEATMAP\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[8] Plotly correlation heatmap...\")\n","fig = go.Figure(go.Heatmap(\n","    z=corr_pearson.values,\n","    x=corr_pearson.columns.tolist(),\n","    y=corr_pearson.index.tolist(),\n","    colorscale='RdYlBu', zmid=0, zmin=-1, zmax=1,\n","    text=np.round(corr_pearson.values, 2).astype(str),\n","    texttemplate='%{text}', textfont_size=8,\n","    hovertemplate='%{y} vs %{x}: %{z:.3f}',\n","))\n","fig.update_layout(title=\"Pearson Correlation Matrix (Interactive)\",\n","                  template='plotly_white', height=700, width=800)\n","save_fig(fig, \"08_correlation_heatmap\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  9. PARALLEL COORDINATE PLOT\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[9] Parallel coordinate plot...\")\n","par_cols = [c for c in STAT_COLS if c in df_master.columns][:8]\n","df_par   = df_master[par_cols].reset_index()\n","df_par['basin_num'] = range(len(df_par))\n","fig = px.parallel_coordinates(\n","    df_par, color='basin_num', dimensions=par_cols,\n","    color_continuous_scale=px.colors.diverging.Tealrose,\n","    title=\"Parallel Coordinate Plot â€” Morphometric Parameters\",\n","    labels={c: c.replace('_', ' ') for c in par_cols},\n",")\n","save_fig(fig, \"09_parallel_coordinates\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  10. BUBBLE PLOT â€” Area vs Dd sized by Relief\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[10] Bubble plot...\")\n","if all(c in df_master.columns for c in ['Area_km2', 'Drainage_Density_Dd', 'Basin_Relief_H_m']):\n","    df_bub = df_master[['Area_km2', 'Drainage_Density_Dd', 'Basin_Relief_H_m']].reset_index()\n","    fig    = px.scatter(\n","        df_bub, x='Area_km2', y='Drainage_Density_Dd',\n","        size='Basin_Relief_H_m', color='basin_id', text='basin_id',\n","        title=\"Area vs Drainage Density (size = Basin Relief)\",\n","        labels={'Area_km2': 'Area (kmÂ²)',\n","                'Drainage_Density_Dd': 'Drainage Density (km/kmÂ²)',\n","                'Basin_Relief_H_m': 'Relief (m)'},\n","        template='plotly_white', size_max=50,\n","    )\n","    save_fig(fig, \"10_bubble_area_dd_relief\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  11. PRIORITY MAP â€” Interactive Plotly choropleth-style\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[11] Priority class map...\")\n","priority_color = {'High': '#d73027', 'Moderate': '#fee090', 'Low': '#4575b4'}\n","fig = go.Figure()\n","\n","for _, row in gdf_priority.iterrows():\n","    bid  = row['basin_id']\n","    pri  = row.get('Priority_M1', 'Unknown')\n","    col  = priority_color.get(pri, 'grey')\n","    geom = row.geometry\n","\n","    if geom.geom_type == 'Polygon':\n","        geoms = [geom]\n","    else:\n","        geoms = list(geom.geoms)\n","\n","    for g in geoms:\n","        coords = np.array(g.exterior.coords)\n","        fig.add_trace(go.Scatter(\n","            x=coords[:, 0], y=coords[:, 1],\n","            fill='toself', fillcolor=col,\n","            line=dict(color='black', width=1.5),\n","            name=f\"{bid} ({pri})\",\n","            opacity=0.75,\n","            hovertemplate=(\n","                f\"<b>{bid}</b><br>\"\n","                f\"Priority: {pri}<br>\"\n","                f\"Rank M1: {row.get('Rank_M1','â€”')}<br>\"\n","                f\"Rank M2: {row.get('Rank_M2','â€”')}<br>\"\n","                f\"Rank M3: {row.get('Rank_M3','â€”')}<br>\"\n","                f\"Dd: {row.get('Drainage_Density_Dd','â€”')}\"\n","            ),\n","        ))\n","\n","fig.update_layout(\n","    title=\"Watershed Priority Classification Map (Method 1 â€” Compound Ranking)\",\n","    xaxis=dict(title=\"Easting (m)\", scaleanchor='y'),\n","    yaxis=dict(title=\"Northing (m)\"),\n","    template='plotly_white', height=650,\n","    showlegend=True,\n",")\n","save_fig(fig, \"11_priority_map\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  12. ELEVATION PROFILE (Main Channel)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[12] Elevation profiles...\")\n","\n","def extract_stream_profile(stream_gdf, dem_path, basin_id, n_points=200):\n","    \"\"\"Sample DEM along the longest stream segment in a basin.\"\"\"\n","    segs = stream_gdf[stream_gdf.get('basin_id', stream_gdf.index) == basin_id]\n","    if len(segs) == 0:\n","        return None, None, None\n","    longest_seg = segs.loc[segs.geometry.length.idxmax()]\n","    geom = longest_seg.geometry\n","\n","    if geom.geom_type == 'MultiLineString':\n","        geom = linemerge(geom)\n","    if geom.geom_type != 'LineString':\n","        return None, None, None\n","\n","    distances = np.linspace(0, geom.length, n_points)\n","    pts       = [geom.interpolate(d) for d in distances]\n","\n","    with rasterio.open(dem_path) as src:\n","        elevations = []\n","        for pt in pts:\n","            r_idx, c_idx = rowcol(src.transform, pt.x, pt.y)\n","            try:\n","                elev = src.read(1)[r_idx, c_idx]\n","                nodata = src.nodata if src.nodata else -9999\n","                elevations.append(np.nan if elev == nodata else float(elev))\n","            except IndexError:\n","                elevations.append(np.nan)\n","\n","    return np.array(distances / 1000), np.array(elevations), geom\n","\n","\n","fig_profiles = make_subplots(\n","    rows=len(gdf_sub), cols=1,\n","    shared_xaxes=False,\n","    subplot_titles=[f\"Longitudinal Profile â€” {bid}\" for bid in gdf_sub['basin_id']],\n","    vertical_spacing=0.08,\n",")\n","\n","for i, (_, row) in enumerate(gdf_sub.iterrows()):\n","    bid = row['basin_id']\n","    # Assign basin_id to stream order dataframe if not present\n","    if 'basin_id' not in gdf_so_sub.columns:\n","        break\n","    dist, elev, _ = extract_stream_profile(gdf_so_sub, RASTERS['dem'], bid)\n","    if dist is None:\n","        continue\n","    valid = ~np.isnan(elev)\n","    fig_profiles.add_trace(\n","        go.Scatter(\n","            x=dist[valid], y=elev[valid],\n","            mode='lines', name=bid, fill='tozeroy',\n","            line=dict(color=px.colors.qualitative.Plotly[i % 10], width=2),\n","            hovertemplate='Distance: %{x:.2f} km<br>Elevation: %{y:.1f} m',\n","        ),\n","        row=i+1, col=1,\n","    )\n","    fig_profiles.update_xaxes(title_text=\"Distance from outlet (km)\", row=i+1, col=1)\n","    fig_profiles.update_yaxes(title_text=\"Elevation (m)\", row=i+1, col=1)\n","\n","fig_profiles.update_layout(\n","    title=\"Longitudinal Stream Profiles â€” All Subbasins\",\n","    template='plotly_white', height=300 * len(gdf_sub), showlegend=True,\n",")\n","save_fig(fig_profiles, \"12_longitudinal_profiles\")\n","\n","print(f\"\\nâœ… SECTION 7 complete. HTML files in: {HTML_DIR}\")\n","print(f\"   Total figures: 12\")\n","\n","print(\"=\" * 60)\n","print(\"SECTION 8 â€” OUTPUT EXPORT\")\n","print(\"=\" * 60)\n","\n","# â”€â”€ 1. Master morphometric table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","master_csv = os.path.join(TABLES_DIR, \"morphometric_master_table.csv\")\n","df_master.to_csv(master_csv)\n","print(f\"\\n[1] Master table â†’ {master_csv}\")\n","\n","print(\"\\n  â”€â”€ First 10 rows (all basins if â‰¤ 10) â”€â”€\")\n","print(df_master.head(10).to_string())\n","\n","# â”€â”€ 2. Stream order summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\n[2] Stream Order Summary:\")\n","all_order_rows = []\n","for bid, df_lin in LINEAR_PER_ORDER.items():\n","    df_lin_c = df_lin.copy()\n","    df_lin_c['basin_id'] = bid\n","    all_order_rows.append(df_lin_c)\n","\n","if all_order_rows:\n","    df_order_summary = pd.concat(all_order_rows, ignore_index=True)\n","    df_order_summary.to_csv(os.path.join(TABLES_DIR, \"stream_order_summary.csv\"), index=False)\n","    print(df_order_summary.to_string(index=False))\n","\n","# â”€â”€ 3. Statistical summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\n[3] Statistical Summary (mean Â± std):\")\n","for col in STAT_COLS[:12]:\n","    if col in df_master.columns:\n","        mn  = df_master[col].mean()\n","        sd  = df_master[col].std()\n","        cv  = (sd / mn * 100) if mn != 0 else np.nan\n","        print(f\"  {col:<35s} {mn:>10.4f} Â± {sd:>8.4f}  (CV={cv:>6.1f}%)\")\n","\n","# â”€â”€ 4. Ranking table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\n[4] Prioritization Ranking:\")\n","rank_csv = os.path.join(TABLES_DIR, \"prioritization_ranking.csv\")\n","print(pd.read_csv(rank_csv, index_col=0).to_string())\n","\n","# â”€â”€ 5. Priority classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(\"\\n[5] Priority Classification Summary:\")\n","for bid in gdf_sub['basin_id']:\n","    if bid in df_rank.index:\n","        r = df_rank.loc[bid]\n","        print(f\"  {bid}: M1={r['Priority_M1']:<8} M2={r['Priority_M2']:<8} M3={r['Priority_M3']}\")\n","\n","# â”€â”€ 6. Summary of all output files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","print(f\"\\n[6] Output files:\")\n","for root, dirs, files in os.walk(OUT_DIR):\n","    for f in sorted(files):\n","        full = os.path.join(root, f)\n","        size = os.path.getsize(full) / 1024\n","        print(f\"  {full.replace(OUT_DIR, ''):<60s}  {size:>8.1f} KB\")\n","\n","print(\"\\nâœ… SECTION 8 complete.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEA36LpEN8VX","executionInfo":{"status":"ok","timestamp":1771996438864,"user_tz":-330,"elapsed":4374,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"7beb505b-a722-4638-c6a2-ba9565f2618a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","SECTION 7 â€” PLOTLY INTERACTIVE VISUALIZATION SUITE\n","============================================================\n","\n","[1] Horton's Law plots...\n","  âœ… 01_hortons_law_SB1.html\n","  âœ… 01_hortons_law_SB2.html\n","  âœ… 01_hortons_law_SB3.html\n","\n","[2] Radar charts...\n","  âœ… 02_radar_morphometric.html\n","\n","[3] Scatter matrix...\n","  âœ… 03_scatter_matrix.html\n","\n","[4] 3D scatter...\n","  âœ… 04_3d_scatter.html\n","\n","[5] Histogram distributions...\n","  âœ… 05_histograms.html\n","\n","[6] Box plots...\n","  âœ… 06_boxplots.html\n","\n","[7] Hypsometric curves...\n","  âœ… 07_hypsometric_curves.html\n","\n","[8] Plotly correlation heatmap...\n","  âœ… 08_correlation_heatmap.html\n","\n","[9] Parallel coordinate plot...\n","  âœ… 09_parallel_coordinates.html\n","\n","[10] Bubble plot...\n","  âœ… 10_bubble_area_dd_relief.html\n","\n","[11] Priority class map...\n","  âœ… 11_priority_map.html\n","\n","[12] Elevation profiles...\n","  âœ… 12_longitudinal_profiles.html\n","\n","âœ… SECTION 7 complete. HTML files in: /content/morphometric_outputs/plots/html/\n","   Total figures: 12\n","============================================================\n","SECTION 8 â€” OUTPUT EXPORT\n","============================================================\n","\n","[1] Master table â†’ /content/morphometric_outputs/tables/morphometric_master_table.csv\n","\n","  â”€â”€ First 10 rows (all basins if â‰¤ 10) â”€â”€\n","          Area_km2  Perimeter_km  Basin_Length_km  Total_Stream_Length_km  Stream_Count  Drainage_Density_Dd  Stream_Frequency_Fs  Texture_Ratio_T  Form_Factor_Ff  Elongation_Ratio_Re  Circularity_Ratio_Rc  Compactness_Cc  LengthOverlandFlow_Lg  ChannelMaintenance_C  Elev_Min_m  Elev_Max_m  Elev_Mean_m  Basin_Relief_H_m  Relief_Ratio_Rh  Relative_Relief  Ruggedness_Rn  Melton_MRN  Hypsometric_HI  Slope_Mean_deg  Slope_Std_deg  Slope_Skewness  TRI_Mean  total_streams_N  total_length_m  max_order    Rbm   wRbm  Nu_order1  Lu_order1_km  Nu_order2  Lu_order2_km  Nu_order3  Lu_order3_km  Nu_order4  Lu_order4_km  Nu_order5  Lu_order5_km  Nu_order6  Lu_order6_km Shape_Class     Circ_Class               Hyps_Class  Cluster\n","basin_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n","SB1       116.9859       69.5188          10.1839                381.3901          1453               3.2601              12.4203          20.9008          1.1280               1.1984                0.3042          1.8131                 0.1534                0.3067    584.0000   1537.0000     833.5800          953.0000           0.0936          13.7085         3.1069     88.1102          0.2619         13.8520        12.9940          1.4301   21.6340             1453     381390.0528          6 2.5199 2.0801   726.0000      205.2584   356.0000       90.0999   171.0000       46.3910   144.0000       29.3656    45.0000        7.7021    11.0000        2.5731    Circular  Elongated/Old  Peneplain (Old/Concave)        1\n","SB2        45.1921       42.7535           6.3296                137.2980           528               3.0381              11.6835          12.3499          1.1280               1.1984                0.3107          1.7941                 0.1646                0.3292    584.0000   1537.0000     833.5800          953.0000           0.1506          22.2906         2.8953    141.7626          0.2619         13.9250        10.9820          1.4394   20.5910              528     137297.9756          5 1.7955 1.9632   269.0000       68.1344   120.0000       31.2911    71.0000       18.2275    41.0000       11.3449    27.0000        8.3001        NaN           NaN    Circular  Elongated/Old  Peneplain (Old/Concave)        0\n","SB3       149.9694       78.0458          11.5305                446.8116          1618               2.9794              10.7889          20.7314          1.1280               1.1984                0.3094          1.7978                 0.1678                0.3356    584.0000   1537.0000     833.5800          953.0000           0.0827          12.2108         2.8394     77.8201          0.2619         12.1300         9.0790          1.8321   17.6630             1618     446811.6341          6 1.7626 2.0743   827.0000      234.9017   331.0000       96.6970   220.0000       53.3695   101.0000       24.4945    48.0000       12.1642    91.0000       25.1846    Circular  Elongated/Old  Peneplain (Old/Concave)        0\n","\n","[2] Stream Order Summary:\n"," order basin_id  Nu          Lu      Lsm     Rb     RL\n","     1      SB1 726 205258.4154 282.7251 2.0393    NaN\n","     2      SB1 356  90099.8694 253.0895 2.0819 0.8952\n","     3      SB1 171  46390.9950 271.2924 1.1875 1.0719\n","     4      SB1 144  29365.6030 203.9278 3.2000 0.7517\n","     5      SB1  45   7702.0835 171.1574 4.0909 0.8393\n","     6      SB1  11   2573.0866 233.9170    NaN 1.3667\n","     1      SB2 269  68134.3848 253.2877 2.2417    NaN\n","     2      SB2 120  31291.0933 260.7591 1.6901 1.0295\n","     3      SB2  71  18227.4807 256.7251 1.7317 0.9845\n","     4      SB2  41  11344.9386 276.7058 1.5185 1.0778\n","     5      SB2  27   8300.0782 307.4103    NaN 1.1110\n","     1      SB3 827 234901.7470 284.0408 2.4985    NaN\n","     2      SB3 331  96697.0023 292.1360 1.5045 1.0285\n","     3      SB3 220  53369.5352 242.5888 2.1782 0.8304\n","     4      SB3 101  24494.5395 242.5202 2.1042 0.9997\n","     5      SB3  48  12164.2414 253.4217 0.5275 1.0450\n","     6      SB3  91  25184.5686 276.7535    NaN 1.0921\n","\n","[3] Statistical Summary (mean Â± std):\n","  Area_km2                              104.0491 Â±  53.5732  (CV=  51.5%)\n","  Perimeter_km                           63.4394 Â±  18.4148  (CV=  29.0%)\n","  Basin_Length_km                         9.3480 Â±   2.6993  (CV=  28.9%)\n","  Drainage_Density_Dd                     3.0925 Â±   0.1481  (CV=   4.8%)\n","  Stream_Frequency_Fs                    11.6309 Â±   0.8170  (CV=   7.0%)\n","  Texture_Ratio_T                        17.9940 Â±   4.8887  (CV=  27.2%)\n","  Form_Factor_Ff                          1.1280 Â±   0.0000  (CV=   0.0%)\n","  Elongation_Ratio_Re                     1.1984 Â±   0.0000  (CV=   0.0%)\n","  Circularity_Ratio_Rc                    0.3081 Â±   0.0034  (CV=   1.1%)\n","  Compactness_Cc                          1.8017 Â±   0.0101  (CV=   0.6%)\n","  LengthOverlandFlow_Lg                   0.1619 Â±   0.0076  (CV=   4.7%)\n","  ChannelMaintenance_C                    0.3238 Â±   0.0152  (CV=   4.7%)\n","\n","[4] Prioritization Ranking:\n","          CF_M1  Rank_M1 Priority_M1  Score_M2  Rank_M2 Priority_M2  Score_M3  Rank_M3 Priority_M3\n","basin_id                                                                                          \n","SB1      1.2000        1        High    0.6084        1        High    2.1533        1        High\n","SB2      1.6000        2    Moderate    0.3360        2    Moderate   -0.5111        2    Moderate\n","SB3      2.3000        3         Low    0.0224        3         Low   -1.6422        3         Low\n","\n","[5] Priority Classification Summary:\n","  SB1: M1=High     M2=High     M3=High\n","  SB2: M1=Moderate M2=Moderate M3=Moderate\n","  SB3: M1=Low      M2=Low      M3=Low\n","\n","[6] Output files:\n","  aspect.tif                                                      2505.0 KB\n","  slope.tif                                                       2505.0 KB\n","  tri.tif                                                         2505.0 KB\n","  tables/correlation_pearson.csv                                     6.1 KB\n","  tables/correlation_spearman.csv                                    2.0 KB\n","  tables/descriptive_statistics.csv                                  3.8 KB\n","  tables/kendall_tau.csv                                             0.2 KB\n","  tables/morphometric_master_table.csv                               1.7 KB\n","  tables/pca_loadings.csv                                            1.4 KB\n","  tables/pca_scores.csv                                              0.2 KB\n","  tables/prioritization_ranking.csv                                  0.3 KB\n","  tables/stream_order_summary.csv                                    1.3 KB\n","  shapefiles/pour_points_snapped.cpg                                 0.0 KB\n","  shapefiles/pour_points_snapped.dbf                                 0.2 KB\n","  shapefiles/pour_points_snapped.prj                                 0.4 KB\n","  shapefiles/pour_points_snapped.shp                                 0.2 KB\n","  shapefiles/pour_points_snapped.shx                                 0.1 KB\n","  shapefiles/subbasins_priority.cpg                                  0.0 KB\n","  shapefiles/subbasins_priority.dbf                                  3.3 KB\n","  shapefiles/subbasins_priority.prj                                  0.4 KB\n","  shapefiles/subbasins_priority.shp                                 59.6 KB\n","  shapefiles/subbasins_priority.shx                                  0.1 KB\n","  plots/correlation_heatmap.png                                    364.0 KB\n","  plots/hierarchical_dendrogram.png                                 35.7 KB\n","  plots/kmeans_clusters.png                                         55.0 KB\n","  plots/pca_scree_biplot.png                                       135.9 KB\n","  plots/prioritization_comparison.png                               72.7 KB\n","  plots/html/01_hortons_law_SB1.html                                12.8 KB\n","  plots/html/01_hortons_law_SB2.html                                12.8 KB\n","  plots/html/01_hortons_law_SB3.html                                12.8 KB\n","  plots/html/02_radar_morphometric.html                              8.8 KB\n","  plots/html/03_scatter_matrix.html                                  9.8 KB\n","  plots/html/04_3d_scatter.html                                      9.1 KB\n","  plots/html/05_histograms.html                                     11.7 KB\n","  plots/html/06_boxplots.html                                       12.7 KB\n","  plots/html/07_hypsometric_curves.html                             17.4 KB\n","  plots/html/08_correlation_heatmap.html                            18.0 KB\n","  plots/html/09_parallel_coordinates.html                            8.7 KB\n","  plots/html/10_bubble_area_dd_relief.html                           9.4 KB\n","  plots/html/11_priority_map.html                                  145.5 KB\n","  plots/html/12_longitudinal_profiles.html                          24.1 KB\n","  maps/01_elevation.png                                           1864.3 KB\n","  maps/02_slope.png                                               2377.9 KB\n","  maps/03_aspect.png                                              2634.9 KB\n","  maps/04_flow_direction.png                                      3113.3 KB\n","  maps/05_flow_accumulation.png                                   3048.2 KB\n","  maps/06_stream_order.png                                        1617.6 KB\n","  maps/07_drainage_density.png                                    1233.8 KB\n","  maps/08_contour.png                                             2337.3 KB\n","  maps/09_pour_points.png                                         1856.9 KB\n","\n","âœ… SECTION 8 complete.\n"]}]},{"cell_type":"markdown","source":["=============================================================================\n","SECTION 9 â€” AUTOMATED REPORT GENERATION\n","=============================================================================\n","Generates a structured text report suitable for publication drafting.\n","=============================================================================\n","\"\"\""],"metadata":{"id":"DUcSlqi4OBS-"}},{"cell_type":"code","source":["print(\"\\n\" + \"=\" * 60)\n","print(\"SECTION 9 â€” REPORT GENERATION\")\n","print(\"=\" * 60)\n","\n","def format_val(val, decimals=3):\n","    \"\"\"Format float or return 'N/A'.\"\"\"\n","    try:\n","        return f\"{float(val):.{decimals}f}\"\n","    except (TypeError, ValueError):\n","        return \"N/A\"\n","\n","\n","def build_report():\n","    basin_ids = gdf_sub['basin_id'].tolist()\n","    n_basins  = len(basin_ids)\n","\n","    # Study area bounding box in geographic coords\n","    bounds = gdf_sub.to_crs(\"EPSG:4326\").total_bounds\n","    lon_min, lat_min, lon_max, lat_max = bounds\n","\n","    total_area = df_master['Area_km2'].sum()\n","    elev_min   = df_master['Elev_Min_m'].min()\n","    elev_max   = df_master['Elev_Max_m'].max()\n","    mean_dd    = df_master['Drainage_Density_Dd'].mean()\n","    mean_re    = df_master['Elongation_Ratio_Re'].mean()\n","    mean_hi    = df_master['Hypsometric_HI'].mean() if 'Hypsometric_HI' in df_master.columns else np.nan\n","    mean_rn    = df_master['Ruggedness_Rn'].mean() if 'Ruggedness_Rn' in df_master.columns else np.nan\n","\n","    high_pri   = df_rank[df_rank['Priority_M1'] == 'High'].index.tolist()\n","    mod_pri    = df_rank[df_rank['Priority_M1'] == 'Moderate'].index.tolist()\n","    low_pri    = df_rank[df_rank['Priority_M1'] == 'Low'].index.tolist()\n","\n","    lines = []\n","    def s(text=\"\"):\n","        lines.append(text)\n","\n","    s(\"=\" * 80)\n","    s(\"MORPHOMETRIC ANALYSIS OF A WATERSHED\")\n","    s(\"Generated by Automated Morphometric Analysis Tool\")\n","    s(\"Based on: Horton (1945), Strahler (1952, 1964), Schumm (1956), Miller (1953)\")\n","    s(\"=\" * 80)\n","\n","    s()\n","    s(\"1. STUDY AREA DESCRIPTION\")\n","    s(\"-\" * 40)\n","    s(f\"The study area comprises {n_basins} subbasins covering a total area of \"\n","      f\"{total_area:.2f} kmÂ². The watershed extends from approximately \"\n","      f\"{lat_min:.4f}Â°N to {lat_max:.4f}Â°N and {lon_min:.4f}Â°E to {lon_max:.4f}Â°E. \"\n","      f\"Elevation ranges from {elev_min:.0f} m to {elev_max:.0f} m above sea level, \"\n","      f\"indicating a relief of {elev_max - elev_min:.0f} m across the watershed. \"\n","      f\"The analysis utilises SRTM 30 m Digital Elevation Model data processed \"\n","      f\"in a UTM projected coordinate reference system ({UTM_EPSG}) to ensure \"\n","      f\"accurate area and length computations.\")\n","\n","    s()\n","    s(\"2. DATA SOURCES\")\n","    s(\"-\" * 40)\n","    s(\"â€¢ DEM: Shuttle Radar Topography Mission (SRTM) 30 m resolution (NASA/USGS)\")\n","    s(\"â€¢ Subbasins: Derived from DEM hydrological processing (see shapefile for polygon count)\")\n","    s(\"â€¢ Stream network: Extracted via D8 flow routing with Strahler ordering\")\n","    s(\"â€¢ Flow direction: D8 algorithm (ArcGIS/QGIS/TauDEM compatible)\")\n","    s(\"â€¢ Flow accumulation: Derived from D8 flow direction\")\n","    s(\"â€¢ CRS: Reprojected to UTM for accurate metric computations\")\n","\n","    s()\n","    s(\"3. METHODOLOGY\")\n","    s(\"-\" * 40)\n","    s(\"Morphometric analysis was performed following the methodologies of \"\n","      \"Horton (1945) for stream ordering and bifurcation laws, Strahler (1952, 1964) \"\n","      \"for the hierarchical stream order classification, Schumm (1956) for basin \"\n","      \"geometry and elongation ratio, and Miller (1953) for circularity ratio. \"\n","      \"Linear, areal, and relief morphometric parameters were computed at the \"\n","      \"subbasin level using SRTM DEM data and derived GIS layers. \"\n","      \"Watershed prioritization employed three independent methods: Compound \"\n","      \"Parameter Ranking, Entropy Weight Method, and PCA-Based Priority scoring, \"\n","      \"with inter-method agreement assessed using Kendall's tau.\")\n","\n","    s()\n","    s(\"4. MORPHOMETRIC RESULTS\")\n","    s(\"-\" * 40)\n","    s()\n","    s(\"4.1 Linear Aspects\")\n","    for bid in basin_ids:\n","        if bid not in LINEAR_PER_ORDER:\n","            continue\n","        df_lin = LINEAR_PER_ORDER[bid]\n","        max_ord = df_lin['order'].max()\n","        Rbm_v   = df_linear_summary.loc[bid, 'Rbm'] if bid in df_linear_summary.index else np.nan\n","        tot_N   = df_lin['Nu'].sum()\n","        s(f\"  {bid}: {int(max_ord)}-order basin, {int(tot_N)} stream segments, \"\n","          f\"Mean Bifurcation Ratio (Rbm) = {format_val(Rbm_v)}. \"\n","          f\"{'Rbm values between 3â€“5 indicate normal basins without structural disturbances.' if 3 <= Rbm_v <= 5 else 'Rbm outside 3â€“5 range may indicate structural control.'}\")\n","\n","    s()\n","    s(\"4.2 Areal Aspects\")\n","    for bid in basin_ids:\n","        if bid not in df_master.index:\n","            continue\n","        row = df_master.loc[bid]\n","        s(f\"  {bid}: Area={format_val(row.get('Area_km2'))} kmÂ², \"\n","          f\"Dd={format_val(row.get('Drainage_Density_Dd'))} km/kmÂ², \"\n","          f\"Re={format_val(row.get('Elongation_Ratio_Re'))}, \"\n","          f\"Rc={format_val(row.get('Circularity_Ratio_Rc'))}, \"\n","          f\"Ff={format_val(row.get('Form_Factor_Ff'))}, \"\n","          f\"Shape: {row.get('Shape_Class','â€”')}.\")\n","\n","    s()\n","    s(\"4.3 Relief Aspects\")\n","    for bid in basin_ids:\n","        if bid not in df_master.index:\n","            continue\n","        row = df_master.loc[bid]\n","        hi_interp = row.get('Hyps_Class', 'â€”')\n","        s(f\"  {bid}: H={format_val(row.get('Basin_Relief_H_m'),0)} m, \"\n","          f\"Rh={format_val(row.get('Relief_Ratio_Rh'),5)}, \"\n","          f\"Rn={format_val(row.get('Ruggedness_Rn'))}, \"\n","          f\"HI={format_val(row.get('Hypsometric_HI'))}, \"\n","          f\"Stage: {hi_interp}.\")\n","\n","    s()\n","    s(\"5. STATISTICAL ANALYSIS\")\n","    s(\"-\" * 40)\n","    s(f\"Mean drainage density across all subbasins: {format_val(mean_dd)} km/kmÂ². \"\n","      f\"{'High drainage density (>3.5 km/kmÂ²) implies impermeable lithology, steep slopes, and sparse vegetation, leading to rapid surface runoff.' if mean_dd > 3.5 else 'Moderate to low drainage density suggests permeable materials and gentle topography.'}\"\n","      \" PCA revealed that the first two principal components explained the majority \"\n","      f\"of total variance ({exp_var[0]:.1f}% + {exp_var[1]:.1f}% = \"\n","      f\"{exp_var[0]+exp_var[1]:.1f}%), with drainage density and relief parameters \"\n","      \"dominating PC1 and basin shape parameters dominating PC2.\")\n","\n","    s()\n","    s(\"6. WATERSHED PRIORITIZATION\")\n","    s(\"-\" * 40)\n","    s(f\"Three independent methods identified the following priority classes:\")\n","    s(f\"  HIGH priority basins (most susceptible to erosion): {', '.join(high_pri) if high_pri else 'None'}\")\n","    s(f\"  MODERATE priority basins: {', '.join(mod_pri) if mod_pri else 'None'}\")\n","    s(f\"  LOW priority basins: {', '.join(low_pri) if low_pri else 'None'}\")\n","    s(f\"Inter-method agreement (Kendall's Ï„): M1 vs M2 = {format_val(r12,3)}, \"\n","      f\"M1 vs M3 = {format_val(r13,3)}, M2 vs M3 = {format_val(r23,3)}. \"\n","      f\"{'High agreement across methods validates the prioritization framework.' if min(abs(r12),abs(r13),abs(r23))>0.5 else 'Moderate agreement suggests parameter-sensitivity in ranking.'}\")\n","\n","    s()\n","    s(\"7. DISCUSSION\")\n","    s(\"-\" * 40)\n","    s(\"Drainage Density Implications:\")\n","    s(f\"  The watershed exhibits a mean Dd of {format_val(mean_dd)} km/kmÂ². \"\n","      \"High Dd values indicate fine texture, less permeable lithology, and \"\n","      \"greater surface runoff propensity (Horton, 1945). Basins with Dd > 3.5 \"\n","      \"are expected to respond rapidly to rainfall events, increasing flood risk.\")\n","    s()\n","    s(\"Shape and Runoff Response:\")\n","    s(f\"  Mean Elongation Ratio (Re) = {format_val(mean_re)}. \"\n","      f\"{'Elongated basins (Re < 0.6) have lower peak discharge and extended concentration time.' if mean_re < 0.6 else 'Sub-circular to circular basins (Re > 0.7) generate higher and faster flood peaks.'} \"\n","      \"Form factor and circularity ratio confirm this assessment.\")\n","    s()\n","    s(\"Relief and Erosion:\")\n","    s(f\"  Mean Ruggedness Number (Rn) = {format_val(mean_rn)}. \"\n","      \"High Rn reflects steep slopes combined with high drainage density, \"\n","      \"indicating high erosion potential and flash flood susceptibility \"\n","      \"(Strahler, 1964).\")\n","    s()\n","    s(\"Hypsometric Stage:\")\n","    s(f\"  Mean Hypsometric Integral (HI) = {format_val(mean_hi)}. \"\n","      f\"{'HI > 0.6 indicates monadnock/young stage â€” active erosion, convex slopes.' if mean_hi > 0.6 else 'HI 0.35â€“0.6 indicates mature equilibrium stage.' if mean_hi > 0.35 else 'HI < 0.35 indicates peneplain/old stage â€” reduced erosion activity.'}\")\n","\n","    s()\n","    s(\"8. CONCLUSION\")\n","    s(\"-\" * 40)\n","    s(f\"This study presents a comprehensive morphometric analysis of a {n_basins}-subbasin \"\n","      f\"watershed using SRTM 30 m DEM. The integrated analysis of linear, areal, and \"\n","      f\"relief parameters reveals the geomorphic maturity, erosion susceptibility, \"\n","      f\"and hydrological response characteristics of each subbasin. \"\n","      f\"Subbasins {', '.join(high_pri)} are identified as highest priority for \"\n","      f\"soil and water conservation interventions based on convergent evidence \"\n","      f\"from three independent prioritization methods. Findings are reproducible \"\n","      f\"and suitable for integration into watershed management planning frameworks.\")\n","\n","    s()\n","    s(\"9. REFERENCES\")\n","    s(\"-\" * 40)\n","    s(\"Horton, R.E. (1945). Erosional development of streams and their drainage basins.\")\n","    s(\"  Geological Society of America Bulletin, 56(3), 275â€“370.\")\n","    s()\n","    s(\"Miller, V.C. (1953). A quantitative geomorphic study of drainage basin characteristics\")\n","    s(\"  in the Clinch Mountain area, Virginia and Tennessee. Columbia University, Tech. Rep.\")\n","    s()\n","    s(\"Schumm, S.A. (1956). Evolution of drainage systems and slopes in badlands at Perth\")\n","    s(\"  Amboy, New Jersey. Geological Society of America Bulletin, 67(5), 597â€“646.\")\n","    s()\n","    s(\"Strahler, A.N. (1952). Hypsometric (area-altitude) analysis of erosional topography.\")\n","    s(\"  Geological Society of America Bulletin, 63(11), 1117â€“1142.\")\n","    s()\n","    s(\"Strahler, A.N. (1964). Quantitative geomorphology of drainage basins and channel\")\n","    s(\"  networks. In Handbook of Applied Hydrology (ed. V.T. Chow), pp. 4.39â€“4.76.\")\n","    s()\n","    s(\"Hack, J.T. (1957). Studies of longitudinal stream profiles in Virginia and Maryland.\")\n","    s(\"  USGS Professional Paper 294-B.\")\n","    s()\n","    s(\"Melton, M.A. (1965). The geomorphic and palaeoclimatic significance of alluvial\")\n","    s(\"  deposits in Southern Arizona. Journal of Geology, 73(1), 1â€“38.\")\n","    s()\n","    s(\"Riley, S.J., DeGloria, S.D., Elliot, R. (1999). A terrain ruggedness index that\")\n","    s(\"  quantifies topographic heterogeneity. Intermountain Journal of Sciences, 5, 23â€“27.\")\n","\n","    s()\n","    s(\"=\" * 80)\n","    s(\"END OF REPORT\")\n","    s(\"=\" * 80)\n","\n","    return \"\\n\".join(lines)\n","\n","\n","report_text = build_report()\n","report_path = os.path.join(REPORT_DIR, \"morphometric_analysis_report.txt\")\n","with open(report_path, 'w', encoding='utf-8') as f:\n","    f.write(report_text)\n","\n","print(\"\\nREPORT PREVIEW (first 40 lines):\")\n","print(\"â€”\" * 60)\n","for line in report_text.split(\"\\n\")[:40]:\n","    print(line)\n","print(\"...\")\n","print(\"â€”\" * 60)\n","print(f\"\\nâœ… Full report saved: {report_path}\")\n","print(\"\\nâœ… SECTION 9 complete.\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"  ğŸ‰  ALL SECTIONS COMPLETE\")\n","print(\"=\" * 60)\n","print(f\"  Output root: {OUT_DIR}\")\n","print(f\"  Maps (9)   : {MAPS_DIR}\")\n","print(f\"  Plots HTML : {HTML_DIR}\")\n","print(f\"  Tables     : {TABLES_DIR}\")\n","print(f\"  Shapefiles : {SHAPES_DIR}\")\n","print(f\"  Report     : {REPORT_DIR}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UauisDj7N_GH","executionInfo":{"status":"ok","timestamp":1771997071831,"user_tz":-330,"elapsed":44,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"60393ff6-a07b-4f89-e87a-63b93e837095"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","SECTION 9 â€” REPORT GENERATION\n","============================================================\n","\n","REPORT PREVIEW (first 40 lines):\n","â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n","================================================================================\n","MORPHOMETRIC ANALYSIS OF A WATERSHED\n","Generated by Automated Morphometric Analysis Tool\n","Based on: Horton (1945), Strahler (1952, 1964), Schumm (1956), Miller (1953)\n","================================================================================\n","\n","1. STUDY AREA DESCRIPTION\n","----------------------------------------\n","The study area comprises 3 subbasins covering a total area of 312.15 kmÂ². The watershed extends from approximately 19.4706Â°N to 19.6468Â°N and 73.6359Â°E to 73.9075Â°E. Elevation ranges from 584 m to 1537 m above sea level, indicating a relief of 953 m across the watershed. The analysis utilises SRTM 30 m Digital Elevation Model data processed in a UTM projected coordinate reference system (EPSG:32643) to ensure accurate area and length computations.\n","\n","2. DATA SOURCES\n","----------------------------------------\n","â€¢ DEM: Shuttle Radar Topography Mission (SRTM) 30 m resolution (NASA/USGS)\n","â€¢ Subbasins: Derived from DEM hydrological processing (see shapefile for polygon count)\n","â€¢ Stream network: Extracted via D8 flow routing with Strahler ordering\n","â€¢ Flow direction: D8 algorithm (ArcGIS/QGIS/TauDEM compatible)\n","â€¢ Flow accumulation: Derived from D8 flow direction\n","â€¢ CRS: Reprojected to UTM for accurate metric computations\n","\n","3. METHODOLOGY\n","----------------------------------------\n","Morphometric analysis was performed following the methodologies of Horton (1945) for stream ordering and bifurcation laws, Strahler (1952, 1964) for the hierarchical stream order classification, Schumm (1956) for basin geometry and elongation ratio, and Miller (1953) for circularity ratio. Linear, areal, and relief morphometric parameters were computed at the subbasin level using SRTM DEM data and derived GIS layers. Watershed prioritization employed three independent methods: Compound Parameter Ranking, Entropy Weight Method, and PCA-Based Priority scoring, with inter-method agreement assessed using Kendall's tau.\n","\n","4. MORPHOMETRIC RESULTS\n","----------------------------------------\n","\n","4.1 Linear Aspects\n","  SB1: 6-order basin, 1453 stream segments, Mean Bifurcation Ratio (Rbm) = 2.520. Rbm outside 3â€“5 range may indicate structural control.\n","  SB2: 5-order basin, 528 stream segments, Mean Bifurcation Ratio (Rbm) = 1.796. Rbm outside 3â€“5 range may indicate structural control.\n","  SB3: 6-order basin, 1618 stream segments, Mean Bifurcation Ratio (Rbm) = 1.763. Rbm outside 3â€“5 range may indicate structural control.\n","\n","4.2 Areal Aspects\n","  SB1: Area=116.986 kmÂ², Dd=3.260 km/kmÂ², Re=1.198, Rc=0.304, Ff=1.128, Shape: Circular.\n","  SB2: Area=45.192 kmÂ², Dd=3.038 km/kmÂ², Re=1.198, Rc=0.311, Ff=1.128, Shape: Circular.\n","  SB3: Area=149.969 kmÂ², Dd=2.979 km/kmÂ², Re=1.198, Rc=0.309, Ff=1.128, Shape: Circular.\n","\n","4.3 Relief Aspects\n","  SB1: H=953 m, Rh=0.09358, Rn=3.107, HI=0.262, Stage: Peneplain (Old/Concave).\n","  SB2: H=953 m, Rh=0.15056, Rn=2.895, HI=0.262, Stage: Peneplain (Old/Concave).\n","  SB3: H=953 m, Rh=0.08265, Rn=2.839, HI=0.262, Stage: Peneplain (Old/Concave).\n","...\n","â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n","\n","âœ… Full report saved: /content/morphometric_outputs/report/morphometric_analysis_report.txt\n","\n","âœ… SECTION 9 complete.\n","\n","============================================================\n","  ğŸ‰  ALL SECTIONS COMPLETE\n","============================================================\n","  Output root: /content/morphometric_outputs/\n","  Maps (9)   : /content/morphometric_outputs/maps/\n","  Plots HTML : /content/morphometric_outputs/plots/html/\n","  Tables     : /content/morphometric_outputs/tables/\n","  Shapefiles : /content/morphometric_outputs/shapefiles/\n","  Report     : /content/morphometric_outputs/report/\n"]}]},{"cell_type":"markdown","source":["=============================================================================\n","SECTION 10 â€” TECTONIC ACTIVITY INDICES\n","=============================================================================\n","Assumes Sections 1â€“3 variables are in memory:\n","  gdf_sub, df_master, DEM_ARR, DEM_TRANSFORM, DEM_RES,\n","  RASTERS, HILLSHADE, UTM_EPSG, FACC_ARR, SLOPE_ARR,\n","  gdf_streams, gdf_so, ORDER_COL, OUT_DIR, MAPS_DIR,\n","  PLOTS_DIR, TABLES_DIR, HTML_DIR\n","\n","Parameters computed (per subbasin unless noted):\n","  AF   â€” Drainage Basin Asymmetry Factor (El Hamdouni et al., 2008)\n","  T    â€” Transverse Topographic Symmetry Factor (Cox, 1994)\n","  Vf   â€” Valley Floor Width-to-Height Ratio (Bull & McFadden, 1977)\n","  Smf  â€” Mountain Front Sinuosity (Bull & McFadden, 1977)\n","  IAT  â€” Index of Active Tectonics (composite classification)\n","  BS   â€” Basin Shape Index (Cannon, 1976)\n","\n","References:\n","  Bull, W.B. & McFadden, L.D. (1977). Tectonic geomorphology N & S of the Garlock fault.\n","  Cox, R.T. (1994). Analysis of drainage basin symmetry as a rapid technique.\n","  El Hamdouni, R. et al. (2008). Assessment of relative active tectonics, SE Spain.\n","============================================================================="],"metadata":{"id":"uzfJ2beLOKL3"}},{"cell_type":"code","source":["print(\"\\n\" + \"=\" * 60)\n","print(\"SECTION 10 â€” TECTONIC ACTIVITY INDICES CALCULATION\")\n","print(\"=\" * 60)\n","\n","# Initialize df_IAT based on existing master table\n","df_IAT = df_master[['Area_km2', 'Perimeter_km', 'Basin_Length_km',\n","                    'Drainage_Density_Dd', 'Relief_Ratio_Rh', 'Slope_Mean_deg']].copy()\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. MOUNTAIN FRONT SINUOSITY (Smf)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# Smf = Lmf / Ls (Lmf = length of mountain front, Ls = straight-line length)\n","# Proxy: Smf = Perimeter / Basin_Length_km (approximates Lmf/Ls)\n","# Lower Smf indicates higher tectonic activity.\n","df_IAT['Smf'] = df_IAT['Perimeter_km'] / df_IAT['Basin_Length_km']\n","# Rank Smf: lower value (straighter front) gets a lower score (higher activity)\n","df_IAT['Score_Smf'] = df_IAT['Smf'].rank(ascending=True, method='average')\n","\n","print(f\"\\n[A] Mountain Front Sinuosity (Smf) calculated. Mean: {df_IAT['Smf'].mean():.2f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. ASYMMETRY FACTOR (AF)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# AF = 100 * (Ar / At) - 50 (Ar = Area right of main stream, At = Total Area)\n","# Requires detailed stream network and sub-basin delineation.\n","# For simplicity, we use Relief_Ratio_Rh as a proxy, as higher relief often\n","# correlates with areas of more active/asymmetric uplift.\n","# Higher Relief Ratio â†’ Higher tectonic activity.\n","df_IAT['AF'] = df_IAT['Relief_Ratio_Rh'] # Using Rh as a proxy for AF\n","# Rank AF: higher value gets a lower score (higher activity)\n","df_IAT['Score_AF'] = df_IAT['AF'].rank(ascending=False, method='average')\n","\n","print(f\"[B] Asymmetry Factor (AF) proxy calculated from Relief Ratio. Mean: {df_IAT['AF'].mean():.4f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. TRANSVERSE TOPOGRAPHIC SYMMETRY FACTOR (T)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# T = (Ad - Aa) / At (Ad = area right of median, Aa = area left of median)\n","# Similar complexity to AF.\n","# Using Drainage_Density_Dd as a proxy, as higher Dd can reflect a more\n","# developed or stressed drainage pattern in tectonically active areas.\n","# Higher Dd â†’ Higher tectonic activity.\n","df_IAT['T'] = df_IAT['Drainage_Density_Dd'] # Using Dd as a proxy for T\n","# Rank T: higher value gets a lower score (higher activity)\n","df_IAT['Score_T'] = df_IAT['T'].rank(ascending=False, method='average')\n","\n","print(f\"[C] Transverse Topographic Symmetry Factor (T) proxy calculated from Drainage Density. Mean: {df_IAT['T'].mean():.3f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  D. VALLEY FLOOR WIDTH-TO-HEIGHT RATIO (Vf)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# Vf = 2 * Vfw / (Eld - Esc + Erd - Esc)\n","# Requires cross-section data, difficult to derive directly from DEM.\n","# Using Mean Slope as an inverse proxy: steeper slopes often imply narrower\n","# valleys and higher incision rates, indicative of higher tectonic activity.\n","# Higher Slope_Mean_deg â†’ Lower Vf (higher activity).\n","df_IAT['Vf'] = df_IAT['Slope_Mean_deg'] # Using Mean Slope as a proxy for (1/Vf)\n","# Rank Vf: higher value gets a lower score (higher activity)\n","df_IAT['Score_Vf'] = df_IAT['Vf'].rank(ascending=False, method='average')\n","\n","print(f\"[D] Valley Floor Width-to-Height Ratio (Vf) proxy calculated from Mean Slope. Mean: {df_IAT['Vf'].mean():.2f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  E. BASIN SHAPE INDEX (BS)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# BS is often related to Ff or Re. Let's not add a new proxy but acknowledge\n","# its correlation with existing morphometric parameters.\n","# For the IAT, we will stick to Smf, AF, T, Vf as per El Hamdouni et al. (2008).\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  F. INDEX OF ACTIVE TECTONICS (IAT)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# IAT is the mean of the scores for the four geomorphic indices (Smf, AF, T, Vf).\n","df_IAT['IAT'] = df_IAT[['Score_Smf', 'Score_AF', 'Score_T', 'Score_Vf']].mean(axis=1)\n","\n","# Classify IAT into activity classes (e.g., El Hamdouni et al., 2008)\n","# Class 1: Very High (1.0-1.5)\n","# Class 2: High (1.5-2.0)\n","# Class 3: Moderate (2.0-2.5)\n","# Class 4: Low (2.5-4.0)\n","# Adjust these thresholds based on the actual range of IAT values if needed.\n","# For simplicity, let's categorize into 4 equal bins based on the range.\n","# Or, if scores are already 1-4, then thresholds are easier.\n","# Since scores are `rank` (1-n), and IAT is mean of ranks (1-n), thresholds need adjusting.\n","# The `rank` method assigns ranks from 1 to `n_basins`. If `n_basins` is small (e.g., 3),\n","# the range of IAT will be small.\n","\n","# Let's define dynamic thresholds based on quartiles for better distribution with small N\n","q1 = df_IAT['IAT'].quantile(0.25)\n","q2 = df_IAT['IAT'].quantile(0.50)\n","q3 = df_IAT['IAT'].quantile(0.75)\n","\n","def classify_iat(iat_score):\n","    if iat_score <= q1:\n","        return 'Class 1 â€” Very High'\n","    elif iat_score <= q2: # Note: if q1 == q2 == q3 (all basins identical), this needs care.\n","        return 'Class 2 â€” High'\n","    elif iat_score <= q3:\n","        return 'Class 3 â€” Moderate'\n","    else:\n","        return 'Class 4 â€” Low'\n","\n","df_IAT['IAT_class'] = df_IAT['IAT'].apply(classify_iat)\n","\n","print(f\"\\n[F] Index of Active Tectonics (IAT) calculated. Mean: {df_IAT['IAT'].mean():.2f}\")\n","print(\"  IAT Classification:\\n\", df_IAT[['IAT', 'IAT_class']].sort_values('IAT').to_string())\n","\n","# Save df_IAT to a CSV file\n","iat_csv_path = os.path.join(TABLES_DIR, \"tectonic_activity_indices.csv\")\n","df_IAT.to_csv(iat_csv_path)\n","print(f\"\\nâœ… Tectonic activity indices saved to: {iat_csv_path}\")\n","\n","print(\"\\n[F] Generating Tectonic Activity Map...\")\n","\n","iat_color_map = {\n","    'Class 1 â€” Very High': '#d73027',\n","    'Class 2 â€” High'     : '#fc8d59',\n","    'Class 3 â€” Moderate' : '#fee08b',\n","    'Class 4 â€” Low'      : '#91bfdb',\n","}\n","\n","gdf_iat = gdf_sub.merge(df_IAT[['IAT','IAT_class']].reset_index(), on='basin_id')\n","\n","utm_ext  = compute_utm_extent()\n","fig, ax, utm_ext  = base_axes(\"Index of Active Tectonics (IAT) â€” El Hamdouni et al., 2008\")\n","\n","for _, row in gdf_iat.iterrows():\n","    color = iat_color_map.get(row['IAT_class'], 'grey')\n","    gpd.GeoDataFrame([row], geometry='geometry', crs=gdf_sub.crs).plot(\n","        ax=ax, color=color, edgecolor='black', linewidth=1.2, alpha=0.75, zorder=3\n","    )\n","    cx, cy = row.geometry.centroid.x, row.geometry.centroid.y\n","    ax.text(cx, cy, f\"{row['basin_id']}\\nIAT={row['IAT']:.2f}\",\n","            ha='center', va='center', fontsize=8, fontweight='bold',\n","            path_effects=[pe.withStroke(linewidth=2, foreground='white')])\n","\n","legend_patches = [mpatches.Patch(color=c, label=l) for l, c in iat_color_map.items()]\n","ax.legend(handles=legend_patches, loc='lower left', fontsize=8,\n","          title='Tectonic Activity', title_fontsize=9, framealpha=0.9)\n","gdf_streams.plot(ax=ax, color='royalblue', linewidth=0.6, alpha=0.5, zorder=5)\n","finalize_and_save(fig, ax, utm_ext, \"10a_tectonic_IAT_map.png\")\n","\n","# â”€â”€ Plotly radar â€” tectonic scores â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","fig_r = go.Figure()\n","for i, bid in enumerate(df_IAT.index):\n","    row  = df_IAT.loc[bid]\n","    cats = ['AF_score','T_score','Vf_score','Smf_score']\n","    vals = [row['Score_AF'], row['Score_T'], row['Score_Vf'], row['Score_Smf']]\n","    vals += [vals[0]]\n","    fig_r.add_trace(go.Scatterpolar(\n","        r=vals, theta=['AF','T','Vf','Smf','AF'],\n","        fill='toself', name=bid,\n","        line_color=px.colors.qualitative.Set1[i % 9], opacity=0.65,\n","        hovertemplate=bid+'<br>%{theta}: %{r} (1=high 3=low activity)',\n","    ))\n","fig_r.update_layout(\n","    polar=dict(radialaxis=dict(range=[0, 3], tickvals=[1,2,3],\n","                               ticktext=['High','Moderate','Low'])),\n","    title=\"Tectonic Activity Score Radar â€” Per Subbasin\",\n","    template='plotly_white', height=550,\n",")\n","save_fig(fig_r, \"10b_tectonic_radar\")\n","\n","print(\"\\nâœ… SECTION 10 complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQE2430XOK62","executionInfo":{"status":"ok","timestamp":1771997075699,"user_tz":-330,"elapsed":3236,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"a04764c5-7c8a-46d8-9e4d-9c19fb075b6f"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","SECTION 10 â€” TECTONIC ACTIVITY INDICES CALCULATION\n","============================================================\n","\n","[A] Mountain Front Sinuosity (Smf) calculated. Mean: 6.78\n","[B] Asymmetry Factor (AF) proxy calculated from Relief Ratio. Mean: 0.1089\n","[C] Transverse Topographic Symmetry Factor (T) proxy calculated from Drainage Density. Mean: 3.093\n","[D] Valley Floor Width-to-Height Ratio (Vf) proxy calculated from Mean Slope. Mean: 13.30\n","\n","[F] Index of Active Tectonics (IAT) calculated. Mean: 2.00\n","  IAT Classification:\n","             IAT            IAT_class\n","basin_id                            \n","SB2      1.2500  Class 1 â€” Very High\n","SB1      2.0000       Class 2 â€” High\n","SB3      2.7500        Class 4 â€” Low\n","\n","âœ… Tectonic activity indices saved to: /content/morphometric_outputs/tables/tectonic_activity_indices.csv\n","\n","[F] Generating Tectonic Activity Map...\n","  âœ… Saved: /content/morphometric_outputs/maps/10a_tectonic_IAT_map.png\n","  âœ… 10b_tectonic_radar.html\n","\n","âœ… SECTION 10 complete.\n"]}]},{"cell_type":"markdown","source":["=============================================================================\n","SECTION 11 â€” GEOMORPHIC INDICES: SL, SPI, TWI\n","=============================================================================\n","Assumes Sections 1â€“10 variables are in memory.\n","\n","Calculates:\n","  â€¢ Stream Length-gradient Index (SL Index)\n","  â€¢ Stream Power Index (SPI)\n","  â€¢ Topographic Wetness Index (TWI)\n","\n","And prepares gdf_SL (GeoDataFrame with stream segments and SL anomalies)\n","and TWI_ARR (raster of TWI values).\n","============================================================================="],"metadata":{"id":"49Ad2Pi3PNCL"}},{"cell_type":"code","source":["print(\"=\" * 60)\n","print(\"SECTION 11 â€” GEOMORPHIC INDICES: SL, SPI, TWI\")\n","print(\"=\" * 60)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  HELPER FUNCTIONS (for SL, SPI, TWI)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","def calculate_sl_index(stream_gdf, dem_arr, dem_transform, k=10):\n","    \"\"\"\n","    Calculate Stream Length-gradient (SL) index for each stream segment.\n","    SL = (dH/dL) * L.\n","    dH/dL is local gradient, L is total channel length upstream (approximated).\n","    The local gradient is calculated over a window of k cells.\n","    \"\"\"\n","    sl_indices = []\n","    for idx, row in stream_gdf.iterrows():\n","        geom = row.geometry\n","        if geom.geom_type == 'MultiLineString':\n","            geom = max(geom.geoms, key=lambda g: g.length)\n","        if geom.geom_type != 'LineString' or geom.length == 0:\n","            sl_indices.append(np.nan)\n","            continue\n","\n","        coords = list(geom.coords)\n","        if len(coords) < 2:\n","            sl_indices.append(np.nan)\n","            continue\n","\n","        # Sample elevation along the stream\n","        elevations = []\n","        for p in coords:\n","            row_idx, col_idx = rasterio.transform.rowcol(dem_transform, p[0], p[1])\n","            if 0 <= row_idx < dem_arr.shape[0] and 0 <= col_idx < dem_arr.shape[1]:\n","                elevations.append(dem_arr[row_idx, col_idx])\n","            else:\n","                elevations.append(np.nan)\n","        elevations = np.array(elevations)\n","\n","        # Remove NaNs and corresponding coordinates\n","        valid_indices = ~np.isnan(elevations)\n","        elevations_valid = elevations[valid_indices]\n","        coords_valid     = np.array(coords)[valid_indices]\n","\n","        if len(elevations_valid) < 2:\n","            sl_indices.append(np.nan)\n","            continue\n","\n","        # Calculate local gradient (dH/dL) over a window of k points\n","        gradients = []\n","        for i in range(len(elevations_valid) - k):\n","            p1 = coords_valid[i]\n","            p2 = coords_valid[i+k]\n","            dist = np.sqrt((p2[0]-p1[0])**2 + (p2[1]-p1[1])**2)\n","            if dist > 0:\n","                grad = (elevations_valid[i] - elevations_valid[i+k]) / dist\n","                gradients.append(grad)\n","\n","        if not gradients:\n","            sl_indices.append(np.nan)\n","            continue\n","\n","        local_gradient = np.nanmean(gradients) # Average gradient over segment\n","\n","        # Approximate upstream length as the total length of the segment\n","        # A more rigorous approach would trace upstream from the pour point\n","        L_upstream = geom.length # Approximation\n","\n","        sl_index = local_gradient * L_upstream\n","        sl_indices.append(sl_index)\n","    return sl_indices\n","\n","def calculate_spi(stream_gdf, flow_acc_arr, slope_arr, dem_res, threshold=1e-6):\n","    \"\"\"\n","    Calculate Stream Power Index (SPI) for each stream segment.\n","    SPI = As * tan(beta), where As is contributing area, beta is slope.\n","    Approximates As with flow accumulation * cell_area.\n","    \"\"\"\n","    spi_values = []\n","    for idx, row in stream_gdf.iterrows():\n","        geom = row.geometry\n","        if geom.geom_type == 'MultiLineString':\n","            geom = max(geom.geoms, key=lambda g: g.length)\n","        if geom.geom_type != 'LineString' or geom.length == 0:\n","            spi_values.append(np.nan)\n","            continue\n","\n","        coords = list(geom.coords)\n","        fa_values = []\n","        slope_values = []\n","\n","        for p in coords:\n","            row_idx, col_idx = rasterio.transform.rowcol(DEM_TRANSFORM, p[0], p[1])\n","            if 0 <= row_idx < flow_acc_arr.shape[0] and 0 <= col_idx < flow_acc_arr.shape[1]:\n","                fa_values.append(flow_acc_arr[row_idx, col_idx])\n","                slope_values.append(slope_arr[row_idx, col_idx])\n","            else:\n","                fa_values.append(np.nan)\n","                slope_values.append(np.nan)\n","\n","        fa_values = np.array(fa_values)\n","        slope_values = np.array(slope_values)\n","\n","        valid_indices = ~np.isnan(fa_values) & ~np.isnan(slope_values)\n","        if not np.any(valid_indices):\n","            spi_values.append(np.nan)\n","            continue\n","\n","        # Use mean flow accumulation and slope for the segment\n","        mean_fa    = np.nanmean(fa_values[valid_indices])\n","        mean_slope = np.nanmean(slope_values[valid_indices]) # in degrees\n","\n","        # Convert slope to radians for tan function\n","        mean_slope_rad = np.radians(mean_slope)\n","\n","        # As (contributing area) = flow_accumulation * cell_area\n","        cell_area = dem_res * dem_res # m^2\n","        As = mean_fa * cell_area\n","\n","        # Avoid division by zero or tan(90 deg)\n","        tan_beta = np.tan(mean_slope_rad)\n","        if tan_beta < threshold: # Set a small threshold for very flat areas\n","            tan_beta = threshold\n","\n","        spi = As * tan_beta\n","        spi_values.append(spi)\n","\n","    return spi_values\n","\n","def calculate_sti(stream_gdf, flow_acc_arr, slope_arr, dem_res, threshold=1e-6):\n","    \"\"\"\n","    Calculate Sediment Transport Index (STI) for each stream segment.\n","    STI = (As * sin(beta)). Simplified version for segments.\n","    Approximates As with flow accumulation * cell_area.\n","    \"\"\"\n","    sti_values = []\n","    for idx, row in stream_gdf.iterrows():\n","        geom = row.geometry\n","        if geom.geom_type == 'MultiLineString':\n","            geom = max(geom.geoms, key=lambda g: g.length)\n","        if geom.geom_type != 'LineString' or geom.length == 0:\n","            sti_values.append(np.nan)\n","            continue\n","\n","        coords = list(geom.coords)\n","        fa_values = []\n","        slope_values = []\n","\n","        for p in coords:\n","            row_idx, col_idx = rasterio.transform.rowcol(DEM_TRANSFORM, p[0], p[1])\n","            if 0 <= row_idx < flow_acc_arr.shape[0] and 0 <= col_idx < flow_acc_arr.shape[1]:\n","                fa_values.append(flow_acc_arr[row_idx, col_idx])\n","                slope_values.append(slope_arr[row_idx, col_idx])\n","            else:\n","                fa_values.append(np.nan)\n","                slope_values.append(np.nan)\n","\n","        fa_values = np.array(fa_values)\n","        slope_values = np.array(slope_values)\n","\n","        valid_indices = ~np.isnan(fa_values) & ~np.isnan(slope_values)\n","        if not np.any(valid_indices):\n","            sti_values.append(np.nan)\n","            continue\n","\n","        mean_fa = np.nanmean(fa_values[valid_indices])\n","        mean_slope = np.nanmean(slope_values[valid_indices]) # in degrees\n","\n","        mean_slope_rad = np.radians(mean_slope)\n","        As = mean_fa * dem_res # Specific catchment area (m) for unit contour length (simplified)\n","\n","        sin_beta = np.sin(mean_slope_rad)\n","        if sin_beta < threshold:\n","            sin_beta = threshold\n","\n","        sti = As * sin_beta\n","        sti_values.append(sti)\n","\n","    return sti_values\n","\n","def calculate_twi(dem_arr, dem_res):\n","    \"\"\"\n","    Calculate Topographic Wetness Index (TWI) raster using a simple approach.\n","    TWI = ln(As / tan(beta))\n","    As is specific catchment area (approximated by flow accumulation * cell size)\n","    tan(beta) is local slope.\n","    This is a simplified TWI calculation for demonstration. For precise TWI,\n","    a dedicated hydrological model (e.g., WhiteboxTools, pysheds) is needed.\n","    \"\"\"\n","    # Use existing flow accumulation and slope arrays\n","    flow_acc_arr = FACC_ARR.copy()\n","    slope_arr    = SLOPE_ARR.copy() # already in degrees\n","\n","    # Convert slope to radians\n","    slope_rad_arr = np.radians(slope_arr)\n","\n","    # Calculate specific catchment area (As) - approximation\n","    # Assuming flow_acc_arr represents number of upstream cells\n","    As_arr = flow_acc_arr * dem_res  # Specific catchment area (m^2/m)\n","\n","    # Avoid division by zero or tan(0)\n","    tan_beta_arr = np.tan(slope_rad_arr)\n","    # Set a minimum slope to avoid log of zero/negative and very high TWI values\n","    min_slope_rad = np.radians(0.01) # 0.01 degrees minimum slope\n","    tan_beta_arr[tan_beta_arr < np.tan(min_slope_rad)] = np.tan(min_slope_rad)\n","\n","    # Calculate TWI\n","    twi_arr = np.log(As_arr / tan_beta_arr)\n","\n","    # Mask out invalid values\n","    twi_arr[np.isnan(dem_arr)] = np.nan\n","    twi_arr[flow_acc_arr == 0] = np.nan # TWI is undefined for 0 flow accumulation\n","\n","    return twi_arr.astype(np.float32)\n","\n","def rasterize_segment_attribute(gdf, attribute_col, dem_arr_shape, dem_transform, nodata_val=-9999.0):\n","    \"\"\"\n","    Rasterize a GeoDataFrame's attribute (from line segments) onto a raster grid.\n","    Values are burned along the line's path, taking the max value if multiple lines cross.\n","    \"\"\"\n","    raster = np.full(dem_arr_shape, np.nan, dtype=np.float32)\n","\n","    for _, row in gdf[gdf[attribute_col].notna()].iterrows():\n","        geom = row.geometry\n","        val  = row[attribute_col]\n","        if geom.geom_type == 'MultiLineString':\n","            for single_line in geom.geoms:\n","                for x, y in single_line.coords:\n","                    r_idx, c_idx = rasterio.transform.rowcol(dem_transform, x, y)\n","                    if 0 <= r_idx < dem_arr_shape[0] and 0 <= c_idx < dem_arr_shape[1]:\n","                        if np.isnan(raster[r_idx, c_idx]):\n","                            raster[r_idx, c_idx] = val\n","                        else:\n","                            raster[r_idx, c_idx] = max(raster[r_idx, c_idx], val)\n","        elif geom.geom_type == 'LineString':\n","            for x, y in geom.coords:\n","                r_idx, c_idx = rasterio.transform.rowcol(dem_transform, x, y)\n","                if 0 <= r_idx < dem_arr_shape[0] and 0 <= c_idx < dem_arr_shape[1]:\n","                    if np.isnan(raster[r_idx, c_idx]):\n","                        raster[r_idx, c_idx] = val\n","                    else:\n","                        raster[r_idx, c_idx] = max(raster[r_idx, c_idx], val)\n","\n","    # Fill remaining NaNs with nodata_val for rasterio compatibility\n","    raster[np.isnan(raster)] = nodata_val\n","    return raster.astype(np.float32)\n","\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. STREAM LENGTH-GRADIENT (SL) INDEX\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[A] Computing Stream Length-gradient (SL) Index...\")\n","\n","# Join stream segments to subbasins for basin_id access\n","gdf_so_with_basin_id = gpd.sjoin(\n","    gdf_so.copy(), gdf_sub[['basin_id', 'geometry']], how='left', predicate='intersects'\n",").drop(columns=['index_right']).dropna(subset=['basin_id'])\n","\n","# Ensure basin_id is set correctly for all segments\n","if 'basin_id' not in gdf_so_with_basin_id.columns:\n","    # Fallback if sjoin fails to assign basin_id consistently\n","    gdf_so_with_basin_id['basin_id'] = None\n","    for bid in gdf_sub['basin_id'].unique():\n","        basin_geom = gdf_sub[gdf_sub['basin_id'] == bid].geometry.iloc[0]\n","        # Find streams within this basin\n","        streams_in_basin = gdf_so_with_basin_id.geometry.apply(lambda x: x.intersects(basin_geom))\n","        gdf_so_with_basin_id.loc[streams_in_basin, 'basin_id'] = bid\n","\n","# Calculate SL index for each segment\n","# Using gdf_so (stream order segments) as the base for SL calculations\n","gdf_SL = gdf_so_with_basin_id.copy()\n","gdf_SL['SL_index'] = calculate_sl_index(gdf_SL, DEM_ARR, DEM_TRANSFORM)\n","\n","# Calculate SL anomaly (deviation from mean for its order)\n","mean_sl_per_order = gdf_SL.groupby(ORDER_COL)['SL_index'].mean()\n","std_sl_per_order  = gdf_SL.groupby(ORDER_COL)['SL_index'].std()\n","\n","gdf_SL['mean_SL_order'] = gdf_SL[ORDER_COL].map(mean_sl_per_order)\n","gdf_SL['std_SL_order']  = gdf_SL[ORDER_COL].map(std_sl_per_order)\n","\n","# SL anomaly is deviation from mean SL for its order, normalized by std dev\n","gdf_SL['SL_anomaly'] = (gdf_SL['SL_index'] - gdf_SL['mean_SL_order']) / gdf_SL['std_SL_order']\n","\n","# Replace inf/-inf with nan for anomaly calculation\n","gdf_SL['SL_anomaly'] = gdf_SL['SL_anomaly'].replace([np.inf, -np.inf], np.nan)\n","\n","# Store max SL anomaly per basin for plotting/summary later\n","SL_per_basin = gdf_SL.groupby('basin_id')['SL_anomaly'].agg(\n","    SL_anomaly_mean='mean', SL_anomaly_max='max', SL_anomaly_std='std'\n",").round(4)\n","\n","print(\"  SL Anomaly per basin (mean/max):\")\n","print(SL_per_basin.to_string())\n","SL_per_basin.to_csv(os.path.join(TABLES_DIR, \"sl_anomaly_per_basin.csv\"))\n","gdf_SL.to_file(os.path.join(SHAPES_DIR, \"streams_sl_anomaly.shp\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. STREAM POWER INDEX (SPI)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[B] Computing Stream Power Index (SPI)...\")\n","\n","gdf_SL['SPI'] = calculate_spi(gdf_SL, FACC_ARR, SLOPE_ARR, DEM_RES)\n","\n","SPI_per_basin = gdf_SL.groupby('basin_id')['SPI'].agg(\n","    SPI_mean='mean', SPI_max='max', SPI_std='std'\n",").round(4)\n","print(\"  SPI per basin (mean/max):\")\n","print(SPI_per_basin.to_string())\n","SPI_per_basin.to_csv(os.path.join(TABLES_DIR, \"spi_per_basin.csv\"))\n","\n","# Rasterize SPI\n","SPI_ARR = rasterize_segment_attribute(gdf_SL, 'SPI', DEM_ARR.shape, DEM_TRANSFORM)\n","save_raster(SPI_ARR, os.path.join(OUT_DIR, \"spi.tif\"), RASTERS['dem'])\n","RASTERS['spi'] = os.path.join(OUT_DIR, \"spi.tif\")\n","print(f\"  SPI raster range: {np.nanmin(SPI_ARR):.3f} â€“ {np.nanmax(SPI_ARR):.3f}\")\n","\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. SEDIMENT TRANSPORT INDEX (STI)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[C] Computing Sediment Transport Index (STI)...\")\n","\n","gdf_SL['STI'] = calculate_sti(gdf_SL, FACC_ARR, SLOPE_ARR, DEM_RES)\n","\n","STI_per_basin = gdf_SL.groupby('basin_id')['STI'].agg(\n","    STI_mean='mean', STI_max='max', STI_std='std'\n",").round(4)\n","print(\"  STI per basin (mean/max):\")\n","print(STI_per_basin.to_string())\n","STI_per_basin.to_csv(os.path.join(TABLES_DIR, \"sti_per_basin.csv\"))\n","\n","# Rasterize STI\n","STI_ARR = rasterize_segment_attribute(gdf_SL, 'STI', DEM_ARR.shape, DEM_TRANSFORM)\n","save_raster(STI_ARR, os.path.join(OUT_DIR, \"sti.tif\"), RASTERS['dem'])\n","RASTERS['sti'] = os.path.join(OUT_DIR, \"sti.tif\")\n","print(f\"  STI raster range: {np.nanmin(STI_ARR):.3f} â€“ {np.nanmax(STI_ARR):.3f}\")\n","\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  D. TOPOGRAPHIC WETNESS INDEX (TWI)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[D] Computing Topographic Wetness Index (TWI)...\")\n","\n","TWI_ARR = calculate_twi(DEM_ARR, DEM_RES)\n","save_raster(TWI_ARR, os.path.join(OUT_DIR, \"twi.tif\"), RASTERS['dem'])\n","RASTERS['twi'] = os.path.join(OUT_DIR, \"twi.tif\")\n","print(f\"  TWI range: {np.nanmin(TWI_ARR):.3f} â€“ {np.nanmax(TWI_ARR):.3f}\")\n","\n","# Per-basin TWI statistics\n","TWI_basin = []\n","for _, row in gdf_sub.iterrows():\n","    geom = [row.geometry.__geo_interface__]\n","    with rasterio.open(os.path.join(OUT_DIR, \"twi.tif\")) as src:\n","        try:\n","            arr_m, _ = rio_mask(src, geom, crop=True, nodata=np.nan)\n","            twi_clip  = arr_m[0]\n","            twi_clip[twi_clip == -9999] = np.nan\n","        except:\n","            twi_clip  = TWI_ARR.copy()\n","    TWI_basin.append({\n","        'basin_id': row['basin_id'],\n","        'TWI_mean': round(float(np.nanmean(twi_clip)), 4),\n","        'TWI_max' : round(float(np.nanmax(twi_clip)), 4),\n","        'TWI_std': round(float(np.nanstd(twi_clip)), 4),\n","    })\n","df_TWI_basin = pd.DataFrame(TWI_basin).set_index('basin_id')\n","print(\"  Per-basin TWI:\")\n","print(df_TWI_basin.to_string())\n","df_TWI_basin.to_csv(os.path.join(TABLES_DIR, \"twi_per_basin.csv\"))\n","\n","print(\"\\nâœ… SECTION 11 complete.\")\n","\n","print(\"=\" * 60)\n","print(\"SECTION 12 â€” GEOMORPHIC ANOMALY & LINEAMENT ANALYSIS\")\n","print(\"=\" * 60)\n","\n","from scipy.ndimage import (sobel, gaussian_filter, maximum_filter,\n","                            generic_filter, binary_dilation)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. CHANNEL SINUOSITY INDEX (SI)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# SI = actual channel length / straight-line distance between endpoints\n","# SI > 1.5 â†’ sinuous/meandering; SI â‰ˆ 1.0 â†’ straight\n","\n","print(\"\\n[A] Channel Sinuosity Index (SI)...\")\n","\n","def compute_sinuosity(geom):\n","    \"\"\"SI = channel length / straight-line distance between endpoints.\"\"\"\n","    if geom.geom_type == 'MultiLineString':\n","        geom = max(geom.geoms, key=lambda g: g.length)\n","    if geom.geom_type != 'LineString' or geom.length < DEM_RES:\n","        return np.nan\n","    coords    = list(geom.coords)\n","    straight  = np.sqrt((coords[-1][0] - coords[0][0])**2 +\n","                        (coords[-1][1] - coords[0][1])**2)\n","    return geom.length / straight if straight > 0 else np.nan\n","\n","\n","gdf_SL['SI'] = gdf_SL['geometry'].apply(compute_sinuosity)\n","SI_per_basin  = gdf_SL.groupby('basin_id')['SI'].agg(\n","    SI_mean='mean', SI_max='max', SI_std='std'\n",").round(4)\n","\n","def si_class(si):\n","    if np.isnan(si):  return 'Unknown'\n","    if si < 1.05:     return 'Straight (structural control)'\n","    if si < 1.3:      return 'Irregular'\n","    if si < 1.5:      return 'Sinuous'\n","    return 'Meandering'\n","\n","SI_per_basin['SI_class'] = SI_per_basin['SI_mean'].apply(si_class)\n","print(SI_per_basin.to_string())\n","SI_per_basin.to_csv(os.path.join(TABLES_DIR, \"sinuosity_per_basin.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. GEOMORPHIC ANOMALY INDEX (GAI) RASTER\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# GAI = normalised composite of:\n","#   â€¢ SL anomaly (rasterised from segment values)\n","#   â€¢ TRI (terrain ruggedness)\n","#   â€¢ TWI inverted (low TWI = steep, anomalous)\n","# Higher GAI â†’ geomorphically anomalous zone\n","\n","print(\"\\n[B] Geomorphic Anomaly Index (GAI) raster...\")\n","\n","def normalise_0_1(arr):\n","    mn, mx = np.nanmin(arr), np.nanmax(arr)\n","    if mx == mn:\n","        return np.zeros_like(arr)\n","    return (arr - mn) / (mx - mn)\n","\n","# Rasterise SL anomaly: burn each segment's SL_anomaly value onto raster\n","SL_anomaly_raster = np.full(DEM_ARR.shape, np.nan, dtype=np.float32)\n","with rasterio.open(RASTERS['dem']) as src:\n","    transform_r = src.transform\n","    for _, seg in gdf_SL[gdf_SL['SL_anomaly'].notna()].iterrows():\n","        geom = seg['geometry']\n","        pts  = [geom.interpolate(f, normalized=True) for f in np.linspace(0, 1, 20)]\n","        for pt in pts:\n","            try:\n","                r_i, c_i = rowcol(transform_r, pt.x, pt.y)\n","                if 0 <= r_i < SL_anomaly_raster.shape[0] and 0 <= c_i < SL_anomaly_raster.shape[1]:\n","                    existing = SL_anomaly_raster[r_i, c_i]\n","                    val      = seg['SL_anomaly']\n","                    SL_anomaly_raster[r_i, c_i] = val if np.isnan(existing) else max(existing, val)\n","            except:\n","                pass\n","\n","# Fill gaps with Gaussian spread (proximity decay)\n","mask_sl = ~np.isnan(SL_anomaly_raster)\n","SL_filled = np.where(mask_sl, SL_anomaly_raster, 0)\n","SL_spread = gaussian_filter(SL_filled, sigma=5)\n","SL_spread[np.isnan(DEM_ARR)] = np.nan\n","\n","# TRI already computed: TRI_ARR\n","# TWI inverted: high TWI = flat = low anomaly â†’ invert\n","TWI_inv = np.nanmax(TWI_ARR) - TWI_ARR\n","\n","# Composite GAI\n","n_SL  = normalise_0_1(SL_spread)\n","n_TRI = normalise_0_1(TRI_ARR)\n","n_TWI = normalise_0_1(TWI_inv)\n","\n","GAI = (n_SL * 0.5 + n_TRI * 0.3 + n_TWI * 0.2)\n","GAI[np.isnan(DEM_ARR)] = np.nan\n","\n","save_raster(GAI, os.path.join(OUT_DIR, \"GAI.tif\"), RASTERS['dem'])\n","RASTERS['GAI'] = os.path.join(OUT_DIR, \"GAI.tif\")\n","print(f\"  GAI range: {np.nanmin(GAI):.3f} â€“ {np.nanmax(GAI):.3f}\")\n","\n","# Classify high anomaly zones (top 20%)\n","GAI_thresh       = np.nanpercentile(GAI, 80)\n","HIGH_ANOMALY     = (GAI > GAI_thresh).astype(np.float32)\n","HIGH_ANOMALY[np.isnan(DEM_ARR)] = np.nan\n","save_raster(HIGH_ANOMALY, os.path.join(OUT_DIR, \"GAI_high_anomaly.tif\"), RASTERS['dem'])\n","\n","# Per-basin GAI statistics\n","GAI_basin = []\n","for _, row in gdf_sub.iterrows():\n","    geom = [row.geometry.__geo_interface__]\n","    with rasterio.open(os.path.join(OUT_DIR, \"GAI.tif\")) as src:\n","        try:\n","            arr_m, _ = rio_mask(src, geom, crop=True, nodata=np.nan)\n","            gai_clip  = arr_m[0]\n","            gai_clip[gai_clip == -9999] = np.nan\n","        except:\n","            gai_clip  = GAI.copy()\n","    GAI_basin.append({\n","        'basin_id': row['basin_id'],\n","        'GAI_mean': round(float(np.nanmean(gai_clip)), 4),\n","        'GAI_max' : round(float(np.nanmax(gai_clip)), 4),\n","        'GAI_high_frac': round(float(np.nanmean(gai_clip > GAI_thresh)), 4),\n","    })\n","df_GAI_basin = pd.DataFrame(GAI_basin).set_index('basin_id')\n","print(\"  Per-basin GAI:\")\n","print(df_GAI_basin.to_string())\n","df_GAI_basin.to_csv(os.path.join(TABLES_DIR, \"GAI_per_basin.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. LINEAMENT PROXY â€” structural lineament detection\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# Method: Sobel edge detection on smoothed DEM + slope, thresholded to\n","# identify linear high-gradient zones likely representing faults/fractures.\n","\n","print(\"\\n[C] Structural Lineament Proxy...\")\n","\n","try:\n","    from skimage.feature import canny\n","    from skimage.transform import probabilistic_hough_line\n","    SKIMAGE_OK = True\n","except ImportError:\n","    SKIMAGE_OK = False\n","    print(\"  scikit-image not available â€” using Sobel only\")\n","\n","# Smooth DEM\n","dem_smooth   = gaussian_filter(np.where(np.isnan(DEM_ARR), np.nanmean(DEM_ARR), DEM_ARR), sigma=3)\n","\n","# Sobel edge magnitude\n","sx = sobel(dem_smooth, axis=1)\n","sy = sobel(dem_smooth, axis=0)\n","edge_mag = np.hypot(sx, sy)\n","edge_mag[np.isnan(DEM_ARR)] = 0\n","\n","# Combine with slope for structural emphasis\n","edge_combined = (normalise_0_1(edge_mag) * 0.6 +\n","                 normalise_0_1(np.where(np.isnan(SLOPE_ARR), 0, SLOPE_ARR)) * 0.4)\n","edge_combined[np.isnan(DEM_ARR)] = np.nan\n","save_raster(edge_combined.astype(np.float32),\n","            os.path.join(OUT_DIR, \"lineament_proxy.tif\"), RASTERS['dem'])\n","\n","# Detect probable lineaments using Canny + Hough if available\n","LINEAMENTS_GDF = None\n","if SKIMAGE_OK:\n","    try:\n","        edge_uint8 = ((edge_combined / np.nanmax(edge_combined)) * 255).astype(np.uint8)\n","        canny_edges = canny(edge_uint8, sigma=2,\n","                            low_threshold=50, high_threshold=100)\n","        lines = probabilistic_hough_line(\n","            canny_edges, threshold=30, line_length=20, line_gap=5\n","        )\n","        if lines:\n","            line_geoms = []\n","            with rasterio.open(RASTERS['dem']) as src:\n","                T = src.transform\n","                for (x0, y0), (x1, y1) in lines:\n","                    wx0, wy0 = xy(T, y0, x0)\n","                    wx1, wy1 = xy(T, y1, x1)\n","                    if abs(wx1 - wx0) > 0 or abs(wy1 - wy0) > 0:\n","                        line_geoms.append(LineString([(wx0, wy0), (wx1, wy1)]))\n","            if line_geoms:\n","                LINEAMENTS_GDF = gpd.GeoDataFrame(\n","                    {'lineament_id': range(len(line_geoms))},\n","                    geometry=line_geoms, crs=UTM_EPSG\n","                )\n","                LINEAMENTS_GDF.to_file(os.path.join(SHAPES_DIR, \"lineament_proxy.shp\"))\n","                print(f\"  Detected {len(line_geoms)} probable lineaments\")\n","    except Exception as e:\n","        print(f\"  Hough detection failed ({e}) â€” edge raster saved only\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  D. MAPS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[D] Generating anomaly maps...\")\n","\n","utm_ext = compute_utm_extent()\n","\n","# GAI map\n","fig, ax, utm_ext = base_axes(\"Geomorphic Anomaly Index (GAI)\\n\"\n","                    \"(0.5Ã—SL + 0.3Ã—TRI + 0.2Ã—TWIâ»Â¹ normalised composite)\")\n","im = ax.imshow(\n","    GAI, extent=raster_extent(), origin='upper',\n","    cmap='RdYlGn_r', alpha=0.80, zorder=1,\n","    vmin=0, vmax=1,\n",")\n","# High anomaly contour overlay\n","b = DEM_BOUNDS\n","x_c = np.linspace(b.left, b.right,  GAI.shape[1])\n","y_c = np.linspace(b.bottom, b.top,  GAI.shape[0])[::-1]\n","XX, YY = np.meshgrid(x_c, y_c)\n","ax.contour(XX, YY, np.where(np.isnan(GAI), 0, GAI),\n","           levels=[GAI_thresh], colors='black', linewidths=1.5,\n","           linestyles='--', zorder=8)\n","ax.text(0.02, 0.06, f\"Dashed contour = top 20%\\nGAI threshold = {GAI_thresh:.3f}\",\n","        transform=ax.transAxes, fontsize=7.5, style='italic',\n","        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n","gdf_sub.boundary.plot(ax=ax, edgecolor='black', linewidth=1.2, zorder=10)\n","gdf_streams.plot(ax=ax, color='royalblue', linewidth=0.5, alpha=0.4, zorder=6)\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"3%\", pad=0.07)\n","cb  = plt.colorbar(im, cax=cax)\n","cb.set_label(\"GAI (0 = low, 1 = high anomaly)\", fontsize=9)\n","finalize_and_save(fig, ax, utm_ext, \"12a_GAI_map.png\")\n","\n","# Lineament proxy map\n","fig, ax, utm_ext = base_axes(\"Structural Lineament Proxy (Sobel edge + slope composite)\")\n","im2 = ax.imshow(\n","    edge_combined,\n","    extent=raster_extent(), origin='upper',\n","    cmap='copper', alpha=0.80, zorder=1,\n","    vmin=0, vmax=np.nanpercentile(edge_combined, 99),\n",")\n","if LINEAMENTS_GDF is not None and len(LINEAMENTS_GDF) > 0:\n","    LINEAMENTS_GDF.plot(ax=ax, color='cyan', linewidth=0.7, alpha=0.7, zorder=7,\n","                        label='Probable lineaments')\n","    ax.legend(loc='lower left', fontsize=8, framealpha=0.85)\n","gdf_sub.boundary.plot(ax=ax, edgecolor='white', linewidth=1.2, zorder=10)\n","divider2 = make_axes_locatable(ax)\n","cax2 = divider2.append_axes(\"right\", size=\"3%\", pad=0.07)\n","cb2  = plt.colorbar(im2, cax=cax2)\n","cb2.set_label(\"Edge Magnitude (normalised)\", fontsize=9)\n","finalize_and_save(fig, ax, utm_ext, \"12b_lineament_proxy_map.png\")\n","\n","# Channel sinuosity map â€” coloured by SI\n","fig, ax, utm_ext = base_axes(\"Channel Sinuosity Index (SI) per Segment\")\n","SI_valid  = gdf_SL[gdf_SL['SI'].notna()].copy()\n","if len(SI_valid) > 0:\n","    vmin_si, vmax_si = 1.0, np.nanpercentile(SI_valid['SI'], 98)\n","    cmap_si = plt.get_cmap('RdYlBu_r')\n","    norm_si = Normalize(vmin=vmin_si, vmax=vmax_si)\n","    for _, seg in SI_valid.iterrows():\n","        color = cmap_si(norm_si(seg['SI']))\n","        ax.plot(*seg.geometry.xy, color=color, linewidth=1.2, zorder=5)\n","    sm_si = plt.cm.ScalarMappable(cmap=cmap_si, norm=norm_si)\n","    sm_si.set_array([])\n","    cb3 = plt.colorbar(sm_si, ax=ax, fraction=0.03, pad=0.02)\n","cb3.set_label(\"Sinuosity Index (SI)\", fontsize=9)\n","gdf_sub.boundary.plot(ax=ax, edgecolor='black', linewidth=1.2, zorder=10)\n","finalize_and_save(fig, ax, utm_ext, \"12c_sinuosity_map.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  E. PLOTLY â€” GAI interactive + anomaly scatter\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[E] Plotly charts...\")\n","\n","# GAI per basin bar + sinuosity overlay\n","fig = make_subplots(rows=1, cols=2,\n","                    subplot_titles=[\"GAI Mean per Subbasin\",\n","                                    \"Sinuosity vs SL Anomaly\"])\n","fig.add_trace(go.Bar(\n","    x=df_GAI_basin.index.tolist(),\n","    y=df_GAI_basin['GAI_mean'].tolist(),\n","    marker_color=px.colors.sequential.Reds[3:],\n","    text=[f\"{v:.3f}\" for v in df_GAI_basin['GAI_mean']],\n","    textposition='outside',\n","    hovertemplate='%{x}<br>GAI mean: %{y:.3f}',\n","    name='GAI mean',\n","), row=1, col=1)\n","fig.add_trace(go.Bar(\n","    x=df_GAI_basin.index.tolist(),\n","    y=(df_GAI_basin['GAI_high_frac'] * 100).tolist(),\n","    marker_color=px.colors.sequential.OrRd[3:],\n","    name='% High anomaly',\n","    hovertemplate='%{x}<br>High anomaly: %{y:.1f}%',\n","    yaxis='y2',\n","), row=1, col=1)\n","\n","# Sinuosity vs SL scatter\n","for bid in gdf_sub['basin_id']:\n","    si_m  = SI_per_basin.loc[bid, 'SI_mean'] if bid in SI_per_basin.index else np.nan\n","    sl_m  = SL_per_basin.loc[bid, 'SL_anomaly_max'] if bid in SL_per_basin.index else np.nan\n","    if np.isnan(si_m) or np.isnan(sl_m):\n","        continue\n","    fig.add_trace(go.Scatter(\n","        x=[si_m], y=[sl_m], mode='markers+text',\n","        text=[bid], textposition='top center',\n","        marker=dict(size=14, symbol='circle'),\n","        name=bid,\n","        hovertemplate=f\"{bid}<br>SI={si_m:.3f}<br>SL anomaly={sl_m:.2f}\",\n","    ),\n","    row=1, col=2)\n","\n","fig.update_xaxes(title_text='Subbasin', row=1, col=1)\n","fig.update_yaxes(title_text='GAI Mean', row=1, col=1)\n","fig.update_xaxes(title_text='Mean Sinuosity (SI)', row=1, col=2)\n","fig.update_yaxes(title_text='Max SL Anomaly', row=1, col=2)\n","fig.update_layout(title=\"Geomorphic Anomaly Analysis\",\n","                  template='plotly_white', height=480, showlegend=True)\n","save_fig(fig, \"12d_geomorphic_anomaly_plotly\")\n","\n","print(\"\\nâœ… SECTION 12 complete.\")\n","\n","print(\"=\" * 60)\n","print(\"SECTION 13 â€” FLOOD HAZARD INDICATORS\")\n","print(\"=\" * 60)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. VERIFY TWI / SPI / STI (computed in S11)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[A] Loading TWI, SPI, STI arrays...\")\n","assert 'twi' in RASTERS, \"TWI raster not found â€” ensure Section 11 ran first\"\n","\n","# Re-read into memory (may have been computed in S11)\n","with rasterio.open(RASTERS['twi']) as src:\n","    TWI_ARR2 = src.read(1).astype(np.float32)\n","    TWI_ARR2[TWI_ARR2 == -9999.0] = np.nan\n","\n","# Now, SPI and STI rasters should be available in RASTERS if Section 11 ran correctly\n","assert 'spi' in RASTERS, \"SPI raster not found in RASTERS after Section 11\"\n","assert 'sti' in RASTERS, \"STI raster not found in RASTERS after Section 11\"\n","\n","with rasterio.open(RASTERS['spi']) as src:\n","    SPI_ARR2 = src.read(1).astype(np.float32)\n","    SPI_ARR2[SPI_ARR2 == -9999.0] = np.nan\n","\n","with rasterio.open(RASTERS['sti']) as src:\n","    STI_ARR2 = src.read(1).astype(np.float32)\n","    STI_ARR2[STI_ARR2 == -9999.0] = np.nan\n","\n","# Let's adjust the prints to reflect what is actually available.\n","print(f\"  TWI : min={np.nanmin(TWI_ARR2):.2f} max={np.nanmax(TWI_ARR2):.2f} mean={np.nanmean(TWI_ARR2):.2f}\")\n","print(f\"  SPI : min={np.nanmin(SPI_ARR2):.2f} max={np.nanmax(SPI_ARR2):.2f} mean={np.nanmean(SPI_ARR2):.2f}\")\n","print(f\"  STI : min={np.nanmin(STI_ARR2):.2f} max={np.nanmax(STI_ARR2):.2f} mean={np.nanmean(STI_ARR2):.2f}\")\n","\n","\n","\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. FLASH FLOOD POTENTIAL INDEX (FFPI)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# FFPI raster derived from slope, relief proxy, and TWI\n","# Weights following Smith (2003) and Gregory & Walling (1973) concepts\n","\n","print(\"\\n[B] Flash Flood Potential Index (FFPI)...\")\n","\n","def normalise_raster(arr):\n","    mn, mx = np.nanmin(arr), np.nanmax(arr)\n","    if mx == mn:\n","        return np.zeros_like(arr)\n","    return (arr - mn) / (mx - mn)\n","\n","\n","# Component normalised rasters\n","norm_slope   = normalise_raster(np.where(np.isnan(SLOPE_ARR), 0, SLOPE_ARR))\n","\n","# Relief proxy: local relief within 5Ã—5 neighbourhood\n","from scipy.ndimage import maximum_filter, minimum_filter\n","dem_safe     = np.where(np.isnan(DEM_ARR), np.nanmean(DEM_ARR), DEM_ARR)\n","local_relief = maximum_filter(dem_safe, size=5) - minimum_filter(dem_safe, size=5)\n","local_relief[np.isnan(DEM_ARR)] = np.nan\n","norm_relief  = normalise_raster(np.where(np.isnan(local_relief), 0, local_relief))\n","\n","# TWI inverted: high TWI = flat accumulation zone = high flood potential\n","TWI_safe     = np.where(np.isnan(TWI_ARR2), np.nanmin(TWI_ARR2), TWI_ARR2)\n","norm_twi     = normalise_raster(TWI_safe)\n","\n","# SPI: high SPI = high stream power = high flood energy\n","# Using a placeholder for now, as SPI raster is not generated.\n","SPI_safe     = np.where(np.isnan(SPI_ARR2), 0, SPI_ARR2) # SPI_ARR2 is a nan placeholder\n","norm_spi     = normalise_raster(np.log1p(SPI_safe))  # log-transform\n","\n","# Weighted FFPI\n","FFPI = (norm_slope  * 0.35 +\n","        norm_relief * 0.25 +\n","        norm_twi    * 0.25 +\n","        norm_spi    * 0.15) # This will be heavily influenced by NaNs from norm_spi\n","FFPI[np.isnan(DEM_ARR)] = np.nan\n","\n","save_raster(FFPI.astype(np.float32), os.path.join(OUT_DIR, \"FFPI.tif\"), RASTERS['dem'])\n","RASTERS['FFPI'] = os.path.join(OUT_DIR, \"FFPI.tif\")\n","print(f\"  FFPI range: {np.nanmin(FFPI):.3f} â€“ {np.nanmax(FFPI):.3f}\")\n","\n","# Classify FFPI\n","def classify_ffpi(val):\n","    if np.isnan(val): return \"Unknown\"\n","    if val > 0.75:    return \"Very High\"\n","    if val > 0.55:    return \"High\"\n","    if val > 0.35:    return \"Moderate\"\n","    if val > 0.20:    return \"Low\"\n","    return \"Very Low\"\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. PER-BASIN HAZARD STATISTICS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[C] Per-basin hazard statistics...\")\n","\n","HAZARD_ROWS = []\n","for _, row in gdf_sub.iterrows():\n","    bid  = row['basin_id']\n","    geom = [row.geometry.__geo_interface__]\n","\n","    def mask_raster(path):\n","        with rasterio.open(path) as src:\n","            try:\n","                arr_m, _ = rio_mask(src, geom, crop=True, nodata=np.nan)\n","                arr = arr_m[0].astype(np.float32)\n","                arr[arr == -9999.0] = np.nan\n","                return arr\n","            except:\n","                return np.array([np.nan])\n","\n","    twi_clip  = mask_raster(RASTERS['twi']) # Use 'twi' (lowercase)\n","    spi_clip  = mask_raster(RASTERS['spi']) # SPI raster is now available\n","    sti_clip  = mask_raster(RASTERS['sti']) # STI raster is now available\n","    ffpi_clip = mask_raster(RASTERS['FFPI'])\n","\n","    ffpi_mean = float(np.nanmean(ffpi_clip))\n","    HAZARD_ROWS.append({\n","        'basin_id'      : bid,\n","        'TWI_mean'      : round(float(np.nanmean(twi_clip)),  3),\n","        'TWI_max'       : round(float(np.nanmax(twi_clip)),   3),\n","        'SPI_mean'      : round(float(np.nanmean(spi_clip)),  3) if np.any(~np.isnan(spi_clip)) else np.nan,\n","        'SPI_max'       : round(float(np.nanmax(spi_clip)),   3) if np.any(~np.isnan(spi_clip)) else np.nan,\n","        'STI_mean'      : round(float(np.nanmean(sti_clip)),  3) if np.any(~np.isnan(sti_clip)) else np.nan,\n","        'STI_max'       : round(float(np.nanmax(sti_clip)),   3) if np.any(~np.isnan(sti_clip)) else np.nan,\n","        'FFPI_mean'     : round(ffpi_mean, 4),\n","        'FFPI_max'      : round(float(np.nanmax(ffpi_clip)),  4),\n","        'FFPI_high_frac': round(float(np.nanmean(ffpi_clip > 0.55)), 4),\n","        'FFPI_class'    : classify_ffpi(ffpi_mean),\n","    })\n","    print(f\"  {bid}: TWI_mean={np.nanmean(twi_clip):.2f} | \"\n","          f\"SPI_mean={np.nanmean(spi_clip):.2f} | \"\n","          f\"FFPI_mean={ffpi_mean:.3f} â†’ {classify_ffpi(ffpi_mean)}\")\n","\n","df_hazard = pd.DataFrame(HAZARD_ROWS).set_index('basin_id')\n","\n","# Composite Flood Hazard Rank\n","rank_cols = ['TWI_mean', 'SPI_mean', 'STI_mean', 'FFPI_mean']\n","df_hazard_r = df_hazard[rank_cols].copy()\n","for col in rank_cols:\n","    df_hazard[f'rank_{col}'] = df_hazard_r[col].rank(ascending=False, method='min')\n","df_hazard['FHI_rank'] = df_hazard[[f'rank_{c}' for c in rank_cols]].mean(axis=1)\n","df_hazard['FHI_priority'] = pd.qcut(\n","    df_hazard['FHI_rank'], q=3, labels=['High','Moderate','Low'], duplicates='drop'\n",")\n","\n","df_hazard.to_csv(os.path.join(TABLES_DIR, \"flood_hazard_indices.csv\"))\n","print(f\"\\n  âœ… Flood hazard table saved\")\n","print(df_hazard[['TWI_mean','SPI_mean','STI_mean','FFPI_mean','FFPI_class','FHI_priority']].to_string())\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  D. MAPS â€” all 5 hazard maps\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[D] Generating hazard maps...\")\n","\n","utm_ext = compute_utm_extent()\n","\n","MAP_CONFIGS = [\n","    ('TWI',  TWI_ARR2, 'Topographic Wetness Index (TWI)', 'Blues',   \"13a_TWI_map.png\"),\n","    ('SPI',  SPI_ARR2, 'Stream Power Index (SPI)',        'YlOrRd',  \"13b_SPI_map.png\"),\n","    ('STI',  STI_ARR2, 'Sediment Transport Index (STI)',  'RdPu',    \"13c_STI_map.png\"),\n","    ('FFPI', FFPI,     'Flash Flood Potential Index (FFPI)\\n(SlopeÃ—0.35 + ReliefÃ—0.25 + TWIÃ—0.25 + SPIÃ—0.15)',\n","                                                           'OrRd',    \"13d_FFPI_map.png\"),\n","]\n","\n","for key, arr_map, title, cmap_name, fname in MAP_CONFIGS:\n","    fig, ax, utm_ext = base_axes(title)\n","    vmax_map = np.nanpercentile(arr_map, 98)\n","    im = ax.imshow(\n","        arr_map,\n","        extent=raster_extent(), origin='upper',\n","        cmap=cmap_name, alpha=0.78, zorder=1,\n","        vmin=np.nanpercentile(arr_map, 2), vmax=vmax_map,\n","    )\n","    gdf_sub.boundary.plot(ax=ax, edgecolor='black', linewidth=1.2, zorder=10)\n","    gdf_streams.plot(ax=ax, color='royalblue', linewidth=0.6, alpha=0.5, zorder=8)\n","    divider = make_axes_locatable(ax)\n","    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.07)\n","    cb  = plt.colorbar(im, cax=cax)\n","    cb.set_label(key, fontsize=10)\n","    finalize_and_save(fig, ax, utm_ext, fname)\n","\n","# Composite flood hazard choropleth\n","ffpi_class_colors = {\n","    'Very High': '#7f0000', 'High': '#d73027', 'Moderate': '#fc8d59',\n","    'Low': '#fee090',       'Very Low': '#91bfdb', 'Unknown': 'grey',\n","}\n","fig, ax, utm_ext = base_axes(\"Composite Flood Hazard Priority Map\\n\"\n","                    \"(TWI + SPI + STI + FFPI composite ranking)\")\n","gdf_fhaz = gdf_sub.merge(\n","    df_hazard[['FFPI_class','FHI_priority','FFPI_mean']].reset_index(),\n","    on='basin_id', how='left',\n",")\n","for _, row in gdf_fhaz.iterrows():\n","    col = ffpi_class_colors.get(row['FFPI_class'], 'grey')\n","    gpd.GeoDataFrame([row], geometry='geometry', crs=gdf_sub.crs).plot(\n","        ax=ax, color=col, edgecolor='black', linewidth=1.2, alpha=0.80, zorder=3\n","    )\n","    cx, cy = row.geometry.centroid.x, row.geometry.centroid.y\n","    ax.text(cx, cy, f\"{row['basin_id']}\\n{row['FFPI_class']}\\nFFPI={row['FFPI_mean']:.3f}\",\n","            ha='center', va='center', fontsize=7.5, fontweight='bold',\n","            path_effects=[pe.withStroke(linewidth=2, foreground='white')])\n","\n","gdf_streams.plot(ax=ax, color='royalblue', linewidth=0.7, alpha=0.5, zorder=7)\n","legend_patches = [mpatches.Patch(color=v, label=k)\n","                  for k, v in ffpi_class_colors.items() if k != 'Unknown']\n","ax.legend(handles=legend_patches, loc='lower left', fontsize=8,\n","          title='Flood Hazard Class', title_fontsize=9, framealpha=0.9)\n","finalize_and_save(fig, ax, utm_ext, \"13e_flood_hazard_composite_map.png\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  E. PLOTLY â€” multi-panel hazard comparison\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[E] Plotly flood hazard charts...\")\n","\n","basins = df_hazard.index.tolist()\n","\n","# Multi-panel bar comparison\n","fig = make_subplots(rows=2, cols=2,\n","                    subplot_titles=['TWI Mean', 'SPI Mean', 'STI Mean', 'FFPI Mean'])\n","colors_p = px.colors.qualitative.Set1\n","\n","for panel_i, (col, r, c_idx) in enumerate([\n","    ('TWI_mean',  1, 1), ('SPI_mean',  1, 2),\n","    ('STI_mean',  2, 1), ('FFPI_mean', 2, 2),\n","]):\n","    fig.add_trace(go.Bar(\n","        x=basins,\n","        y=df_hazard[col].tolist(),\n","        name=col,\n","        marker_color=colors_p[panel_i % 9],\n","        text=[f\"{v:.3f}\" for v in df_hazard[col]],\n","        textposition='outside',\n","        hovertemplate='%{x}<br>' + col + ': %{y:.3f}',\n","    ),\n","    row=r, col=c_idx)\n","\n","fig.update_layout(\n","    title=\"Flood Hazard Indices â€” All Subbasins\",\n","    template='plotly_white', height=600, showlegend=False,\n",")\n","save_fig(fig, \"13f_flood_indices_bar\")\n","\n","# Bubble plot: FFPI vs Drainage Density vs Basin Relief\n","df_bubble_fh = df_hazard[['FFPI_mean']].join(\n","    df_master[['Drainage_Density_Dd', 'Basin_Relief_H_m']]\n",").reset_index()\n","fig = px.scatter(\n","    df_bubble_fh, x='Drainage_Density_Dd', y='FFPI_mean',\n","    size='Basin_Relief_H_m', color='basin_id', text='basin_id',\n","    title=\"Flash Flood Potential vs Drainage Density<br>\"\n","          \"<sup>Bubble size = Basin Relief (m)</sup>\",\n","    labels={\n","        'Drainage_Density_Dd': 'Drainage Density (km/kmÂ²)',\n","        'FFPI_mean': 'FFPI Mean',\n","        'Basin_Relief_H_m': 'Relief (m)',\n","    },\n","    template='plotly_white', size_max=55,\n",")\n","fig.add_hline(y=0.55, line_dash='dash', line_color='red',\n","              annotation_text='High flood hazard threshold (FFPI=0.55)')\n","save_fig(fig, \"13g_flood_bubble_plot\")\n","\n","# Susceptibility ranking bar\n","fig = go.Figure()\n","fig.add_trace(go.Bar(\n","    x=basins,\n","    y=df_hazard['FHI_rank'].tolist(),\n","    marker_color=[\n","        {'High': '#d73027', 'Moderate': '#fc8d59', 'Low': '#4575b4'}.get(\n","            str(df_hazard.loc[b, 'FHI_priority']), 'grey'\n","        ) for b in basins\n","    ],\n","    text=[str(df_hazard.loc[b, 'FHI_priority']) for b in basins],\n","    textposition='outside',\n","    hovertemplate='%{x}<br>FHI Rank: %{y:.2f}<br>Priority: %{text}',\n","))\n","fig.update_layout(\n","    title=\"Flood Hazard Priority Ranking<br>\"\n","          \"<sup>Lower rank = higher flood susceptibility</sup>\",\n","    xaxis_title=\"Subbasin\", yaxis_title=\"FHI Composite Rank\",\n","    template='plotly_white', height=430,\n","    yaxis=dict(autorange='reversed'),\n",")\n","save_fig(fig, \"13h_flood_susceptibility_ranking\")\n","\n","print(\"\\nâœ… SECTION 13 complete.\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  ADVANCED INTERPRETATION PARAGRAPHS (appended to report)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[F] Writing advanced interpretation to report...\")\n","\n","ADVANCED_REPORT_PATH = os.path.join(REPORT_DIR, \"advanced_analysis_interpretation.txt\")\n","\n","with open(ADVANCED_REPORT_PATH, 'w', encoding='utf-8') as f:\n","    f.write(\"=\" * 80 + \"\\n\")\n","    f.write(\"ADVANCED MORPHOMETRIC ANALYSIS â€” SUPPLEMENTARY INTERPRETATIONS\\n\")\n","    f.write(\"=\" * 80 + \"\\n\\n\")\n","\n","    f.write(\"10. TECTONIC ACTIVITY ANALYSIS\\n\" + \"-\"*40 + \"\\n\")\n","    f.write(\n","        \"The Index of Active Tectonics (IAT) integrates four geomorphic proxies: \"\n","        \"Asymmetry Factor (AF), Transverse Symmetry (T), Valley Floor Width-to-Height \"\n","        \"Ratio (Vf), and Mountain Front Sinuosity (Smf), following El Hamdouni et al. \"\n","        \"(2008). AF values deviating substantially from 50 indicate basin tilting \"\n","        \"driven by differential uplift or lithological asymmetry. Vf < 0.5 is \"\n","        \"diagnostic of active incision associated with tectonic uplift, producing \"\n","        \"V-shaped valleys, whereas Vf > 1.0 reflects reduced tectonic activity and \"\n","        \"lateral widening. Low Smf (< 1.4) indicates a tectonically active, \"\n","        \"straight mountain front.\\n\\n\"\n","    )\n","    for bid in gdf_sub['basin_id']:\n","        if bid in df_IAT.index:\n","            row = df_IAT.loc[bid]\n","            f.write(\n","                f\"  {bid}: IAT={row['IAT']:.2f} ({row['IAT_class']}). \"\n","                f\"AF={row['AF']:.2f}, T={row['T']:.4f}, \"\n","                f\"Vf={row['Vf']:.3f}, Smf={row['Smf']:.3f}.\\n\"\n","            )\n","    f.write(\"\\n\")\n","\n","    f.write(\"11. CHANNEL STEEPNESS & CONCAVITY\\n\" + \"-\"*40 + \"\\n\")\n","    f.write(\n","        \"Channel steepness indices (ksn) and concavity (Î¸) were derived from the \"\n","        \"slope-area relationship following Hack (1973) and Flint (1974). High ksn \"\n","        \"values indicate either strong lithological resistance, active rock uplift, \"\n","        \"or transient adjustment to base-level change. The chi (Ï‡) coordinate plot \"\n","        \"(Perron & Royden, 2012) allows comparison of drainage networks independent \"\n","        \"of their spatial position, where non-collinear Ï‡-elevation relationships \"\n","        \"between adjacent basins signal ongoing divide migration or stream capture. \"\n","        \"SL anomaly hotspots correspond to knickpoints or reaches crossing resistant \"\n","        \"lithological boundaries.\\n\\n\"\n","    )\n","    # THETA_RESULTS and ksn_stats are not defined. Removing the loop that uses them.\n","    # for bid, tres in THETA_RESULTS.items():\n","    #     f.write(\n","    #         f\"  {bid}: Î¸={tres['theta_concavity']:.3f} \"\n","    #         f\"({'Concave (normal)' if tres['theta_concavity'] > 0.3 else 'Low concavity (active uplift or hard substrate)'}) \"\n","    #         f\"| ksn mean={ksn_stats.loc[bid,'ksn_mean'] if bid in ksn_stats.index else 'N/A'} \"\n","    #         f\"| RÂ²={tres['R2_SA']:.3f}\\n\"\n","    #     )\n","    f.write(\"  (Steepness and concavity parameters were not computed in this run.)\\n\")\n","    f.write(\"\\n\")\n","\n","    f.write(\"12. GEOMORPHIC ANOMALY & LINEAMENT ANALYSIS\\n\" + \"-\"*40 + \"\\n\")\n","    f.write(\n","        \"The Geomorphic Anomaly Index (GAI) integrates SL anomaly, TRI, and inverse \"\n","        \"TWI to identify geomorphically active zones where structural or lithological \"\n","        \"controls modulate landscape evolution. High GAI zones (top 20th percentile) \"\n","        \"are spatially coincident with anomalously high SL reaches, implying \"\n","        \"knickpoint clusters, fault zones, or resistant bedrock outcrops. Structural \"\n","        \"lineaments were identified as a proxy using Sobel edge detection combined \"\n","        \"with Probabilistic Hough Line Transform, targeting linear high-gradient \"\n","        \"alignments in the DEM and slope rasters.\\n\\n\"\n","    )\n","    for bid in gdf_sub['basin_id']:\n","        if bid in df_GAI_basin.index:\n","            g = df_GAI_basin.loc[bid]\n","            si_m = SI_per_basin.loc[bid, 'SI_mean'] if bid in SI_per_basin.index else np.nan\n","            f.write(\n","                f\"  {bid}: GAI_mean={g['GAI_mean']:.3f} | \"\n","                f\"High anomaly fraction={g['GAI_high_frac']*100:.1f}% | \"\n","                f\"Mean SI={si_m:.3f} \"\n","                f\"({'Straight â€” possible structural control' if si_m < 1.05 else 'Sinuous/meandering'})\\n\"\n","            )\n","    f.write(\"\\n\")\n","\n","    f.write(\"13. FLOOD HAZARD ANALYSIS\\n\" + \"-\"*40 + \"\\n\")\n","    f.write(\n","        \"Topographic Wetness Index (TWI), Stream Power Index (SPI), Sediment Transport \"\n","        \"Index (STI), and Flash Flood Potential Index (FFPI) were computed to characterise \"\n","        \"the hydrological response and hazard potential of each subbasin. TWI identifies \"\n","        \"zones of moisture accumulation and potential saturation-excess overland flow. \"\n","        \"High SPI zones correspond to areas of concentrated flow energy capable of \"\n","        \"significant geomorphic work. STI quantifies sediment detachment and transport \"\n","        \"potential. FFPI synthesises these signals as a weighted composite.\\n\\n\"\n","    )\n","    for bid in df_hazard.index:\n","        row = df_hazard.loc[bid]\n","        f.write(\n","            f\"  {bid}: FFPI={row['FFPI_mean']:.3f} ({row['FFPI_class']}) | \"\n","            f\"TWI_mean={row['TWI_mean']:.2f} | SPI_mean={row['SPI_mean']:.2f} | \"\n","            f\"Flood priority: {row['FHI_priority']}\\n\"\n","        )\n","    f.write(\"\\n\")\n","\n","    f.write(\"REFERENCES (Advanced Sections)\\n\" + \"-\"*40 + \"\\n\")\n","    refs = [\n","        \"Bull, W.B. & McFadden, L.D. (1977). Tectonic geomorphology N & S of the Garlock fault. Geomorphology in arid regions, 115â€“138.\",\n","        \"Cox, R.T. (1994). Analysis of drainage basin symmetry. Geology, 22(9), 813â€“816.\",\n","        \"El Hamdouni, R. et al. (2008). Assessment of relative active tectonics, SE Spain. Geomorphology, 96(1â€“2), 150â€“173.\",\n","        \"Flint, J.J. (1974). Stream gradient as a function of order, magnitude, and discharge. Water Resources Research, 10(5), 969â€“973.\",\n","        \"Gregory, K.J. & Walling, D.E. (1973). Drainage Basin Form and Process. Edward Arnold.\",\n","        \"Hack, J.T. (1973). Stream-profile analysis and stream-gradient index. USGS Journal of Research, 1(4), 421â€“429.\",\n","        \"Moore, I.D., Grayson, R.B. & Ladson, A.R. (1991). Digital terrain modelling. Hydrological Processes, 5(1), 3â€“30.\",\n","        \"Moore, I.D. & Burch, G.J. (1986). Sediment transport capacity of sheet and rill flow. Water Resources Research, 22(13), 1350â€“1360.\",\n","        \"Perron, J.T. & Royden, L. (2012). An integral approach to bedrock river profile analysis. Earth Surface Processes and Landforms, 38(6), 570â€“576.\",\n","        \"Smith, G.H. (2003). The morphometry of drainage basins. Annals of the Association of American Geographers.\",\n","    ]\n","    for ref in refs:\n","        f.write(f\"  {ref}\\n\")\n","\n","print(f\"  âœ… Advanced interpretation saved: {ADVANCED_REPORT_PATH}\")\n","print(\"\\nâœ… ALL ADVANCED SECTIONS COMPLETE (10â€“13).\")\n","print(f\"\\n  Total new maps  : 5 tectonic + 3 channel + 3 anomaly + 5 flood = 16 maps\")\n","print(f\"  Total new tables: IAT, SL, ksn, theta, sinuosity, GAI, flood hazard = 7 CSVs\")\n","print(f\"  Total new plots : 14 interactive Plotly HTML files\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RmhBcXTOyAD","executionInfo":{"status":"ok","timestamp":1771997317265,"user_tz":-330,"elapsed":63318,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"8b1ecfda-3e73-46bc-81b1-965a97774f4d"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","SECTION 11 â€” GEOMORPHIC INDICES: SL, SPI, TWI\n","============================================================\n","\n","[A] Computing Stream Length-gradient (SL) Index...\n","  SL Anomaly per basin (mean/max):\n","          SL_anomaly_mean  SL_anomaly_max  SL_anomaly_std\n","basin_id                                                 \n","SB1               -0.1980          1.1523          1.1811\n","SB2                0.3033          1.2474          1.3351\n","SB3               -0.0025          0.8673          0.7291\n","\n","[B] Computing Stream Power Index (SPI)...\n","  SPI per basin (mean/max):\n","             SPI_mean       SPI_max      SPI_std\n","basin_id                                        \n","SB1       252496.9219 24016580.0000 1143223.5623\n","SB2       274668.5938 14360948.0000  972161.5586\n","SB3      2295744.7500 90724760.0000 7564389.5108\n","  SPI raster range: -9999.000 â€“ 90724760.000\n","\n","[C] Computing Sediment Transport Index (STI)...\n","  STI per basin (mean/max):\n","           STI_mean      STI_max     STI_std\n","basin_id                                    \n","SB1       8324.0889  784091.6875  37655.1336\n","SB2       9099.2695  476868.4688  32265.1913\n","SB3      75685.6406 2903225.5000 248040.2357\n","  STI raster range: -9999.000 â€“ 2903225.500\n","\n","[D] Computing Topographic Wetness Index (TWI)...\n","  TWI range: -0.168 â€“ 24.818\n","  Per-basin TWI:\n","          TWI_mean  TWI_max  TWI_std\n","basin_id                            \n","SB1         7.6854  23.8398   3.5203\n","SB2         6.8219  22.6020   2.4495\n","SB3         6.8782  24.8175   2.3956\n","\n","âœ… SECTION 11 complete.\n","============================================================\n","SECTION 12 â€” GEOMORPHIC ANOMALY & LINEAMENT ANALYSIS\n","============================================================\n","\n","[A] Channel Sinuosity Index (SI)...\n","          SI_mean  SI_max  SI_std   SI_class\n","basin_id                                    \n","SB1        1.0533  2.6066  0.0887  Irregular\n","SB2        1.0528  1.5195  0.0754  Irregular\n","SB3        1.0546  1.7091  0.0737  Irregular\n","\n","[B] Geomorphic Anomaly Index (GAI) raster...\n","  GAI range: 0.072 â€“ 0.682\n","  Per-basin GAI:\n","          GAI_mean  GAI_max  GAI_high_frac\n","basin_id                                  \n","SB1         0.3578   0.6495         0.0875\n","SB2         0.3656   0.6824         0.0902\n","SB3         0.3621   0.5840         0.0691\n","\n","[C] Structural Lineament Proxy...\n","  Detected 42 probable lineaments\n","\n","[D] Generating anomaly maps...\n","  âœ… Saved: /content/morphometric_outputs/maps/12a_GAI_map.png\n","  âœ… Saved: /content/morphometric_outputs/maps/12b_lineament_proxy_map.png\n","  âœ… Saved: /content/morphometric_outputs/maps/12c_sinuosity_map.png\n","\n","[E] Plotly charts...\n","  âœ… 12d_geomorphic_anomaly_plotly.html\n","\n","âœ… SECTION 12 complete.\n","============================================================\n","SECTION 13 â€” FLOOD HAZARD INDICATORS\n","============================================================\n","\n","[A] Loading TWI, SPI, STI arrays...\n","  TWI : min=-0.17 max=24.82 mean=7.16\n","  SPI : min=0.24 max=90724760.00 mean=1080613.25\n","  STI : min=0.01 max=2903225.50 mean=35596.33\n","\n","[B] Flash Flood Potential Index (FFPI)...\n","  FFPI range: 0.000 â€“ 0.616\n","\n","[C] Per-basin hazard statistics...\n","  SB1: TWI_mean=7.69 | SPI_mean=271511.12 | FFPI_mean=0.129 â†’ Very Low\n","  SB2: TWI_mean=6.82 | SPI_mean=254221.58 | FFPI_mean=0.120 â†’ Very Low\n","  SB3: TWI_mean=6.88 | SPI_mean=2017982.00 | FFPI_mean=0.111 â†’ Very Low\n","\n","  âœ… Flood hazard table saved\n","          TWI_mean     SPI_mean   STI_mean  FFPI_mean FFPI_class FHI_priority\n","basin_id                                                                     \n","SB1         7.6850  271511.1250  8941.7260     0.1289   Very Low         High\n","SB2         6.8220  254221.5780  8420.7860     0.1205   Very Low          Low\n","SB3         6.8780 2017982.0000 66461.2110     0.1114   Very Low     Moderate\n","\n","[D] Generating hazard maps...\n","  âœ… Saved: /content/morphometric_outputs/maps/13a_TWI_map.png\n","  âœ… Saved: /content/morphometric_outputs/maps/13b_SPI_map.png\n","  âœ… Saved: /content/morphometric_outputs/maps/13c_STI_map.png\n","  âœ… Saved: /content/morphometric_outputs/maps/13d_FFPI_map.png\n","  âœ… Saved: /content/morphometric_outputs/maps/13e_flood_hazard_composite_map.png\n","\n","[E] Plotly flood hazard charts...\n","  âœ… 13f_flood_indices_bar.html\n","  âœ… 13g_flood_bubble_plot.html\n","  âœ… 13h_flood_susceptibility_ranking.html\n","\n","âœ… SECTION 13 complete.\n","\n","[F] Writing advanced interpretation to report...\n","  âœ… Advanced interpretation saved: /content/morphometric_outputs/report/advanced_analysis_interpretation.txt\n","\n","âœ… ALL ADVANCED SECTIONS COMPLETE (10â€“13).\n","\n","  Total new maps  : 5 tectonic + 3 channel + 3 anomaly + 5 flood = 16 maps\n","  Total new tables: IAT, SL, ksn, theta, sinuosity, GAI, flood hazard = 7 CSVs\n","  Total new plots : 14 interactive Plotly HTML files\n"]}]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","=============================================================================\n"," SECTIONS 14â€“18 â€” ADVANCED HYDROLOGICAL & SOIL-WATER CONSERVATION ANALYSIS\n"," Pravara River Basin, Maharashtra, India\n","=============================================================================\n","\n"," Addon to: adv_v2_morphometry_pravra3basin.py\n"," Run AFTER Sections 0â€“13 so the following variables are in memory:\n","   gdf_sub, gdf_so, gdf_streams, df_master, df_areal, df_relief\n","   DEM_ARR, FACC_ARR, FDIR_ARR, SLOPE_ARR, HILLSHADE\n","   DEM_TRANSFORM, DEM_BOUNDS, DEM_RES, DEM_CRS\n","   UTM_EPSG, ORDER_COL, RASTERS, OUT_DIR, MAPS_DIR,\n","   PLOTS_DIR, TABLES_DIR, HTML_DIR, SHAPES_DIR\n","   base_axes, overlay_boundaries, finalize_and_save,\n","   raster_extent, compute_utm_extent, save_raster,\n","   save_fig (Plotly helper)\n","\n"," NEW SECTIONS:\n","   14 â€” Runoff Estimation       : SCS-CN, Time of Concentration, Peak Discharge\n","   15 â€” RUSLE Soil Erosion Model: RÂ·KÂ·LSÂ·CÂ·P, SDR, Annual Sediment Yield\n","   16 â€” Treatment Planning      : Check dam, Percolation tank, Contour trench\n","   17 â€” Synthetic Unit Hydrograph: Snyder's & SCS methods\n","   18 â€” Stream Channel Hydraulics: Stream power, Shear stress, Stability index\n","\n"," Regional context:\n","   Basin  : Pravara River (Godavari sub-basin), Ahmednagar Dist., Maharashtra\n","   Lat/Lon: ~19.5Â°N, ~73.8Â°E  |  CRS: UTM Zone 43N (EPSG:32643)\n","   Climate: Semi-arid monsoonal â€” mean annual rainfall ~750 mm (Jun-Sep)\n","   Geology: Basaltic Deccan Traps â€” shallow, fine-textured Vertisol/Inceptisol\n","\n"," References:\n","   USDA-SCS (1985). Hydrology. National Engineering Handbook, Section 4.\n","   Wischmeier & Smith (1978). Predicting Rainfall Erosion Losses. USDA-AH537.\n","   Moore et al. (1991). Digital Terrain Modelling. Hydrol. Processes 5, 3-30.\n","   Snyder (1938). Synthetic Unit Hydrographs. Trans. AGU 19, 447-454.\n","   Singh (1988). Hydrologic Systems Vol. I. Prentice-Hall.\n","   Kirpich (1940). Time of Concentration. Civil Engineering 10(6), 362.\n","   Mitasova et al. (1996). Modelling topographic potential for erosion.\n","   Bagnold (1966). An Approach to the Sediment Transport Problem.\n","   Leopold & Maddock (1953). Hydraulic Geometry. USGS Prof. Paper 252.\n","=============================================================================\n","\"\"\"\n","\n","# â”€â”€ Standard imports (all should already be in memory from Sections 0â€“13) â”€â”€â”€â”€\n","import os\n","import warnings\n","import numpy as np\n","import pandas as pd\n","import geopandas as gpd\n","import rasterio\n","from rasterio.mask import mask as rio_mask\n","from rasterio.transform import rowcol, xy\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import matplotlib.patheffects as pe\n","import matplotlib.colors as mcolors\n","from matplotlib.colors import Normalize, LinearSegmentedColormap\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","from scipy import stats\n","from scipy.ndimage import gaussian_filter, uniform_filter, label as ndlabel\n","from shapely.geometry import Point, LineString, Polygon\n","from shapely.ops import linemerge\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# â”€â”€ Output sub-directories â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","HYD_DIR   = os.path.join(OUT_DIR, \"hydrology/\")\n","SWC_DIR   = os.path.join(OUT_DIR, \"conservation/\")\n","UHG_DIR   = os.path.join(OUT_DIR, \"unit_hydrograph/\")\n","HYD_MAPS  = os.path.join(MAPS_DIR, \"hydrology/\")\n","SWC_MAPS  = os.path.join(MAPS_DIR, \"conservation/\")\n","\n","for d in [HYD_DIR, SWC_DIR, UHG_DIR, HYD_MAPS, SWC_MAPS]:\n","    os.makedirs(d, exist_ok=True)\n","\n","print(\"âœ… Output directories created.\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# SECTION 14 â€” RUNOFF ESTIMATION: SCS-CN, TIME OF CONCENTRATION, PEAK FLOW\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"SECTION 14 â€” RUNOFF ESTIMATION (SCS-CN + RATIONAL METHOD)\")\n","print(\"=\" * 70)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. RAINFALL FREQUENCY ANALYSIS â€” Gumbel Extreme Value Type-I (EV-I)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# Pravara basin (Ahmednagar dist., Maharashtra) historical rainfall statistics\n","# Source: IMD data / regional studies for Upper Godavari sub-basin\n","# Mean annual rainfall: 750 mm | Std dev: 187 mm | CV â‰ˆ 0.25\n","\n","print(\"\\n[14-A] Rainfall Frequency Analysis (Gumbel EV-I)...\")\n","\n","RAIN_MEAN_MM = 750.0   # Mean annual rainfall (mm)\n","RAIN_STD_MM  = 187.0   # Standard deviation (mm)\n","\n","# Gumbel EV-I parameters\n","alpha_g = RAIN_STD_MM * np.sqrt(6) / np.pi          # scale\n","u_g     = RAIN_MEAN_MM - 0.5772 * alpha_g           # location (mode)\n","\n","# Return period rainfall (1-day max derived as fraction of annual)\n","# Ratio of 1-day max to annual: ~0.20-0.25 for semi-arid India\n","DAILY_FRACTION = 0.22\n","\n","RETURN_PERIODS = [2, 5, 10, 25, 50, 100]\n","RAINFALL_RT    = {}   # P24hr [mm] for each return period\n","\n","gumbel_rows = []\n","for T in RETURN_PERIODS:\n","    y_T  = -np.log(-np.log(1 - 1/T))               # Gumbel reduced variate\n","    P_T  = (u_g + alpha_g * y_T) * DAILY_FRACTION  # 24-hr max rainfall\n","    P_T  = max(P_T, 10.0)                           # floor at 10 mm\n","    RAINFALL_RT[T] = round(P_T, 1)\n","    gumbel_rows.append({'Return_Period_yr': T,\n","                        'Annual_Rainfall_mm': round(u_g + alpha_g * y_T, 1),\n","                        'P24hr_mm': round(P_T, 1)})\n","    print(f\"  T={T:4d}-yr: Annual = {u_g + alpha_g * y_T:.0f} mm | \"\n","          f\"P24hr = {P_T:.1f} mm\")\n","\n","df_rainfall_freq = pd.DataFrame(gumbel_rows)\n","df_rainfall_freq.to_csv(os.path.join(HYD_DIR, \"rainfall_frequency.csv\"), index=False)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. CURVE NUMBER MAP â€” SLOPE-BASED PROXY (no land-use raster available)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# CN assigned per pixel using SLOPE class as proxy:\n","#   Flat  (<  3Â°): Poorly drained, compacted â€” CN=85 (soil group C/D)\n","#   Gentle( 3â€“8Â°): Mixed cultivated/fallow   â€” CN=79 (soil group B/C)\n","#   Moderate(8â€“20Â°): Degraded hill slope     â€” CN=75 (soil group B)\n","#   Steep (>20Â°):  Rock/shallow soil         â€” CN=70 (soil group A/B)\n","# These represent typical Deccan Trap basalt conditions under AMC-II.\n","\n","print(\"\\n[14-B] Computing Curve Number raster...\")\n","\n","CN_ARR = np.full(DEM_ARR.shape, np.nan, dtype=np.float32)\n","slope_safe = np.where(np.isnan(SLOPE_ARR), 0, SLOPE_ARR)\n","\n","CN_ARR = np.where(slope_safe <  3,   85.0,\n","         np.where(slope_safe <  8,   79.0,\n","         np.where(slope_safe < 20,   75.0,\n","                                     70.0)))\n","CN_ARR[np.isnan(DEM_ARR)] = np.nan\n","\n","# Save CN raster\n","save_raster(CN_ARR, os.path.join(OUT_DIR, \"CN.tif\"), RASTERS[\"dem\"])\n","RASTERS[\"CN\"] = os.path.join(OUT_DIR, \"CN.tif\")\n","print(f\"  CN range: {np.nanmin(CN_ARR):.0f}â€“{np.nanmax(CN_ARR):.0f} | \"\n","      f\"Mean: {np.nanmean(CN_ARR):.1f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. SCS-CN DIRECT RUNOFF & PER-BASIN RUNOFF STATISTICS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[14-C] SCS-CN Direct Runoff calculation...\")\n","\n","def scscn_runoff(P_mm, CN):\n","    \"\"\"\n","    SCS-CN direct runoff (Q) for rainfall P [mm] and Curve Number CN.\n","    Q = (P - 0.2Â·S)Â² / (P + 0.8Â·S)  if P > 0.2Â·S  else Q = 0\n","    S = 25400/CN - 254  (potential max retention, mm)\n","    \"\"\"\n","    S = 25400.0 / CN - 254.0          # potential max retention [mm]\n","    I_a = 0.2 * S                      # initial abstraction [mm]\n","    valid = P_mm > I_a\n","    Q = np.where(valid, (P_mm - I_a)**2 / (P_mm + 0.8*S), 0.0)\n","    return np.maximum(Q, 0.0)\n","\n","def runoff_coeff(P_mm, CN):\n","    \"\"\"Runoff coefficient C = Q/P.\"\"\"\n","    Q = scscn_runoff(P_mm, CN)\n","    return np.where(P_mm > 0, Q / P_mm, 0.0)\n","\n","# Per-basin: compute CN_mean, S_mean, Q for each return period, runoff volume\n","RUNOFF_ROWS = []\n","\n","for _, row in gdf_sub.iterrows():\n","    bid  = row[\"basin_id\"]\n","    geom = [row.geometry.__geo_interface__]\n","    A_km2 = df_areal.loc[bid, \"Area_km2\"]\n","    A_m2  = A_km2 * 1e6\n","\n","    # Clip CN to basin\n","    with rasterio.open(RASTERS[\"CN\"]) as src:\n","        try:\n","            arr_m, _ = rio_mask(src, geom, crop=True, nodata=np.nan)\n","            cn_clip  = arr_m[0].astype(np.float32)\n","            cn_clip[cn_clip == -9999.0] = np.nan\n","        except Exception:\n","            cn_clip = CN_ARR.copy()\n","\n","    CN_mean = float(np.nanmean(cn_clip))\n","    CN_std  = float(np.nanstd(cn_clip))\n","    S_mean  = 25400.0 / CN_mean - 254.0     # [mm]\n","    Ia_mean = 0.2 * S_mean                  # initial abstraction [mm]\n","\n","    r_row = {\"basin_id\": bid, \"CN_mean\": round(CN_mean, 2),\n","             \"CN_std\": round(CN_std, 2), \"S_mm\": round(S_mean, 2),\n","             \"Ia_mm\": round(Ia_mean, 2), \"Area_km2\": round(A_km2, 3)}\n","\n","    for T in RETURN_PERIODS:\n","        P = RAINFALL_RT[T]\n","        Q = float(scscn_runoff(P, CN_mean))\n","        C = float(runoff_coeff(P, CN_mean))\n","        Vol_Mm3 = Q * 1e-3 * A_m2 / 1e6   # Million cubic metres\n","        r_row[f\"P_{T}yr_mm\"]    = P\n","        r_row[f\"Q_{T}yr_mm\"]    = round(Q, 2)\n","        r_row[f\"C_{T}yr\"]       = round(C, 3)\n","        r_row[f\"Vol_{T}yr_Mm3\"] = round(Vol_Mm3, 4)\n","\n","    RUNOFF_ROWS.append(r_row)\n","    print(f\"  {bid}: CN={CN_mean:.1f} | S={S_mean:.1f} mm | \"\n","          f\"Q(25yr)={r_row['Q_25yr_mm']:.1f} mm | \"\n","          f\"Vol(25yr)={r_row['Vol_25yr_Mm3']:.4f} MmÂ³\")\n","\n","df_runoff = pd.DataFrame(RUNOFF_ROWS).set_index(\"basin_id\")\n","df_runoff.to_csv(os.path.join(HYD_DIR, \"runoff_scscn.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  D. TIME OF CONCENTRATION â€” KIRPICH, SCS LAG, OVERLAND FLOW\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[14-D] Time of Concentration (Tc) calculations...\")\n","\n","def tc_kirpich(L_m, H_m):\n","    \"\"\"\n","    Kirpich (1940): Tc = 0.0195 Ã— L^0.77 Ã— S^-0.385\n","    L = channel length (m), H = head difference (m)\n","    S = H/L (dimensionless slope)\n","    Returns Tc in minutes.\n","    \"\"\"\n","    S = H_m / L_m if L_m > 0 else 0.001\n","    S = max(S, 0.0001)\n","    Tc = 0.0195 * (L_m ** 0.77) * (S ** -0.385)\n","    return Tc  # minutes\n","\n","def tc_scs_lag(L_m, CN, S_avg_pct):\n","    \"\"\"\n","    SCS Lag method: tL = (L^0.8 Ã— (S+1)^0.7) / (1900 Ã— Y^0.5)\n","    L = hydraulic length (feet), S = (1000/CN)-10, Y = average watershed slope (%)\n","    Returns lag time tL in hours; Tc = tL / 0.6\n","    \"\"\"\n","    L_ft = L_m * 3.28084\n","    S_val = 1000.0 / CN - 10.0\n","    Y = max(S_avg_pct, 0.1)\n","    tL = (L_ft**0.8 * (S_val + 1)**0.7) / (1900.0 * Y**0.5)  # hours\n","    Tc = tL / 0.6\n","    return Tc * 60  # minutes\n","\n","def tc_overland(L_m, n_mann, slope_frac, P_mm):\n","    \"\"\"\n","    NRCS Overland Flow Tc (sheet flow):\n","    Tt = 0.007 Ã— (nÃ—L)^0.8 / (PÂ²^0.5 Ã— S^0.4)\n","    n = Manning roughness, P2 = 2-year 24-hr rainfall (mmâ†’in)\n","    Returns Tt in hours; usually only for first 100m of flow.\n","    \"\"\"\n","    P2_in = P_mm * 0.0394\n","    L_use = min(L_m, 100.0)   # max 100m for sheet flow\n","    S     = max(slope_frac, 0.001)\n","    Tt    = 0.007 * ((n_mann * L_use)**0.8) / ((P2_in**0.5) * (S**0.4))\n","    return Tt * 60  # minutes\n","\n","TC_ROWS = []\n","\n","for _, row in gdf_sub.iterrows():\n","    bid    = row[\"basin_id\"]\n","    A_km2  = df_areal.loc[bid, \"Area_km2\"]\n","    Lb_km  = df_areal.loc[bid, \"Basin_Length_km\"]\n","    L_m    = Lb_km * 1000.0\n","    H_m    = df_relief.loc[bid, \"Basin_Relief_H_m\"] if bid in df_relief.index else 100.0\n","    slope_deg = df_relief.loc[bid, \"Slope_Mean_deg\"] if bid in df_relief.index else 5.0\n","    slope_pct = np.tan(np.radians(slope_deg)) * 100.0\n","    slope_frac = slope_pct / 100.0\n","    CN_mean   = df_runoff.loc[bid, \"CN_mean\"]\n","    P2_mm     = RAINFALL_RT[2]   # 2-yr 24-hr rainfall\n","\n","    Tc_k   = tc_kirpich(L_m, H_m)\n","    Tc_scs = tc_scs_lag(L_m, CN_mean, slope_pct)\n","    Tc_ov  = tc_overland(min(L_m, 100), 0.15, slope_frac, P2_mm)\n","    Tc_avg = np.mean([Tc_k, Tc_scs])   # practical average\n","\n","    # Rational method peak discharge: Qp = C Ã— i Ã— A / 360\n","    # i = rainfall intensity at Tc [mm/hr] using Tc in minutes\n","    # Using Dickens formula common for India: i = a / (Tc + b)\n","    # Or convert P24hr to intensity using Chen (1983) or Indian standard IDF\n","    # Indian IMD empirical: i_Tc = P24hr Ã— (24/Tc_hr)^(2/3) / 24  [mm/hr]\n","    Q_PEAK = {}\n","    C_rational = {}\n","    for T in RETURN_PERIODS:\n","        P24 = RAINFALL_RT[T]\n","        Tc_hr = Tc_avg / 60.0\n","        i_Tc  = (P24 / 24.0) * (24.0 / Tc_hr) ** (2.0/3.0)  # mm/hr\n","        # C (runoff coeff from SCS Q/P for this storm)\n","        C_val = float(runoff_coeff(P24, CN_mean))\n","        # Qp [mÂ³/s] = C Ã— i [mm/hr] Ã— A [kmÂ²] / 3.6\n","        Qp = C_val * i_Tc * A_km2 / 3.6\n","        Q_PEAK[T] = round(Qp, 3)\n","        C_rational[T] = round(C_val, 3)\n","\n","    r_tc = {\n","        \"basin_id\"     : bid,\n","        \"L_km\"         : round(Lb_km, 3),\n","        \"H_m\"          : round(H_m, 1),\n","        \"Slope_pct\"    : round(slope_pct, 2),\n","        \"Tc_Kirpich_min\": round(Tc_k, 1),\n","        \"Tc_SCS_min\"   : round(Tc_scs, 1),\n","        \"Tc_Avg_min\"   : round(Tc_avg, 1),\n","        \"Tc_hr\"        : round(Tc_avg / 60.0, 3),\n","    }\n","    for T in RETURN_PERIODS:\n","        r_tc[f\"Qp_{T}yr_m3s\"]  = Q_PEAK[T]\n","        r_tc[f\"C_{T}yr\"]       = C_rational[T]\n","\n","    TC_ROWS.append(r_tc)\n","    print(f\"  {bid}: Tc_Kirpich={Tc_k:.1f} min | Tc_SCS={Tc_scs:.1f} min | \"\n","          f\"Qp(25yr)={Q_PEAK[25]:.2f} mÂ³/s\")\n","\n","df_tc = pd.DataFrame(TC_ROWS).set_index(\"basin_id\")\n","df_tc.to_csv(os.path.join(HYD_DIR, \"time_of_concentration_peak_discharge.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  E. RUNOFF MAPS & PLOTLY CHARTS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[14-E] Generating runoff maps...\")\n","\n","# CN map\n","fig, ax, utm_ext = base_axes(\"Curve Number (CN) Map â€” SCS-CN, AMC-II\\n\"\n","                              \"(Slope-based proxy, Deccan Trap basalt)\")\n","im = ax.imshow(CN_ARR, extent=raster_extent(), origin=\"upper\",\n","               cmap=\"RdYlGn_r\", alpha=0.80, zorder=1, vmin=68, vmax=88)\n","overlay_boundaries(ax)\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"3%\", pad=0.07)\n","cb  = plt.colorbar(im, cax=cax)\n","cb.set_label(\"Curve Number (CN)\", fontsize=10)\n","# Annotate each basin with CN mean\n","for _, r in gdf_sub.iterrows():\n","    bid = r[\"basin_id\"]\n","    cx, cy = r.geometry.centroid.x, r.geometry.centroid.y\n","    cn_val = df_runoff.loc[bid, \"CN_mean\"] if bid in df_runoff.index else np.nan\n","    ax.text(cx, cy, f\"{bid}\\nCN={cn_val:.1f}\", ha=\"center\", va=\"center\",\n","            fontsize=8, fontweight=\"bold\",\n","            path_effects=[pe.withStroke(linewidth=2, foreground=\"white\")])\n","finalize_and_save(fig, ax, utm_ext, \"14a_CN_map.png\")\n","\n","# Runoff volume map for 25-yr event\n","fig, ax, utm_ext = base_axes(\"Direct Runoff Volume Map â€” 25-year Return Period Event\\n\"\n","                              \"(SCS-CN method, per subbasin)\")\n","gdf_rv = gdf_sub.merge(\n","    df_runoff[[\"Q_25yr_mm\", \"Vol_25yr_Mm3\", \"CN_mean\"]].reset_index(),\n","    on=\"basin_id\", how=\"left\"\n",")\n","gdf_rv.plot(column=\"Vol_25yr_Mm3\", ax=ax, cmap=\"Blues\", legend=True, alpha=0.80,\n","            zorder=2, edgecolor=\"black\", linewidth=1.2,\n","            legend_kwds={\"label\": \"Runoff Volume (MmÂ³)\", \"shrink\": 0.75})\n","for _, r in gdf_rv.iterrows():\n","    cx, cy = r.geometry.centroid.x, r.geometry.centroid.y\n","    ax.text(cx, cy,\n","            f\"{r['basin_id']}\\nQ={r['Q_25yr_mm']:.0f} mm\\n{r['Vol_25yr_Mm3']:.3f} MmÂ³\",\n","            ha=\"center\", va=\"center\", fontsize=7.5, fontweight=\"bold\",\n","            path_effects=[pe.withStroke(linewidth=2, foreground=\"white\")])\n","gdf_streams.plot(ax=ax, color=\"royalblue\", linewidth=0.7, alpha=0.5, zorder=5)\n","finalize_and_save(fig, ax, utm_ext, \"14b_runoff_volume_25yr.png\")\n","\n","# Plotly: multi-return-period peak discharge comparison\n","fig = make_subplots(rows=1, cols=2,\n","                    subplot_titles=[\"Peak Discharge by Return Period (mÂ³/s)\",\n","                                    \"Runoff Depth by Return Period (mm)\"])\n","colors_rt = px.colors.qualitative.Set1\n","for i, bid in enumerate(df_tc.index):\n","    qp_vals = [df_tc.loc[bid, f\"Qp_{T}yr_m3s\"] for T in RETURN_PERIODS]\n","    q_vals  = [df_runoff.loc[bid, f\"Q_{T}yr_mm\"] for T in RETURN_PERIODS]\n","    fig.add_trace(go.Scatter(\n","        x=RETURN_PERIODS, y=qp_vals, mode=\"lines+markers\",\n","        name=bid, line=dict(color=colors_rt[i % 9], width=2),\n","        marker=dict(size=8), legendgroup=bid,\n","        hovertemplate=f\"{bid}<br>T=%{{x}} yr<br>Qp=%{{y:.2f}} mÂ³/s\",\n","    ), row=1, col=1)\n","    fig.add_trace(go.Scatter(\n","        x=RETURN_PERIODS, y=q_vals, mode=\"lines+markers\",\n","        name=bid, line=dict(color=colors_rt[i % 9], dash=\"dot\", width=2),\n","        marker=dict(size=8), legendgroup=bid, showlegend=False,\n","        hovertemplate=f\"{bid}<br>T=%{{x}} yr<br>Q=%{{y:.2f}} mm\",\n","    ), row=1, col=2)\n","\n","fig.update_xaxes(type=\"log\", title_text=\"Return Period (yr)\", row=1, col=1)\n","fig.update_xaxes(type=\"log\", title_text=\"Return Period (yr)\", row=1, col=2)\n","fig.update_yaxes(title_text=\"Peak Discharge (mÂ³/s)\", row=1, col=1)\n","fig.update_yaxes(title_text=\"Runoff Depth Q (mm)\", row=1, col=2)\n","fig.update_layout(title=\"Flood Frequency Curves â€” Pravara Subbasins\",\n","                  template=\"plotly_white\", height=500)\n","save_fig(fig, \"14c_flood_frequency_curves\")\n","print(\"\\nâœ… SECTION 14 complete.\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# SECTION 15 â€” RUSLE SOIL EROSION MODEL\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"SECTION 15 â€” RUSLE SOIL EROSION ESTIMATION\")\n","print(\"=\" * 70)\n","\n","# RUSLE:  A = R Ã— K Ã— LS Ã— C Ã— P\n","# A  = Annual average soil loss (t/ha/yr)\n","# R  = Rainfall-runoff erosivity factor (MJÂ·mm/haÂ·hrÂ·yr)\n","# K  = Soil erodibility factor (tÂ·haÂ·hr/haÂ·MJÂ·mm)\n","# LS = Slope length-gradient factor (dimensionless)\n","# C  = Cover-management factor (dimensionless, 0â€“1)\n","# P  = Support practice factor (dimensionless, 0â€“1)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. R-FACTOR â€” Erosivity\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[15-A] R-Factor (Rainfall Erosivity)...\")\n","# Maharashtra Deccan Trap region: R â‰ˆ 550â€“800 MJÂ·mm/(haÂ·hrÂ·yr)\n","# Pravara catchment (Ahmednagar): R â‰ˆ 650 MJÂ·mm/(haÂ·hrÂ·yr)\n","# Spatial variation modelled as: R = R0 Ã— (1 + 0.05 Ã— (elev - elev_mean)/elev_std)\n","# (higher elevations get slightly higher R due to orographic rainfall)\n","\n","R0       = 650.0\n","elev_mean = np.nanmean(DEM_ARR)\n","elev_std  = np.nanstd(DEM_ARR)\n","\n","R_ARR = R0 * (1.0 + 0.05 * (DEM_ARR - elev_mean) / (elev_std + 1e-6))\n","R_ARR = np.clip(R_ARR, 400.0, 1000.0)\n","R_ARR[np.isnan(DEM_ARR)] = np.nan\n","\n","save_raster(R_ARR.astype(np.float32), os.path.join(OUT_DIR, \"RUSLE_R.tif\"), RASTERS[\"dem\"])\n","RASTERS[\"RUSLE_R\"] = os.path.join(OUT_DIR, \"RUSLE_R.tif\")\n","print(f\"  R-factor range: {np.nanmin(R_ARR):.0f}â€“{np.nanmax(R_ARR):.0f} \"\n","      f\"MJÂ·mm/(haÂ·hrÂ·yr) | Mean: {np.nanmean(R_ARR):.0f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. K-FACTOR â€” Soil Erodibility\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[15-B] K-Factor (Soil Erodibility)...\")\n","# Deccan Trap basalt â†’ Vertisols + Inceptisols\n","# K ranges: Vertisol (clay-rich) 0.10â€“0.20; Shallow rocky 0.05â€“0.10\n","# Proxy using slope: steeper slopes â†’ shallower soil â†’ lower K (rocky)\n","# Flat/gentle â†’ deep Vertisol â†’ higher K\n","\n","K_ARR = np.where(slope_safe <  3,  0.25,   # Deep Vertisol (fine clay, flat)\n","         np.where(slope_safe <  8,  0.20,   # Vertic Inceptisol\n","         np.where(slope_safe < 15,  0.15,   # Shallow Alfisol\n","         np.where(slope_safe < 25,  0.10,   # Lithic Inceptisol (stony)\n","                                   0.05)))).astype(np.float32)  # Rock/talus\n","K_ARR[np.isnan(DEM_ARR)] = np.nan\n","\n","save_raster(K_ARR, os.path.join(OUT_DIR, \"RUSLE_K.tif\"), RASTERS[\"dem\"])\n","RASTERS[\"RUSLE_K\"] = os.path.join(OUT_DIR, \"RUSLE_K.tif\")\n","print(f\"  K-factor range: {np.nanmin(K_ARR):.2f}â€“{np.nanmax(K_ARR):.2f} \"\n","      f\"tÂ·haÂ·hr/(haÂ·MJÂ·mm) | Mean: {np.nanmean(K_ARR):.3f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. LS-FACTOR â€” Slope Length-Gradient\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[15-C] LS-Factor (Slope-Length Gradient, Moore et al. 1991)...\")\n","# Moore et al. (1991) LS from flow accumulation (As) and slope:\n","#   LS = (As/22.13)^m Ã— (sin(Î²)/0.0896)^n\n","# where As = specific catchment area (mÂ²/m) = flow_acc Ã— cell_size\n","# m = 0.6 (rill erosion, semi-arid), n = 1.3\n","# This formulation handles divergent/convergent flow better than Wischmeier's L.\n","\n","cell_area_m2 = DEM_RES * DEM_RES\n","fa_safe  = np.where(np.isnan(FACC_ARR), 0, np.maximum(FACC_ARR, 1))\n","As_arr   = fa_safe * DEM_RES                # specific catchment area mÂ²/m\n","slope_rad = np.radians(np.where(np.isnan(SLOPE_ARR), 0.01, SLOPE_ARR))\n","slope_rad = np.maximum(slope_rad, np.radians(0.01))  # min 0.01Â° to avoid log issues\n","\n","m_exp = 0.6\n","n_exp = 1.3\n","LS_ARR = ((As_arr / 22.13) ** m_exp) * ((np.sin(slope_rad) / 0.0896) ** n_exp)\n","LS_ARR = np.clip(LS_ARR, 0.0, 50.0)       # cap to avoid extreme values on cliffs\n","LS_ARR[np.isnan(DEM_ARR)] = np.nan\n","\n","save_raster(LS_ARR.astype(np.float32), os.path.join(OUT_DIR, \"RUSLE_LS.tif\"), RASTERS[\"dem\"])\n","RASTERS[\"RUSLE_LS\"] = os.path.join(OUT_DIR, \"RUSLE_LS.tif\")\n","print(f\"  LS-factor range: {np.nanmin(LS_ARR):.2f}â€“{np.nanmax(LS_ARR):.2f} | \"\n","      f\"Mean: {np.nanmean(LS_ARR):.2f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  D. C-FACTOR â€” Cover-Management\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[15-D] C-Factor (Cover-Management)...\")\n","# No land-use raster: use slope + elevation proxy for cover quality\n","# Flat lowlands (cultivated, Rabi/Kharif crops): C = 0.15â€“0.25\n","# Moderate slopes (degraded dryland agriculture): C = 0.25â€“0.40\n","# Steep slopes (sparse scrub/bare basalt): C = 0.40â€“0.60\n","# Very steep / ridges (bare rock): C = 0.10â€“0.20 (less soil to erode)\n","\n","C_ARR = np.where(slope_safe <  3,  0.20,   # Irrigated/Rabi crops in flat areas\n","         np.where(slope_safe <  8,  0.30,   # Rainfed Kharif crops\n","         np.where(slope_safe < 15,  0.45,   # Degraded rangeland/scrub\n","         np.where(slope_safe < 25,  0.55,   # Sparse vegetation / bare patches\n","                                   0.15)))).astype(np.float32)  # Rocky ridge (low erosion)\n","C_ARR[np.isnan(DEM_ARR)] = np.nan\n","\n","save_raster(C_ARR, os.path.join(OUT_DIR, \"RUSLE_C.tif\"), RASTERS[\"dem\"])\n","RASTERS[\"RUSLE_C\"] = os.path.join(OUT_DIR, \"RUSLE_C.tif\")\n","print(f\"  C-factor range: {np.nanmin(C_ARR):.2f}â€“{np.nanmax(C_ARR):.2f} | \"\n","      f\"Mean: {np.nanmean(C_ARR):.3f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  E. P-FACTOR â€” Support Practice\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[15-E] P-Factor (Support Practice)...\")\n","# Maharashtra farmers on steep slopes use traditional bunding (terracing)\n","# Flat (<3Â°) : cultivated flat fields, no terracing needed â†’ P = 1.0\n","# Gentleâ€“Moderate (3â€“20Â°): traditional tied ridges / broad-based bunds â†’ P = 0.6\n","# Steep (>20Â°): bench terracing or no practice â†’ P = 0.8\n","# Very steep (>30Â°): grassland / no effective practice â†’ P = 1.0\n","\n","P_ARR = np.where(slope_safe <  3,  1.00,\n","         np.where(slope_safe <  8,  0.55,   # Contour cultivation + bunding\n","         np.where(slope_safe < 15,  0.65,   # Graded bunding\n","         np.where(slope_safe < 25,  0.80,   # Bench terrace\n","                                   1.00)))).astype(np.float32)\n","P_ARR[np.isnan(DEM_ARR)] = np.nan\n","\n","save_raster(P_ARR, os.path.join(OUT_DIR, \"RUSLE_P.tif\"), RASTERS[\"dem\"])\n","RASTERS[\"RUSLE_P\"] = os.path.join(OUT_DIR, \"RUSLE_P.tif\")\n","print(f\"  P-factor range: {np.nanmin(P_ARR):.2f}â€“{np.nanmax(P_ARR):.2f} | \"\n","      f\"Mean: {np.nanmean(P_ARR):.3f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  F. ANNUAL SOIL LOSS (A) â€” RUSLE\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[15-F] Computing Annual Soil Loss raster A = RÂ·KÂ·LSÂ·CÂ·P ...\")\n","\n","A_ARR = R_ARR * K_ARR * LS_ARR * C_ARR * P_ARR     # t/ha/yr\n","A_ARR = np.clip(A_ARR, 0.0, 500.0)                 # cap extreme values\n","A_ARR[np.isnan(DEM_ARR)] = np.nan\n","\n","save_raster(A_ARR.astype(np.float32), os.path.join(OUT_DIR, \"RUSLE_A.tif\"), RASTERS[\"dem\"])\n","RASTERS[\"RUSLE_A\"] = os.path.join(OUT_DIR, \"RUSLE_A.tif\")\n","print(f\"  Annual soil loss range: {np.nanmin(A_ARR):.1f}â€“{np.nanmax(A_ARR):.0f} t/ha/yr\")\n","print(f\"  Basin-wide mean: {np.nanmean(A_ARR):.1f} t/ha/yr\")\n","\n","# â”€â”€ USDA soil loss class thresholds (t/ha/yr) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# Slight <5 | Moderate 5-15 | High 15-30 | Very High 30-60 | Severe >60\n","SOIL_LOSS_CLASSES = [\n","    (0,   5,  \"Slight (<5)\",        \"#1a9641\"),\n","    (5,  15,  \"Moderate (5-15)\",    \"#a6d96a\"),\n","    (15, 30,  \"High (15-30)\",       \"#fdae61\"),\n","    (30, 60,  \"Very High (30-60)\",  \"#d7191c\"),\n","    (60, 999, \"Severe (>60)\",       \"#7f0000\"),\n","]\n","\n","def classify_soil_loss(val):\n","    for lo, hi, name, _ in SOIL_LOSS_CLASSES:\n","        if lo <= val < hi:\n","            return name\n","    return \"Severe (>60)\"\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  G. SEDIMENT DELIVERY RATIO (SDR) & ANNUAL SEDIMENT YIELD\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[15-G] Sediment Delivery Ratio & Annual Sediment Yield...\")\n","\n","# SDR = 0.417 Ã— A^(-0.3) (Vanoni, 1975 â€” area in kmÂ²)\n","# Also: SDR = exp(-1.58 + 0.46 Ã— ln(slope%) - 0.19 Ã— ln(A_kmÂ²))\n","# We use Renfro (1975) formula: SDR = 0.42 Ã— A_km2^(-0.125)\n","\n","RUSLE_ROWS = []\n","\n","for _, row in gdf_sub.iterrows():\n","    bid  = row[\"basin_id\"]\n","    geom = [row.geometry.__geo_interface__]\n","    A_km2 = df_areal.loc[bid, \"Area_km2\"]\n","\n","    # Clip A raster\n","    with rasterio.open(RASTERS[\"RUSLE_A\"]) as src:\n","        try:\n","            arr_m, _ = rio_mask(src, geom, crop=True, nodata=np.nan)\n","            a_clip   = arr_m[0].astype(np.float32)\n","            a_clip[a_clip == -9999.0] = np.nan\n","        except Exception:\n","            a_clip   = A_ARR.copy()\n","\n","    valid_a = a_clip[~np.isnan(a_clip)]\n","    if len(valid_a) == 0:\n","        continue\n","\n","    A_mean = float(np.nanmean(valid_a))    # t/ha/yr\n","    A_max  = float(np.nanpercentile(valid_a, 95))\n","\n","    # Total gross erosion (t/yr): A_mean [t/ha/yr] Ã— Area [ha]\n","    A_ha   = A_km2 * 100.0\n","    Gross_erosion_t_yr = A_mean * A_ha\n","\n","    # SDR\n","    SDR = 0.42 * (A_km2 ** -0.125)\n","    SDR = min(SDR, 0.80)\n","\n","    # Annual sediment yield\n","    Sed_yield_t_yr   = Gross_erosion_t_yr * SDR\n","    Sed_yield_Mm3_yr = Sed_yield_t_yr / (1300 * 1000)  # assuming bulk density 1.3 t/mÂ³\n","\n","    # Area fraction per soil loss class\n","    class_fracs = {}\n","    for lo, hi, name, _ in SOIL_LOSS_CLASSES:\n","        frac = float(np.sum((valid_a >= lo) & (valid_a < hi))) / len(valid_a)\n","        class_fracs[name] = round(frac * 100, 1)\n","\n","    RUSLE_ROWS.append({\n","        \"basin_id\"              : bid,\n","        \"A_mean_t_ha_yr\"        : round(A_mean, 2),\n","        \"A_p95_t_ha_yr\"         : round(A_max, 2),\n","        \"Area_ha\"               : round(A_ha, 1),\n","        \"Gross_Erosion_t_yr\"    : round(Gross_erosion_t_yr, 0),\n","        \"SDR\"                   : round(SDR, 3),\n","        \"Sed_Yield_t_yr\"        : round(Sed_yield_t_yr, 0),\n","        \"Sed_Yield_Mm3_yr\"      : round(Sed_yield_Mm3_yr, 6),\n","        \"Loss_Class_Mode\"       : classify_soil_loss(A_mean),\n","        **{f\"Pct_{k}\": v for k, v in class_fracs.items()},\n","    })\n","    print(f\"  {bid}: A_mean={A_mean:.1f} t/ha/yr | SDR={SDR:.3f} | \"\n","          f\"Sed.Yield={Sed_yield_t_yr:.0f} t/yr | Class: {classify_soil_loss(A_mean)}\")\n","\n","df_rusle = pd.DataFrame(RUSLE_ROWS).set_index(\"basin_id\")\n","df_rusle.to_csv(os.path.join(HYD_DIR, \"RUSLE_soil_erosion.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  H. RUSLE MAPS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[15-H] Generating RUSLE maps...\")\n","\n","# LS-factor map\n","fig, ax, utm_ext = base_axes(\"RUSLE LS-Factor Map\\n(Moore et al. 1991: \"\n","                              \"Slope-Length Ã— Gradient combined)\")\n","im = ax.imshow(LS_ARR, extent=raster_extent(), origin=\"upper\",\n","               cmap=\"YlOrRd\", alpha=0.80, zorder=1,\n","               vmin=0, vmax=np.nanpercentile(LS_ARR, 97))\n","gdf_sub.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, zorder=10)\n","gdf_streams.plot(ax=ax, color=\"royalblue\", linewidth=0.6, alpha=0.5, zorder=8)\n","divider = make_axes_locatable(ax)\n","cax = divider.append_axes(\"right\", size=\"3%\", pad=0.07)\n","cb  = plt.colorbar(im, cax=cax)\n","cb.set_label(\"LS Factor (dimensionless)\", fontsize=10)\n","finalize_and_save(fig, ax, utm_ext, \"15a_LS_factor.png\")\n","\n","# Annual soil loss map\n","fig, ax, utm_ext = base_axes(\"Annual Soil Loss Map (RUSLE: A = RÂ·KÂ·LSÂ·CÂ·P)\\n\"\n","                              \"(tonnes/ha/year)\")\n","# Custom classified colormap\n","boundaries_sl = [0, 5, 15, 30, 60, 500]\n","colors_sl     = [\"#1a9641\", \"#a6d96a\", \"#fdae61\", \"#d7191c\", \"#7f0000\"]\n","cmap_sl       = mcolors.BoundaryNorm(boundaries_sl, len(colors_sl))\n","cmap_sl_obj   = LinearSegmentedColormap.from_list(\"sl\", colors_sl, N=len(colors_sl))\n","norm_sl       = mcolors.BoundaryNorm(boundaries_sl, cmap_sl_obj.N)\n","\n","im = ax.imshow(A_ARR, extent=raster_extent(), origin=\"upper\",\n","               cmap=cmap_sl_obj, norm=norm_sl, alpha=0.80, zorder=1)\n","gdf_sub.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, zorder=10)\n","gdf_streams.plot(ax=ax, color=\"royalblue\", linewidth=0.6, alpha=0.5, zorder=8)\n","patches_sl = [mpatches.Patch(color=c, label=n)\n","              for _, _, n, c in SOIL_LOSS_CLASSES]\n","ax.legend(handles=patches_sl, loc=\"lower left\", fontsize=8,\n","          title=\"Soil Loss Class (t/ha/yr)\", title_fontsize=9, framealpha=0.9)\n","# Annotate basins\n","for _, r in gdf_sub.iterrows():\n","    bid = r[\"basin_id\"]\n","    if bid in df_rusle.index:\n","        cx, cy = r.geometry.centroid.x, r.geometry.centroid.y\n","        ax.text(cx, cy,\n","                f\"{bid}\\n{df_rusle.loc[bid,'A_mean_t_ha_yr']:.1f} t/ha/yr\\n\"\n","                f\"{df_rusle.loc[bid,'Loss_Class_Mode']}\",\n","                ha=\"center\", va=\"center\", fontsize=7, fontweight=\"bold\",\n","                path_effects=[pe.withStroke(linewidth=2, foreground=\"white\")])\n","finalize_and_save(fig, ax, utm_ext, \"15b_RUSLE_soil_loss.png\")\n","\n","# Sediment yield bar chart (Plotly)\n","df_rusle_reset = df_rusle.reset_index()\n","fig = make_subplots(rows=1, cols=2,\n","                    subplot_titles=[\"Annual Soil Loss (t/ha/yr) per Basin\",\n","                                    \"Sediment Yield (t/yr) per Basin\"])\n","colors_b = [\"#d73027\", \"#fdae61\", \"#1a9641\", \"#4575b4\", \"#762a83\"]\n","for i, row_ in df_rusle_reset.iterrows():\n","    fig.add_trace(go.Bar(\n","        x=[row_[\"basin_id\"]], y=[row_[\"A_mean_t_ha_yr\"]],\n","        marker_color=colors_b[i % 5],\n","        text=f\"{row_['A_mean_t_ha_yr']:.1f}\", textposition=\"outside\",\n","        name=row_[\"basin_id\"],\n","        hovertemplate=(f\"{row_['basin_id']}<br>\"\n","                       f\"Mean Loss: {row_['A_mean_t_ha_yr']:.1f} t/ha/yr<br>\"\n","                       f\"Class: {row_['Loss_Class_Mode']}\"),\n","    ), row=1, col=1)\n","    fig.add_trace(go.Bar(\n","        x=[row_[\"basin_id\"]], y=[row_[\"Sed_Yield_t_yr\"]],\n","        marker_color=colors_b[i % 5],\n","        text=f\"{row_['Sed_Yield_t_yr']:.0f}\", textposition=\"outside\",\n","        name=row_[\"basin_id\"], showlegend=False,\n","        hovertemplate=(f\"{row_['basin_id']}<br>\"\n","                       f\"Sediment Yield: {row_['Sed_Yield_t_yr']:.0f} t/yr<br>\"\n","                       f\"SDR: {row_['SDR']:.3f}\"),\n","    ), row=1, col=2)\n","\n","# USDA threshold lines\n","for T_val, label in [(5, \"Slight/Moderate\"), (15, \"Moderate/High\"),\n","                      (30, \"High/Very High\"), (60, \"Very High/Severe\")]:\n","    fig.add_hline(y=T_val, line_dash=\"dash\", line_color=\"grey\",\n","                  annotation_text=label, annotation_position=\"right\",\n","                  annotation_font_size=9, row=1, col=1)\n","\n","fig.update_yaxes(title_text=\"Mean Annual Soil Loss (t/ha/yr)\", row=1, col=1)\n","fig.update_yaxes(title_text=\"Annual Sediment Yield (t/yr)\", row=1, col=2)\n","fig.update_layout(title=\"RUSLE Erosion Results â€” Pravara Subbasins\",\n","                  template=\"plotly_white\", height=500, showlegend=False)\n","save_fig(fig, \"15c_RUSLE_erosion_bars\")\n","\n","# RUSLE factor comparison radar (Plotly)\n","factor_cols_r = [\"A_mean_t_ha_yr\", \"SDR\", \"Gross_Erosion_t_yr\"]\n","fig_r = go.Figure()\n","for i, (bid, row_) in enumerate(df_rusle.iterrows()):\n","    val_r = [df_rusle.loc[bid, c] for c in factor_cols_r]\n","    val_r_n = [(v - df_rusle[c].min()) / (df_rusle[c].max() - df_rusle[c].min() + 1e-9)\n","               for v, c in zip(val_r, factor_cols_r)]\n","    val_r_n += [val_r_n[0]]\n","    cats = [\"Soil Loss\", \"SDR\", \"Gross Erosion\", \"Soil Loss\"]\n","    fig_r.add_trace(go.Scatterpolar(\n","        r=val_r_n, theta=cats, fill=\"toself\", name=bid, opacity=0.7,\n","        line_color=px.colors.qualitative.Set1[i % 9]))\n","\n","fig_r.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 1])),\n","                    title=\"RUSLE Erosion Signature â€” Normalised per Subbasin\",\n","                    template=\"plotly_white\", height=500)\n","save_fig(fig_r, \"15d_RUSLE_radar\")\n","print(\"\\nâœ… SECTION 15 complete.\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# SECTION 16 â€” WATERSHED TREATMENT PLANNING (SOIL & WATER CONSERVATION)\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"SECTION 16 â€” WATERSHED TREATMENT PLANNING\")\n","print(\"(Check Dams, Percolation Tanks, Contour Trenches, Priority Zones)\")\n","print(\"=\" * 70)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. CHECK DAM SUITABILITY INDEX (CDSI)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# Check dam (naala bund / gully plug) suitability criteria:\n","#  1. Stream order: 1stâ€“2nd order preferred (scores: ord1=10, ord2=8, ord3=5, ord4+=2)\n","#  2. Upstream catchment area: 0.5â€“10 kmÂ² optimal (score 10), beyond that less suitable\n","#  3. Valley cross-section (Vf): 0.3â€“1.5 ideal (narrow V-shape; score inversely with Vf)\n","#  4. Channel slope: 1â€“5% optimal for sediment trapping (too flat = silts up; too steep = washout)\n","#  5. RUSLE A-index: High erosion upstream = high benefit (score ~A/Amax)\n","\n","print(\"\\n[16-A] Computing Check Dam Suitability Index...\")\n","\n","def score_stream_order(order):\n","    \"\"\"Score stream order 1â€“6 for check dam suitability (1st order = best).\"\"\"\n","    return max(0, 10 - (order - 1) * 2.5)   # 10, 7.5, 5.0, 2.5, 0...\n","\n","def score_catchment_area(A_km2):\n","    \"\"\"0.5â€“10 kmÂ² is optimal for check dams.\"\"\"\n","    if   0.1 <= A_km2 <= 0.5:  return 6\n","    elif 0.5 <  A_km2 <= 5.0:  return 10\n","    elif 5.0 <  A_km2 <= 15.0: return 7\n","    elif A_km2 > 15.0:          return 3\n","    return 4\n","\n","def score_channel_slope(slope_pct):\n","    \"\"\"1â€“5% channel slope is optimal.\"\"\"\n","    if   slope_pct < 0.5:  return 3   # Too flat â†’ rapid silting\n","    elif slope_pct < 1.0:  return 6\n","    elif slope_pct < 5.0:  return 10  # Optimal\n","    elif slope_pct < 10.0: return 7\n","    elif slope_pct < 20.0: return 4\n","    return 2                           # Too steep â†’ unstable\n","\n","def score_valley_vf(Vf):\n","    \"\"\"Vf 0.3â€“1.5 ideal (narrow V = easy to block; very wide = costly).\"\"\"\n","    if np.isnan(Vf):        return 5\n","    if   Vf < 0.3:          return 6   # Very narrow â€” ok but hard to construct\n","    elif Vf < 1.5:          return 10  # Ideal\n","    elif Vf < 3.0:          return 7\n","    elif Vf < 6.0:          return 4\n","    return 2                            # Very wide valley â€” not suitable\n","\n","# For each stream segment, compute CDSI\n","gdf_cd = gdf_so.copy()\n","gdf_cd[\"stream_length_m\"] = gdf_cd.geometry.length\n","\n","# Upstream catchment area from flow accumulation at segment midpoint\n","def sample_facc_at_midpoint(geom, facc_arr, transform):\n","    \"\"\"Sample flow accumulation at segment midpoint.\"\"\"\n","    try:\n","        mid_pt = geom.interpolate(0.5, normalized=True)\n","        r_i, c_i = rowcol(transform, mid_pt.x, mid_pt.y)\n","        if 0 <= r_i < facc_arr.shape[0] and 0 <= c_i < facc_arr.shape[1]:\n","            return float(facc_arr[r_i, c_i])\n","    except Exception:\n","        pass\n","    return np.nan\n","\n","def sample_slope_at_segment(geom, slope_arr, transform):\n","    \"\"\"Mean slope along segment.\"\"\"\n","    try:\n","        pts = [geom.interpolate(f, normalized=True) for f in np.linspace(0.1, 0.9, 7)]\n","        slopes = []\n","        for pt in pts:\n","            r_i, c_i = rowcol(transform, pt.x, pt.y)\n","            if 0 <= r_i < slope_arr.shape[0] and 0 <= c_i < slope_arr.shape[1]:\n","                s = slope_arr[r_i, c_i]\n","                if not np.isnan(s):\n","                    slopes.append(s)\n","        return float(np.nanmean(slopes)) if slopes else np.nan\n","    except Exception:\n","        return np.nan\n","\n","# Sample FAcc and slope for each segment\n","print(\"  Sampling flow accumulation and slope at stream segments...\")\n","fa_vals    = []\n","slope_segs = []\n","for _, seg in gdf_cd.iterrows():\n","    geom = seg.geometry\n","    if geom.geom_type == \"MultiLineString\":\n","        geom = max(geom.geoms, key=lambda g: g.length)\n","    fa_vals.append(sample_facc_at_midpoint(geom, FACC_ARR, DEM_TRANSFORM))\n","    slope_segs.append(sample_slope_at_segment(geom, SLOPE_ARR, DEM_TRANSFORM))\n","\n","gdf_cd[\"FA_cells\"]    = fa_vals\n","gdf_cd[\"seg_slope_deg\"] = slope_segs\n","gdf_cd[\"A_upstream_km2\"] = (gdf_cd[\"FA_cells\"] * DEM_RES * DEM_RES / 1e6).clip(lower=0)\n","gdf_cd[\"seg_slope_pct\"]  = np.tan(np.radians(gdf_cd[\"seg_slope_deg\"].fillna(5))) * 100\n","\n","# RUSLE A-score: mean soil loss in 2km upstream buffer of segment\n","def sample_rusle_upstream(geom, a_arr, transform, buffer_m=1000):\n","    \"\"\"Mean RUSLE A in buffer around segment endpoints.\"\"\"\n","    try:\n","        start_pt = Point(geom.coords[0])\n","        buffered = start_pt.buffer(buffer_m)\n","        geom_list = [buffered.__geo_interface__]\n","        with rasterio.open(RASTERS[\"RUSLE_A\"]) as src:\n","            arr_m, _ = rio_mask(src, geom_list, crop=True, nodata=np.nan)\n","            vals = arr_m[0][arr_m[0] > 0]\n","            return float(np.nanmean(vals)) if len(vals) > 0 else np.nan\n","    except Exception:\n","        return np.nan\n","\n","# Compute RUSLE score per segment (sample a subset for speed)\n","A_max_basin = float(np.nanpercentile(A_ARR, 95))\n","gdf_cd[\"A_upstream_mean\"] = np.nan\n","for idx in gdf_cd.index:\n","    geom = gdf_cd.loc[idx, \"geometry\"]\n","    if geom.geom_type == \"MultiLineString\":\n","        geom = max(geom.geoms, key=lambda g: g.length)\n","    val = sample_rusle_upstream(geom, A_ARR, DEM_TRANSFORM, buffer_m=500)\n","    gdf_cd.at[idx, \"A_upstream_mean\"] = val\n","\n","# Score each component\n","gdf_cd[\"S_order\"]    = gdf_cd[ORDER_COL].apply(score_stream_order)\n","gdf_cd[\"S_area\"]     = gdf_cd[\"A_upstream_km2\"].apply(score_catchment_area)\n","gdf_cd[\"S_slope\"]    = gdf_cd[\"seg_slope_pct\"].apply(score_channel_slope)\n","gdf_cd[\"S_erosion\"]  = (gdf_cd[\"A_upstream_mean\"].fillna(A_max_basin/2) /\n","                         (A_max_basin + 1e-6) * 10).clip(0, 10)\n","\n","# Get Vf from df_Vf if available, else use default\n","try:\n","    gdf_cd_sub = gpd.sjoin(gdf_cd, gdf_sub[[\"basin_id\",\"geometry\"]],\n","                            how=\"left\", predicate=\"intersects\")\n","    gdf_cd_sub = gdf_cd_sub.drop_duplicates(subset=gdf_cd_sub.index.name or gdf_cd.index.name)\n","    if \"basin_id\" not in gdf_cd_sub.columns:\n","        gdf_cd[\"S_vf\"] = 5.0\n","    else:\n","        def get_vf_for_basin(bid):\n","            if bid in df_Vf.index:\n","                return score_valley_vf(df_Vf.loc[bid, \"Vf\"])\n","            return 5.0\n","        gdf_cd[\"S_vf\"] = gdf_cd_sub[\"basin_id\"].apply(\n","            lambda b: get_vf_for_basin(b) if pd.notna(b) else 5.0).values\n","except Exception:\n","    gdf_cd[\"S_vf\"] = 5.0\n","\n","# Weighted CDSI (weights reflect relative importance for check dam selection)\n","W = {\"order\": 0.30, \"area\": 0.25, \"slope\": 0.20, \"erosion\": 0.15, \"vf\": 0.10}\n","gdf_cd[\"CDSI\"] = (W[\"order\"]   * gdf_cd[\"S_order\"]   +\n","                   W[\"area\"]    * gdf_cd[\"S_area\"]    +\n","                   W[\"slope\"]   * gdf_cd[\"S_slope\"]   +\n","                   W[\"erosion\"] * gdf_cd[\"S_erosion\"] +\n","                   W[\"vf\"]      * gdf_cd[\"S_vf\"])\n","gdf_cd[\"CDSI\"] = gdf_cd[\"CDSI\"].clip(0, 10)\n","\n","# Classification\n","def cdsi_class(v):\n","    if v >= 7.5: return \"Very Suitable\"\n","    if v >= 5.5: return \"Suitable\"\n","    if v >= 3.5: return \"Moderately Suitable\"\n","    return \"Poorly Suitable\"\n","\n","gdf_cd[\"CDSI_class\"] = gdf_cd[\"CDSI\"].apply(cdsi_class)\n","\n","print(\"  CDSI distribution:\")\n","print(gdf_cd[\"CDSI_class\"].value_counts().to_string())\n","gdf_cd[[\"CDSI\",\"CDSI_class\",\"A_upstream_km2\",\"seg_slope_pct\",\n","         ORDER_COL]].to_csv(os.path.join(SWC_DIR, \"checkdam_suitability.csv\"))\n","gdf_cd.to_file(os.path.join(SHAPES_DIR, \"checkdam_suitability.shp\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. PERCOLATION POND / RECHARGE ZONE SUITABILITY\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[16-B] Percolation Pond & Groundwater Recharge Zones...\")\n","# Criteria: high TWI (water accumulates), low slope (<5Â°),\n","#           moderate FA (not first-order headwaters, not mainstem)\n","#           away from steep erosive zones\n","\n","TWI_safe2  = np.where(np.isnan(TWI_ARR), np.nanmin(TWI_ARR), TWI_ARR)\n","FA_norm    = np.log1p(np.where(np.isnan(FACC_ARR), 0, FACC_ARR))\n","FA_norm    = FA_norm / (np.nanmax(FA_norm) + 1e-9)\n","slope_n2   = 1.0 - (slope_safe / (np.nanmax(slope_safe) + 1e-9))  # inverted â€” flat preferred\n","\n","# TWI normalised\n","TWI_n      = (TWI_safe2 - np.nanmin(TWI_safe2)) / (np.nanmax(TWI_safe2) - np.nanmin(TWI_safe2) + 1e-9)\n","\n","# Filter to gentle slopes\n","mask_flat  = (slope_safe < 5.0).astype(float)\n","mask_flat[np.isnan(DEM_ARR)] = np.nan\n","\n","PERC_ARR   = (TWI_n * 0.50 + FA_norm * 0.30 + slope_n2 * 0.20) * mask_flat\n","PERC_ARR[np.isnan(DEM_ARR)] = np.nan\n","PERC_ARR   = np.clip(PERC_ARR, 0, 1)\n","\n","save_raster(PERC_ARR.astype(np.float32), os.path.join(OUT_DIR, \"percolation_potential.tif\"), RASTERS[\"dem\"])\n","RASTERS[\"percolation\"] = os.path.join(OUT_DIR, \"percolation_potential.tif\")\n","print(f\"  Percolation potential range: {np.nanmin(PERC_ARR):.3f}â€“{np.nanmax(PERC_ARR):.3f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. CONTOUR TRENCH SUITABILITY\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[16-C] Contour Trench Suitability...\")\n","# Contour trenches (staggered trenches across slope) work best where:\n","#  â€¢ Slope: 3â€“30Â° (too flat = no runoff to harvest; too steep = unstable)\n","#  â€¢ High RUSLE A (high erosion = high benefit from trenches)\n","#  â€¢ Not on stream channels (avoid blocking channels)\n","#  â€¢ Moderate soil depth (not rocky)\n","\n","slope_ok    = ((slope_safe >= 3) & (slope_safe < 30)).astype(float)\n","A_norm_c    = np.clip(A_ARR / (A_max_basin + 1e-9), 0, 1)\n","A_norm_c    = np.where(np.isnan(A_norm_c), 0, A_norm_c)\n","\n","# Penalise cells on channels (high flow accumulation)\n","FA_threshold = 500  # cells â€” anything above is a channel\n","not_channel = (FACC_ARR < FA_threshold).astype(float)\n","not_channel[np.isnan(FACC_ARR)] = 1.0\n","\n","CT_ARR = (slope_ok * 0.40 + A_norm_c * 0.40 + not_channel * 0.20)\n","CT_ARR[np.isnan(DEM_ARR)] = np.nan\n","CT_ARR = np.clip(CT_ARR, 0, 1)\n","\n","save_raster(CT_ARR.astype(np.float32), os.path.join(OUT_DIR, \"contour_trench_suitability.tif\"), RASTERS[\"dem\"])\n","RASTERS[\"contour_trench\"] = os.path.join(OUT_DIR, \"contour_trench_suitability.tif\")\n","print(f\"  Contour trench suitability range: {np.nanmin(CT_ARR):.3f}â€“{np.nanmax(CT_ARR):.3f}\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  D. PER-BASIN CONSERVATION SUMMARY & WATER HARVESTING POTENTIAL (WHP)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[16-D] Per-basin conservation statistics & Water Harvesting Potential...\")\n","\n","WHP_ROWS = []\n","\n","for _, row in gdf_sub.iterrows():\n","    bid  = row[\"basin_id\"]\n","    geom = [row.geometry.__geo_interface__]\n","    A_km2 = df_areal.loc[bid, \"Area_km2\"]\n","\n","    def clip_and_stats(raster_path):\n","        with rasterio.open(raster_path) as src:\n","            try:\n","                arr_m, _ = rio_mask(src, geom, crop=True, nodata=np.nan)\n","                arr = arr_m[0].astype(np.float32)\n","                arr[arr == -9999.0] = np.nan\n","                return arr\n","            except Exception:\n","                return np.array([np.nan])\n","\n","    perc_clip = clip_and_stats(RASTERS[\"percolation\"])\n","    ct_clip   = clip_and_stats(RASTERS[\"contour_trench\"])\n","    cn_clip   = clip_and_stats(RASTERS[\"CN\"])\n","    q_25yr_mm = df_runoff.loc[bid, \"Q_25yr_mm\"] if bid in df_runoff.index else np.nan\n","\n","    # WHP = potential runoff harvestable volume (25-yr event, mÂ³)\n","    # Adjusting for realistic harvesting fraction (0.4 = 40% captured)\n","    harvest_frac = 0.40\n","    WHP_m3       = float(q_25yr_mm) * 1e-3 * A_km2 * 1e6 * harvest_frac\n","\n","    # Check dam count potential: every 500â€“1000m on 1stâ€“2nd order streams\n","    n_suitable = int((gdf_cd[gdf_cd[\"CDSI_class\"].isin([\"Very Suitable\", \"Suitable\"])]\n","                       .geometry.length.sum() / 700.0))\n","\n","    WHP_ROWS.append({\n","        \"basin_id\"              : bid,\n","        \"Perc_Potential_mean\"   : round(float(np.nanmean(perc_clip)), 3),\n","        \"Perc_Potential_p75\"    : round(float(np.nanpercentile(perc_clip[~np.isnan(perc_clip)], 75)\n","                                              if np.any(~np.isnan(perc_clip)) else np.nan), 3),\n","        \"ContourTrench_mean\"    : round(float(np.nanmean(ct_clip)), 3),\n","        \"Pct_CT_suitable\"       : round(float(np.nanmean(ct_clip > 0.5)) * 100, 1),\n","        \"WHP_25yr_Mm3\"          : round(WHP_m3 / 1e6, 4),\n","        \"Potential_CheckDams_N\" : n_suitable,\n","        \"CN_mean\"               : round(float(np.nanmean(cn_clip)), 2),\n","        \"SWC_Priority\"          : (\"High\"     if df_rusle.loc[bid, \"A_mean_t_ha_yr\"] > 15 else\n","                                   \"Moderate\" if df_rusle.loc[bid, \"A_mean_t_ha_yr\"] > 5  else\n","                                   \"Low\") if bid in df_rusle.index else \"Unknown\"\n","    })\n","    print(f\"  {bid}: WHP={WHP_m3/1e6:.4f} MmÂ³ | CT_suit%={round(float(np.nanmean(ct_clip > 0.5))*100,1)}% \"\n","          f\"| Est. check dams={n_suitable}\")\n","\n","df_whp = pd.DataFrame(WHP_ROWS).set_index(\"basin_id\")\n","df_whp.to_csv(os.path.join(SWC_DIR, \"conservation_potential.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  E. SWC MAPS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[16-E] Generating conservation maps...\")\n","\n","# Check dam suitability map\n","cdsi_colors = {\"Very Suitable\": \"#1a9641\", \"Suitable\": \"#a6d96a\",\n","               \"Moderately Suitable\": \"#fdae61\", \"Poorly Suitable\": \"#d73027\"}\n","fig, ax, utm_ext = base_axes(\"Check Dam (Naala Bund) Suitability Map\\n\"\n","                              \"CDSI = f(Order, Catchment Area, Slope, Erosion, Valley Width)\")\n","for cls, color in cdsi_colors.items():\n","    segs = gdf_cd[gdf_cd[\"CDSI_class\"] == cls]\n","    if len(segs) > 0:\n","        segs.plot(ax=ax, color=color, linewidth=1.5+gdf_cd[gdf_cd[\"CDSI_class\"]==cls][ORDER_COL].mean()*0.3,\n","                  alpha=0.9, zorder=5, label=cls)\n","gdf_sub.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=1.5, zorder=15)\n","# Mark pour points as potential check dam sites\n","if \"gdf_pp\" in dir() and gdf_pp is not None:\n","    gdf_pp.plot(ax=ax, color=\"red\", markersize=80, marker=\"v\",\n","                zorder=20, label=\"Pour points (outlets)\", edgecolor=\"white\", linewidth=0.8)\n","patches_cd = [mpatches.Patch(color=v, label=k) for k, v in cdsi_colors.items()]\n","ax.legend(handles=patches_cd, loc=\"lower left\", fontsize=8,\n","          title=\"Check Dam Suitability\", title_fontsize=9, framealpha=0.9)\n","finalize_and_save(fig, ax, utm_ext, \"16a_checkdam_suitability.png\")\n","\n","# Composite SWC treatment map\n","fig, ax, utm_ext = base_axes(\"Soil & Water Conservation Treatment Zone Map\\n\"\n","                              \"(Contour Trenches + Percolation Potential)\")\n","# Percolation zones (background)\n","im1 = ax.imshow(PERC_ARR, extent=raster_extent(), origin=\"upper\",\n","                cmap=\"Blues\", alpha=0.55, zorder=1, vmin=0, vmax=1)\n","# Contour trench suitability (overlay)\n","im2 = ax.imshow(np.ma.masked_where(CT_ARR < 0.5, CT_ARR),\n","                extent=raster_extent(), origin=\"upper\",\n","                cmap=\"Oranges\", alpha=0.60, zorder=2, vmin=0.5, vmax=1)\n","gdf_sub.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, zorder=10)\n","# Suitable check dam stream reaches\n","gdf_cd[gdf_cd[\"CDSI\"] >= 5.5].plot(ax=ax, color=\"darkgreen\", linewidth=1.5, zorder=8, alpha=0.85)\n","gdf_cd[gdf_cd[\"CDSI\"] < 5.5].plot(ax=ax, color=\"lightgrey\",  linewidth=0.5, zorder=6, alpha=0.4)\n","\n","legend_items = [\n","    mpatches.Patch(color=\"#3182bd\", alpha=0.55, label=\"Percolation / Recharge Zone\"),\n","    mpatches.Patch(color=\"#e6550d\", alpha=0.60, label=\"Contour Trench Zone (slope 3â€“30Â°)\"),\n","    mpatches.Patch(color=\"darkgreen\",            label=\"Check Dam Sites (CDSI â‰¥ 5.5)\"),\n","]\n","ax.legend(handles=legend_items, loc=\"lower left\", fontsize=8,\n","          title=\"Treatment Zones\", title_fontsize=9, framealpha=0.9)\n","finalize_and_save(fig, ax, utm_ext, \"16b_SWC_treatment_zones.png\")\n","\n","# Plotly: WHP bar chart + SWC priority\n","fig = make_subplots(rows=1, cols=2,\n","                    subplot_titles=[\"Water Harvesting Potential (MmÂ³/25-yr event)\",\n","                                    \"SWC Priority & Estimated Check Dam Count\"])\n","swc_pmap = {\"High\": \"#d73027\", \"Moderate\": \"#fdae61\", \"Low\": \"#4575b4\"}\n","for i, (bid, row_) in enumerate(df_whp.iterrows()):\n","    c = swc_pmap.get(row_[\"SWC_Priority\"], \"grey\")\n","    fig.add_trace(go.Bar(\n","        x=[bid], y=[row_[\"WHP_25yr_Mm3\"]], marker_color=c, name=bid,\n","        text=f\"{row_['WHP_25yr_Mm3']:.4f}\", textposition=\"outside\",\n","        hovertemplate=f\"{bid}<br>WHP={row_['WHP_25yr_Mm3']:.4f} MmÂ³<br>Priority={row_['SWC_Priority']}\",\n","    ), row=1, col=1)\n","    fig.add_trace(go.Bar(\n","        x=[bid], y=[row_[\"Potential_CheckDams_N\"]], marker_color=c, name=bid,\n","        showlegend=False, text=str(row_[\"Potential_CheckDams_N\"]), textposition=\"outside\",\n","        hovertemplate=f\"{bid}<br>Est. check dams={row_['Potential_CheckDams_N']}\",\n","    ), row=1, col=2)\n","\n","fig.update_yaxes(title_text=\"Water Harvesting Potential (MmÂ³)\", row=1, col=1)\n","fig.update_yaxes(title_text=\"Estimated Check Dam Count\", row=1, col=2)\n","fig.update_layout(title=\"Soil & Water Conservation Potential â€” Pravara Subbasins\",\n","                  template=\"plotly_white\", height=480, showlegend=False)\n","save_fig(fig, \"16c_SWC_potential_bars\")\n","print(\"\\nâœ… SECTION 16 complete.\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# SECTION 17 â€” SYNTHETIC UNIT HYDROGRAPH\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"SECTION 17 â€” SYNTHETIC UNIT HYDROGRAPH (Snyder's & SCS Methods)\")\n","print(\"=\" * 70)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. SNYDER'S SYNTHETIC UNIT HYDROGRAPH\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[17-A] Snyder's Synthetic Unit Hydrograph parameters...\")\n","\n","# Snyder (1938) â€” calibrated for Indian semi-arid basins:\n","# Ct = 1.8 (lag coefficient, typical for Deccan Trap with moderate relief)\n","# Cp = 0.6 (peaking coefficient)\n","# tL = Ct Ã— (L Ã— Lca)^0.3      [L = basin length km, Lca = L to centroid km]\n","# Qp = 2.75 Ã— Cp Ã— A / tL      [Qp in mÂ³/s for 1mm/hr rainfall, A in kmÂ²]\n","# tp = tL + tr/2                [tp = time to peak; tr = storm duration = tL/5.5]\n","# W50 = 2.14 / (Qp/A)^1.08     [width at 50% Qp, hrs]\n","# W75 = 1.22 / (Qp/A)^1.08     [width at 75% Qp, hrs]\n","# tb  = 5 Ã— (tp + tr/2) / 24   [base time, hrs]  â€” approximate\n","\n","Ct = 1.8    # lag coefficient (Indian semi-arid, Deccan Trap)\n","Cp = 0.6    # peak coefficient\n","\n","SUH_ROWS = []\n","\n","for _, row in gdf_sub.iterrows():\n","    bid   = row[\"basin_id\"]\n","    geom  = row.geometry\n","    A_km2 = df_areal.loc[bid, \"Area_km2\"]\n","    L_km  = df_areal.loc[bid, \"Basin_Length_km\"]\n","\n","    # Lca: distance from outlet to centroid along main channel\n","    # Approximate as 0.6 Ã— L for natural basins (standard assumption)\n","    Lca_km = 0.6 * L_km\n","\n","    # Snyder lag time\n","    tL_hr  = Ct * (L_km * Lca_km) ** 0.3      # hours\n","\n","    # Standard storm duration\n","    tr_hr  = tL_hr / 5.5\n","\n","    # Time to peak\n","    tp_hr  = tL_hr + tr_hr / 2.0\n","\n","    # Peak discharge (mÂ³/s per mm of rainfall over basin)\n","    Qp     = 2.75 * Cp * A_km2 / tL_hr\n","\n","    # Unit area peak\n","    qp     = Qp / A_km2   # mÂ³/s/kmÂ² per mm\n","\n","    # Hydrograph widths\n","    W50    = 2.14 / (qp ** 1.08)   # hrs\n","    W75    = 1.22 / (qp ** 1.08)   # hrs\n","\n","    # Base time\n","    tb_hr  = 5.0 * tp_hr / 1.0     # approximate (Linsley et al. rule)\n","    tb_hr  = max(tb_hr, 2.0 * tp_hr)  # at least 2Ã—tp\n","\n","    # Time of rise and recession\n","    tr_rise = tp_hr\n","    tr_recs = tb_hr - tp_hr\n","\n","    # Return-period peak discharge (mÂ³/s)\n","    QP_RT = {}\n","    for T in RETURN_PERIODS:\n","        P24  = RAINFALL_RT[T]\n","        Q_mm = float(scscn_runoff(P24, df_runoff.loc[bid,\"CN_mean\"] if bid in df_runoff.index else 78))\n","        QP_RT[T] = round(Qp * Q_mm, 2)   # Qp [mÂ³/s] = unit Qp Ã— Q [mm]\n","\n","    r_suh = {\n","        \"basin_id\"    : bid,\n","        \"L_km\"        : round(L_km, 3),\n","        \"Lca_km\"      : round(Lca_km, 3),\n","        \"A_km2\"       : round(A_km2, 3),\n","        \"tL_hr\"       : round(tL_hr, 3),\n","        \"tr_hr\"       : round(tr_hr, 3),\n","        \"tp_hr\"       : round(tp_hr, 3),\n","        \"Qp_1mm_m3s\"  : round(Qp, 4),\n","        \"qp_m3s_km2\"  : round(qp, 5),\n","        \"W50_hr\"      : round(W50, 3),\n","        \"W75_hr\"      : round(W75, 3),\n","        \"tb_hr\"       : round(tb_hr, 3),\n","    }\n","    for T in RETURN_PERIODS:\n","        r_suh[f\"Qp_{T}yr_m3s\"] = QP_RT[T]\n","\n","    SUH_ROWS.append(r_suh)\n","    print(f\"  {bid}: tL={tL_hr:.2f}hr | tp={tp_hr:.2f}hr | \"\n","          f\"Qp(1mm)={Qp:.3f} mÂ³/s | W50={W50:.2f}hr | W75={W75:.2f}hr\")\n","\n","df_suh = pd.DataFrame(SUH_ROWS).set_index(\"basin_id\")\n","df_suh.to_csv(os.path.join(UHG_DIR, \"snyder_unit_hydrograph_params.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. SCS DIMENSIONLESS UNIT HYDROGRAPH\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[17-B] SCS Dimensionless Unit Hydrograph...\")\n","\n","# SCS dimensionless ratios (t/tp vs Q/Qp)\n","SCS_DIM = np.array([\n","    [0.0, 0.000], [0.1, 0.030], [0.2, 0.100], [0.3, 0.190], [0.4, 0.310],\n","    [0.5, 0.470], [0.6, 0.660], [0.7, 0.820], [0.8, 0.930], [0.9, 0.990],\n","    [1.0, 1.000], [1.1, 0.990], [1.2, 0.930], [1.3, 0.860], [1.4, 0.780],\n","    [1.5, 0.680], [1.6, 0.560], [1.7, 0.460], [1.8, 0.390], [1.9, 0.330],\n","    [2.0, 0.280], [2.2, 0.207], [2.4, 0.147], [2.6, 0.107], [2.8, 0.077],\n","    [3.0, 0.055], [3.5, 0.025], [4.0, 0.011], [4.5, 0.005], [5.0, 0.000],\n","])\n","t_ratio = SCS_DIM[:, 0]\n","q_ratio = SCS_DIM[:, 1]\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. HYDROGRAPH PLOTS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[17-C] Generating unit hydrograph plots...\")\n","\n","# Matplotlib: all basins on one figure\n","fig, axes = plt.subplots(len(df_suh), 1,\n","                         figsize=(12, 4 * len(df_suh)),\n","                         sharex=False)\n","if len(df_suh) == 1:\n","    axes = [axes]\n","\n","colors_suh = plt.cm.Set1(np.linspace(0, 1, max(len(df_suh), 2)))\n","\n","for ax_i, (bid, suh) in enumerate(df_suh.iterrows()):\n","    ax = axes[ax_i]\n","    tp = suh[\"tp_hr\"]\n","    tb = suh[\"tb_hr\"]\n","\n","    # SCS-based hydrograph for 25-yr storm\n","    Q25_mm = (float(df_runoff.loc[bid, \"Q_25yr_mm\"])\n","               if bid in df_runoff.index else 25.0)\n","    Qp_25  = suh[\"Qp_1mm_m3s\"] * Q25_mm\n","\n","    t_abs  = t_ratio * tp\n","    t_full = np.linspace(0, tb * 1.05, 500)\n","    from scipy.interpolate import interp1d\n","    q_interp = interp1d(t_ratio * tp, q_ratio * Qp_25,\n","                         kind=\"linear\", fill_value=0.0, bounds_error=False)\n","    q_full   = q_interp(t_full)\n","\n","    ax.fill_between(t_full, 0, q_full, alpha=0.25, color=colors_suh[ax_i])\n","    ax.plot(t_full, q_full, color=colors_suh[ax_i], linewidth=2.2,\n","            label=f\"{bid} â€” 25-yr (Q={Q25_mm:.0f}mm)\")\n","\n","    # Also plot 10-yr and 50-yr for comparison\n","    for T_comp, ls, alpha_c in [(10, \"--\", 0.6), (50, \"-.\", 0.6)]:\n","        Qmm_c = float(df_runoff.loc[bid, f\"Q_{T_comp}yr_mm\"]\n","                       if bid in df_runoff.index else 20.0)\n","        Qp_c  = suh[\"Qp_1mm_m3s\"] * Qmm_c\n","        ax.plot(t_full, q_interp(t_full) * (Qp_c / (Qp_25 + 1e-9)),\n","                color=colors_suh[ax_i], linestyle=ls, linewidth=1.5, alpha=alpha_c,\n","                label=f\"{T_comp}-yr\")\n","\n","    # Annotate Qp and tp\n","    ax.axvline(tp, color=\"grey\", linestyle=\":\", linewidth=1.2)\n","    ax.axhline(Qp_25, color=\"grey\", linestyle=\":\", linewidth=0.8)\n","    ax.annotate(f\"Qp={Qp_25:.1f} mÂ³/s\\ntp={tp:.2f} hr\",\n","                xy=(tp, Qp_25), xytext=(tp + 0.5, Qp_25 * 0.75),\n","                fontsize=9, arrowprops=dict(arrowstyle=\"->\", color=\"black\"))\n","\n","    # W50 and W75 hatching\n","    w50_half = suh[\"W50_hr\"] / 2.0\n","    w75_half = suh[\"W75_hr\"] / 2.0\n","    ax.axvspan(tp - w50_half, tp + w50_half, alpha=0.08, color=\"blue\", label=\"W50\")\n","    ax.axvspan(tp - w75_half, tp + w75_half, alpha=0.08, color=\"red\",  label=\"W75\")\n","\n","    ax.set_title(f\"Synthetic Unit Hydrograph â€” {bid}  \"\n","                 f\"(A={suh['A_km2']:.1f} kmÂ², L={suh['L_km']:.2f} km)\",\n","                 fontweight=\"bold\", fontsize=11)\n","    ax.set_xlabel(\"Time (hours)\", fontsize=9)\n","    ax.set_ylabel(\"Discharge (mÂ³/s)\", fontsize=9)\n","    ax.legend(fontsize=8, loc=\"upper right\", framealpha=0.85)\n","    ax.grid(True, linestyle=\"--\", alpha=0.4)\n","    ax.set_xlim(0, tb * 1.05)\n","    ax.set_ylim(bottom=0)\n","\n","plt.suptitle(\"Synthetic Unit Hydrographs â€” Pravara Subbasins\\n\"\n","             \"Snyder's Method with SCS Dimensionless UH Shape | Ct=1.8, Cp=0.6\",\n","             fontsize=13, fontweight=\"bold\", y=1.01)\n","plt.tight_layout()\n","fig.savefig(os.path.join(UHG_DIR, \"17_unit_hydrographs.png\"), dpi=180, bbox_inches=\"tight\")\n","plt.close(fig)\n","print(f\"  âœ… Hydrograph plot saved\")\n","\n","# Plotly: interactive multi-basin hydrograph\n","fig_hy = go.Figure()\n","for i, (bid, suh) in enumerate(df_suh.iterrows()):\n","    tp = suh[\"tp_hr\"]\n","    tb = suh[\"tb_hr\"]\n","    Q25_mm = float(df_runoff.loc[bid, \"Q_25yr_mm\"] if bid in df_runoff.index else 25.0)\n","    Qp_25  = suh[\"Qp_1mm_m3s\"] * Q25_mm\n","    t_full = np.linspace(0, tb * 1.05, 300)\n","    q_interp = interp1d(t_ratio * tp, q_ratio * Qp_25,\n","                         kind=\"linear\", fill_value=0.0, bounds_error=False)\n","    q_full = q_interp(t_full)\n","\n","    fig_hy.add_trace(go.Scatter(\n","        x=t_full.tolist(), y=q_full.tolist(),\n","        mode=\"lines\", name=f\"{bid} (25-yr)\",\n","        fill=\"tozeroy\",\n","        line=dict(color=px.colors.qualitative.Set1[i % 9], width=2.5),\n","        hovertemplate=f\"{bid}<br>t=%{{x:.2f}} hr<br>Q=%{{y:.2f}} mÂ³/s\",\n","    ))\n","    # Mark Qp\n","    fig_hy.add_trace(go.Scatter(\n","        x=[tp], y=[Qp_25], mode=\"markers+text\",\n","        text=[f\"Qp={Qp_25:.1f}\"], textposition=\"top center\",\n","        marker=dict(size=10, color=px.colors.qualitative.Set1[i % 9], symbol=\"diamond\"),\n","        name=f\"{bid} peak\", showlegend=False,\n","    ))\n","\n","fig_hy.update_layout(\n","    title=\"Synthetic Unit Hydrographs â€” 25-year Return Period Event<br>\"\n","          \"<sup>Snyder's Method, Deccan Trap basalt calibration: Ct=1.8, Cp=0.6</sup>\",\n","    xaxis_title=\"Time (hours)\",\n","    yaxis_title=\"Discharge Q (mÂ³/s)\",\n","    template=\"plotly_white\", height=550,\n",")\n","save_fig(fig_hy, \"17b_synthetic_unit_hydrographs\")\n","\n","# Summary table plot\n","cols_suh = [\"tp_hr\", \"Qp_1mm_m3s\", \"W50_hr\", \"W75_hr\", \"tb_hr\",\n","             \"Qp_25yr_m3s\", \"Qp_100yr_m3s\"]\n","fig_tbl = go.Figure(go.Table(\n","    header=dict(\n","        values=[\"Basin\", \"tp (hr)\", \"Qp_unit (mÂ³/s)\", \"W50 (hr)\", \"W75 (hr)\",\n","                \"tb (hr)\", \"Qp 25-yr\", \"Qp 100-yr\"],\n","        fill_color=\"#2c5f8c\", font_color=\"white\",\n","        align=\"center\", line_color=\"white\",\n","    ),\n","    cells=dict(\n","        values=[\n","            df_suh.index.tolist(),\n","            df_suh[\"tp_hr\"].round(2).tolist(),\n","            df_suh[\"Qp_1mm_m3s\"].round(4).tolist(),\n","            df_suh[\"W50_hr\"].round(2).tolist(),\n","            df_suh[\"W75_hr\"].round(2).tolist(),\n","            df_suh[\"tb_hr\"].round(2).tolist(),\n","            df_suh[\"Qp_25yr_m3s\"].tolist(),\n","            df_suh[\"Qp_100yr_m3s\"].tolist(),\n","        ],\n","        fill_color=[[\"#f0f4ff\", \"#dce8ff\"] * len(df_suh)],\n","        align=\"center\",\n","    )\n","))\n","fig_tbl.update_layout(title=\"Snyder's UH Parameter Summary Table\",\n","                       template=\"plotly_white\", height=300)\n","save_fig(fig_tbl, \"17c_UH_parameter_table\")\n","print(\"\\nâœ… SECTION 17 complete.\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# SECTION 18 â€” STREAM CHANNEL HYDRAULICS & STABILITY ANALYSIS\n","# â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"SECTION 18 â€” STREAM CHANNEL HYDRAULICS & STABILITY\")\n","print(\"(Bankfull Discharge, Shear Stress, Stream Power, Stability Index)\")\n","print(\"=\" * 70)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  A. HYDRAULIC GEOMETRY â€” Leopold & Maddock (1953) Regional Curves\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# For Indian semi-arid Deccan rivers, regional hydraulic geometry:\n","#   w = a Ã— Q^b     (bankfull width, b â‰ˆ 0.50)\n","#   d = c Ã— Q^f     (bankfull depth, f â‰ˆ 0.40)\n","#   v = k Ã— Q^m     (mean velocity, m â‰ˆ 0.10)\n","# Calibrated coefficients for Deccan Trap basalt basins:\n","#   a=3.2, b=0.50; c=0.28, f=0.40; k=1.12, m=0.10\n","# Q_bankfull estimated as Q(1.5-yr) â€” typical recurrence for bankfull stage\n","\n","print(\"\\n[18-A] Bankfull Discharge & Hydraulic Geometry...\")\n","\n","# Bankfull discharge: Q(1.5-yr) via Gumbel interpolation\n","T_bf = 1.5\n","y_bf = -np.log(-np.log(1 - 1/T_bf))\n","P_bf_annual = u_g + alpha_g * y_bf          # annual rainfall\n","P_bf_24hr   = P_bf_annual * DAILY_FRACTION\n","\n","HG_ROWS = []\n","\n","for _, row in gdf_sub.iterrows():\n","    bid   = row[\"basin_id\"]\n","    A_km2 = df_areal.loc[bid, \"Area_km2\"]\n","    L_km  = df_areal.loc[bid, \"Basin_Length_km\"]\n","    CN    = df_runoff.loc[bid, \"CN_mean\"] if bid in df_runoff.index else 78.0\n","    Tc_hr = df_tc.loc[bid, \"Tc_hr\"] if bid in df_tc.index else 2.0\n","\n","    # Bankfull Q (1.5-yr)\n","    Q_bf_mm = float(scscn_runoff(P_bf_24hr, CN))\n","    C_bf    = float(runoff_coeff(P_bf_24hr, CN))\n","    i_bf    = (P_bf_24hr / 24.0) * (24.0 / Tc_hr) ** (2.0/3.0)\n","    Q_bf    = C_bf * i_bf * A_km2 / 3.6   # mÂ³/s\n","\n","    # Hydraulic geometry (Leopold-Maddock regional coefficients â€” Deccan)\n","    a_w, b_w = 3.20, 0.50   # width\n","    a_d, b_d = 0.28, 0.40   # depth\n","    a_v, b_v = 1.12, 0.10   # velocity\n","\n","    W_bf = a_w * (Q_bf ** b_w)   # bankfull width [m]\n","    D_bf = a_d * (Q_bf ** b_d)   # bankfull depth [m]\n","    V_bf = a_v * (Q_bf ** b_v)   # bankfull velocity [m/s]\n","\n","    # Cross-sectional area and hydraulic radius\n","    A_cs = W_bf * D_bf * 0.80   # assuming trapezoidal Ã— efficiency factor\n","    R_hyd = A_cs / (W_bf + 2*D_bf)  # hydraulic radius [m]\n","\n","    # Channel bed slope from DEM relief and basin length\n","    H_m    = df_relief.loc[bid, \"Basin_Relief_H_m\"] if bid in df_relief.index else 100.0\n","    S_ch   = H_m / (L_km * 1000.0)   # dimensionless\n","\n","    # Manning's n (estimated for Deccan basalt-lined channels)\n","    # Rocky channels: n â‰ˆ 0.035â€“0.050; alluvial gravel: n â‰ˆ 0.025â€“0.035\n","    n_mann = 0.038 + 0.002 * (1 - min(S_ch / 0.01, 1))  # slightly rougher on steeper slopes\n","\n","    # Manning's Q (check)\n","    Q_mann = (1.0 / n_mann) * A_cs * (R_hyd ** (2/3)) * (S_ch ** 0.5)\n","\n","    # â”€â”€ Shear stress â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    # Ï„â‚€ = Ï Ã— g Ã— R Ã— S  [N/mÂ² = Pa]\n","    rho_water = 1000.0   # kg/mÂ³\n","    g         = 9.81     # m/sÂ²\n","    tau0      = rho_water * g * R_hyd * S_ch   # bed shear stress [Pa]\n","\n","    # Critical shear stress â€” Shields (D50 â‰ˆ 15mm for basalt gravel)\n","    # Ï„_c = Î¸_c Ã— (Ï_s - Ï) Ã— g Ã— D50\n","    D50_m    = 0.015    # median grain size [m] â€” basaltic gravel\n","    rho_s    = 2650.0   # sediment density [kg/mÂ³]\n","    theta_c  = 0.047    # Shields parameter for D50 >10mm\n","    tau_c    = theta_c * (rho_s - rho_water) * g * D50_m   # critical shear [Pa]\n","\n","    excess_shear = tau0 - tau_c   # positive = bed mobility\n","\n","    # â”€â”€ Stream power â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    # Î© = Ï Ã— g Ã— Q Ã— S   [W/m]   total stream power\n","    # Ï‰ = Î© / w            [W/mÂ²]  specific (unit width) stream power\n","    Omega_total   = rho_water * g * Q_bf * S_ch\n","    omega_spec    = Omega_total / W_bf   # W/mÂ²\n","\n","    # Critical specific stream power (Bagnold 1966):\n","    # Ï‰_c â‰ˆ 35.0 W/mÂ² for coarse sandâ€“gravel in semi-arid rivers\n","    omega_c = 35.0\n","    omega_excess = omega_spec - omega_c\n","\n","    # â”€â”€ Channel stability index â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    # Regime theory: stable channel has W/D (aspect ratio) within bounds\n","    # For Deccan semi-arid channels: W/D < 15 = stable; 15â€“30 = marginally stable\n","    WD_ratio = W_bf / max(D_bf, 0.01)\n","\n","    def channel_stability(WD, excess_shear_val, omega_exc):\n","        \"\"\"Combined channel stability assessment.\"\"\"\n","        score = 0\n","        if WD < 12:          score += 3   # narrow deep = stable\n","        elif WD < 20:        score += 2\n","        elif WD < 30:        score += 1\n","        if excess_shear_val < 0:  score += 3  # sub-critical shear = stable\n","        elif excess_shear_val < 5: score += 2\n","        elif excess_shear_val < 15: score += 1\n","        if omega_exc < 0:    score += 3   # sub-critical stream power\n","        elif omega_exc < 20: score += 2\n","        elif omega_exc < 50: score += 1\n","        if score >= 7:  return \"Stable\"\n","        if score >= 5:  return \"Marginally Stable\"\n","        if score >= 3:  return \"Unstable\"\n","        return \"Highly Unstable\"\n","\n","    stab_class = channel_stability(WD_ratio, excess_shear, omega_excess)\n","\n","    # â”€â”€ Sediment transport capacity (Einstein-Brown simplified) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","    # Using unit stream power approach: Qs âˆ Ï‰_excessÂ² for Ï‰ > Ï‰_c\n","    if omega_excess > 0:\n","        Qs_relative = (omega_excess / omega_c) ** 2.0  # relative transport capacity\n","    else:\n","        Qs_relative = 0.0\n","\n","    HG_ROWS.append({\n","        \"basin_id\"              : bid,\n","        \"Q_bankfull_m3s\"        : round(Q_bf, 3),\n","        \"W_bankfull_m\"          : round(W_bf, 2),\n","        \"D_bankfull_m\"          : round(D_bf, 2),\n","        \"V_bankfull_ms\"         : round(V_bf, 3),\n","        \"WD_ratio\"              : round(WD_ratio, 2),\n","        \"R_hydraulic_m\"         : round(R_hyd, 3),\n","        \"Channel_Slope_S\"       : round(S_ch, 6),\n","        \"Manning_n\"             : round(n_mann, 4),\n","        \"Q_Manning_m3s\"         : round(Q_mann, 3),\n","        \"Shear_Stress_Pa\"       : round(tau0, 3),\n","        \"Critical_Shear_Pa\"     : round(tau_c, 3),\n","        \"Excess_Shear_Pa\"       : round(excess_shear, 3),\n","        \"Stream_Power_total_Wm\" : round(Omega_total, 2),\n","        \"Stream_Power_spec_Wm2\" : round(omega_spec, 3),\n","        \"Excess_Sp_Power_Wm2\"   : round(omega_excess, 3),\n","        \"Transport_Capacity_rel\": round(Qs_relative, 3),\n","        \"Channel_Stability\"     : stab_class,\n","    })\n","    print(f\"  {bid}: Q_bf={Q_bf:.2f} mÂ³/s | W={W_bf:.1f}m | D={D_bf:.2f}m | \"\n","          f\"Ï„={tau0:.1f}Pa | Ï‰={omega_spec:.1f} W/mÂ² | {stab_class}\")\n","\n","df_hg = pd.DataFrame(HG_ROWS).set_index(\"basin_id\")\n","df_hg.to_csv(os.path.join(HYD_DIR, \"channel_hydraulics.csv\"))\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  B. STREAM POWER INDEX PER ORDER â€” GEOMORPHIC WORK BY ORDER\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[18-B] Stream power analysis per Strahler order...\")\n","\n","# For each order, compute mean gradient, estimated Q, and stream power\n","ORDER_POWER_ROWS = []\n","orders_all = sorted(gdf_so[ORDER_COL].unique())\n","\n","for o in orders_all:\n","    segs = gdf_so[gdf_so[ORDER_COL] == o]\n","    n_segs  = len(segs)\n","    L_total_m = segs.geometry.length.sum()\n","    L_mean_m  = segs.geometry.length.mean()\n","\n","    # Sample slope at each segment\n","    seg_slopes = []\n","    for _, seg in segs.iterrows():\n","        s = sample_slope_at_segment(seg.geometry, SLOPE_ARR, DEM_TRANSFORM)\n","        if s is not None and not np.isnan(s):\n","            seg_slopes.append(s)\n","    mean_slope_deg = float(np.nanmean(seg_slopes)) if seg_slopes else 5.0\n","    S_order = np.tan(np.radians(max(mean_slope_deg, 0.1)))\n","\n","    # Estimate Q for this order using Hack's (1957) scaling:\n","    # Q_order â‰ˆ Q_max_basin Ã— (Dd_order / Dd_total)\n","    # Simpler: Q scales with segment length proxy\n","    Q_order_proxy = 0.02 * (o ** 2.5) * np.mean(\n","        [df_runoff.loc[bid, \"Q_25yr_mm\"] if bid in df_runoff.index else 25\n","         for bid in gdf_sub[\"basin_id\"]]) * 1e-3  # rough proxy\n","\n","    omega_order = rho_water * g * Q_order_proxy * S_order / max(\n","        3.2 * (Q_order_proxy ** 0.5), 0.5)  # W/mÂ²\n","\n","    ORDER_POWER_ROWS.append({\n","        \"Strahler_Order\"     : o,\n","        \"N_segments\"         : n_segs,\n","        \"Total_Length_km\"    : round(L_total_m / 1000, 2),\n","        \"Mean_Seg_Length_m\"  : round(L_mean_m, 1),\n","        \"Mean_Slope_deg\"     : round(mean_slope_deg, 2),\n","        \"Mean_Slope_frac\"    : round(S_order, 5),\n","        \"Qproxy_m3s\"         : round(Q_order_proxy, 4),\n","        \"StreamPower_Wm2\"    : round(omega_order, 2),\n","    })\n","    print(f\"  Order {o}: N={n_segs:4d} | L_tot={L_total_m/1000:.1f} km | \"\n","          f\"S_mean={mean_slope_deg:.2f}Â° | Ï‰â‰ˆ{omega_order:.2f} W/mÂ²\")\n","\n","df_order_power = pd.DataFrame(ORDER_POWER_ROWS)\n","df_order_power.to_csv(os.path.join(HYD_DIR, \"stream_order_power.csv\"), index=False)\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  C. COMPREHENSIVE MAPS & PLOTLY CHARTS\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n[18-C] Generating hydraulics maps and charts...\")\n","\n","# Bankfull width map (choropleth per basin)\n","fig, ax, utm_ext = base_axes(\"Bankfull Channel Width & Hydraulic Geometry\\n\"\n","                              \"Leopold-Maddock Regional Curves (Deccan Trap)\")\n","gdf_hg = gdf_sub.merge(df_hg.reset_index(), on=\"basin_id\", how=\"left\")\n","gdf_hg.plot(column=\"W_bankfull_m\", ax=ax, cmap=\"YlOrRd\", legend=True,\n","            alpha=0.75, zorder=2, edgecolor=\"black\", linewidth=1.2,\n","            legend_kwds={\"label\":\"Bankfull Width (m)\",\"shrink\":0.75})\n","for _, r in gdf_hg.iterrows():\n","    cx, cy = r.geometry.centroid.x, r.geometry.centroid.y\n","    ax.text(cx, cy,\n","            f\"{r['basin_id']}\\nW={r['W_bankfull_m']:.1f}m\\nD={r['D_bankfull_m']:.2f}m\",\n","            ha=\"center\", va=\"center\", fontsize=7.5, fontweight=\"bold\",\n","            path_effects=[pe.withStroke(linewidth=2, foreground=\"white\")])\n","# Stream network coloured by order\n","for o in orders_all:\n","    segs = gdf_so[gdf_so[ORDER_COL] == o]\n","    lw   = 0.4 + o * 0.6\n","    segs.plot(ax=ax, linewidth=lw, color=plt.cm.Blues(0.3 + o * 0.15), zorder=5, alpha=0.9)\n","finalize_and_save(fig, ax, utm_ext, \"18a_bankfull_hydraulics.png\")\n","\n","# Channel stability map\n","stab_colors = {\"Stable\": \"#1a9641\", \"Marginally Stable\": \"#fdae61\",\n","               \"Unstable\": \"#d73027\", \"Highly Unstable\": \"#7f0000\"}\n","fig, ax, utm_ext = base_axes(\"Channel Stability Classification Map\\n\"\n","                              \"(Shear Stress, Stream Power, W/D Ratio)\")\n","for _, r in gdf_hg.iterrows():\n","    col = stab_colors.get(r[\"Channel_Stability\"], \"grey\")\n","    gpd.GeoDataFrame([r], geometry=\"geometry\", crs=gdf_sub.crs).plot(\n","        ax=ax, color=col, edgecolor=\"black\", linewidth=1.2, alpha=0.80, zorder=3)\n","    cx, cy = r.geometry.centroid.x, r.geometry.centroid.y\n","    ax.text(cx, cy, f\"{r['basin_id']}\\n{r['Channel_Stability']}\\nÏ„={r['Shear_Stress_Pa']:.1f}Pa\",\n","            ha=\"center\", va=\"center\", fontsize=7.5, fontweight=\"bold\",\n","            path_effects=[pe.withStroke(linewidth=2, foreground=\"white\")])\n","gdf_streams.plot(ax=ax, color=\"royalblue\", linewidth=0.7, alpha=0.5, zorder=8)\n","patches_st = [mpatches.Patch(color=v, label=k) for k, v in stab_colors.items()]\n","ax.legend(handles=patches_st, loc=\"lower left\", fontsize=8,\n","          title=\"Channel Stability\", title_fontsize=9, framealpha=0.9)\n","finalize_and_save(fig, ax, utm_ext, \"18b_channel_stability.png\")\n","\n","# Plotly: stream power vs shear stress bubble\n","fig = make_subplots(rows=1, cols=2,\n","                    subplot_titles=[\"Stream Power vs Shear Stress per Basin\",\n","                                    \"Stream Power by Strahler Order\"])\n","stab_c_map = {\"Stable\":\"#1a9641\",\"Marginally Stable\":\"#fdae61\",\n","              \"Unstable\":\"#d73027\",\"Highly Unstable\":\"#7f0000\"}\n","for i, (bid, r) in enumerate(df_hg.iterrows()):\n","    c = stab_c_map.get(r[\"Channel_Stability\"], \"grey\")\n","    fig.add_trace(go.Scatter(\n","        x=[r[\"Shear_Stress_Pa\"]], y=[r[\"Stream_Power_spec_Wm2\"]],\n","        mode=\"markers+text\", text=[bid], textposition=\"top center\",\n","        marker=dict(size=r[\"W_bankfull_m\"] * 2.5, color=c, opacity=0.85,\n","                    line=dict(width=1, color=\"black\")),\n","        name=bid,\n","        hovertemplate=(f\"<b>{bid}</b><br>\"\n","                       f\"Ï„ = {r['Shear_Stress_Pa']:.2f} Pa<br>\"\n","                       f\"Ï‰ = {r['Stream_Power_spec_Wm2']:.2f} W/mÂ²<br>\"\n","                       f\"Q_bf = {r['Q_bankfull_m3s']:.2f} mÂ³/s<br>\"\n","                       f\"Stability: {r['Channel_Stability']}\"),\n","    ), row=1, col=1)\n","\n","# Order power bar\n","fig.add_trace(go.Bar(\n","    x=df_order_power[\"Strahler_Order\"].tolist(),\n","    y=df_order_power[\"StreamPower_Wm2\"].tolist(),\n","    marker_color=px.colors.sequential.Blues[2:],\n","    text=[f\"{v:.2f}\" for v in df_order_power[\"StreamPower_Wm2\"]],\n","    textposition=\"outside\",\n","    hovertemplate=\"Order %{x}<br>Ï‰=%{y:.2f} W/mÂ²\",\n","    name=\"Stream Power\",\n","), row=1, col=2)\n","\n","# Critical stream power line\n","fig.add_hline(y=35, line_dash=\"dash\", line_color=\"red\",\n","              annotation_text=\"Ï‰_c = 35 W/mÂ² (critical)\", row=1, col=1)\n","fig.add_hline(y=35, line_dash=\"dash\", line_color=\"red\", row=1, col=2)\n","\n","fig.update_xaxes(title_text=\"Bed Shear Stress Ï„â‚€ (Pa)\", row=1, col=1)\n","fig.update_yaxes(title_text=\"Specific Stream Power Ï‰ (W/mÂ²)\", row=1, col=1)\n","fig.update_xaxes(title_text=\"Strahler Order\", row=1, col=2)\n","fig.update_yaxes(title_text=\"Ï‰ (W/mÂ²)\", row=1, col=2)\n","fig.update_layout(title=\"Stream Channel Hydraulics â€” Pravara River Basin\",\n","                  template=\"plotly_white\", height=520)\n","save_fig(fig, \"18c_stream_power_hydraulics\")\n","\n","# Plotly: Hydraulic geometry log-log plots\n","fig = make_subplots(rows=1, cols=3,\n","                    subplot_titles=[\"Bankfull Width (W-Q)\", \"Bankfull Depth (D-Q)\",\n","                                    \"Bankfull Velocity (V-Q)\"])\n","for i, (bid, r) in enumerate(df_hg.iterrows()):\n","    c = px.colors.qualitative.Set1[i % 9]\n","    fig.add_trace(go.Scatter(\n","        x=[r[\"Q_bankfull_m3s\"]], y=[r[\"W_bankfull_m\"]],\n","        mode=\"markers+text\", text=[bid], textposition=\"top center\",\n","        marker=dict(size=12, color=c), name=bid, legendgroup=bid,\n","        hovertemplate=f\"{bid}<br>Q={r['Q_bankfull_m3s']:.2f} mÂ³/s<br>W={r['W_bankfull_m']:.2f} m\",\n","    ), row=1, col=1)\n","    fig.add_trace(go.Scatter(\n","        x=[r[\"Q_bankfull_m3s\"]], y=[r[\"D_bankfull_m\"]],\n","        mode=\"markers\", marker=dict(size=12, color=c), name=bid,\n","        legendgroup=bid, showlegend=False,\n","        hovertemplate=f\"{bid}<br>Q={r['Q_bankfull_m3s']:.2f} mÂ³/s<br>D={r['D_bankfull_m']:.2f} m\",\n","    ), row=1, col=2)\n","    fig.add_trace(go.Scatter(\n","        x=[r[\"Q_bankfull_m3s\"]], y=[r[\"V_bankfull_ms\"]],\n","        mode=\"markers\", marker=dict(size=12, color=c), name=bid,\n","        legendgroup=bid, showlegend=False,\n","        hovertemplate=f\"{bid}<br>Q={r['Q_bankfull_m3s']:.2f} mÂ³/s<br>V={r['V_bankfull_ms']:.3f} m/s\",\n","    ), row=1, col=3)\n","\n","# Leopold-Maddock regional curves (dashed lines)\n","Q_range = np.logspace(-1, 2, 50)\n","fig.add_trace(go.Scatter(x=Q_range.tolist(), y=(3.20*Q_range**0.50).tolist(),\n","    mode=\"lines\", line=dict(dash=\"dash\",color=\"grey\",width=1.5), name=\"W=3.2Q^0.5\",\n","    hoverinfo=\"skip\"), row=1, col=1)\n","fig.add_trace(go.Scatter(x=Q_range.tolist(), y=(0.28*Q_range**0.40).tolist(),\n","    mode=\"lines\", line=dict(dash=\"dash\",color=\"grey\",width=1.5), name=\"D=0.28Q^0.4\",\n","    showlegend=False, hoverinfo=\"skip\"), row=1, col=2)\n","fig.add_trace(go.Scatter(x=Q_range.tolist(), y=(1.12*Q_range**0.10).tolist(),\n","    mode=\"lines\", line=dict(dash=\"dash\",color=\"grey\",width=1.5), name=\"V=1.12Q^0.1\",\n","    showlegend=False, hoverinfo=\"skip\"), row=1, col=3)\n","\n","for col_i, ylabel in [(1,\"Width W (m)\"), (2,\"Depth D (m)\"), (3,\"Velocity V (m/s)\")]:\n","    fig.update_xaxes(type=\"log\", title_text=\"Bankfull Q (mÂ³/s)\", row=1, col=col_i)\n","    fig.update_yaxes(type=\"log\", title_text=ylabel, row=1, col=col_i)\n","\n","fig.update_layout(title=\"Hydraulic Geometry â€” At-a-Station Relationships (log-log)<br>\"\n","                        \"<sup>Leopold-Maddock (1953) regional curves for Deccan Trap basalt</sup>\",\n","                  template=\"plotly_white\", height=500)\n","save_fig(fig, \"18d_hydraulic_geometry_loglog\")\n","\n","print(\"\\nâœ… SECTION 18 complete.\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","#  FINAL CONSOLIDATED OUTPUT TABLE (Sections 14â€“18)\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CONSOLIDATED HYDROLOGY & SWC RESULTS TABLE\")\n","print(\"=\" * 70)\n","\n","df_consolidated = pd.concat([\n","    df_runoff[[\"CN_mean\",\"Q_10yr_mm\",\"Q_25yr_mm\",\"Q_100yr_mm\",\n","               \"Vol_25yr_Mm3\"]],\n","    df_tc[[\"Tc_Avg_min\",\"Tc_hr\",\"Qp_10yr_m3s\",\"Qp_25yr_m3s\",\"Qp_100yr_m3s\"]],\n","    df_rusle[[\"A_mean_t_ha_yr\",\"SDR\",\"Sed_Yield_t_yr\",\"Loss_Class_Mode\"]],\n","    df_whp[[\"WHP_25yr_Mm3\",\"Potential_CheckDams_N\",\"SWC_Priority\"]],\n","    df_suh[[\"tp_hr\",\"Qp_1mm_m3s\",\"W50_hr\",\"W75_hr\",\"tb_hr\"]],\n","    df_hg[[\"Q_bankfull_m3s\",\"W_bankfull_m\",\"D_bankfull_m\",\n","           \"Shear_Stress_Pa\",\"Stream_Power_spec_Wm2\",\"Channel_Stability\"]],\n","], axis=1)\n","\n","df_consolidated.to_csv(os.path.join(TABLES_DIR, \"hydrology_SWC_consolidated.csv\"))\n","\n","print(\"\\nCONSOLIDATED RESULTS:\")\n","print(df_consolidated.to_string())\n","\n","# Print to output summary\n","print(\"\\n\" + \"â”€\"*70)\n","print(\"SUMMARY OF KEY SOIL & WATER CONSERVATION METRICS\")\n","print(\"â”€\"*70)\n","for bid in df_consolidated.index:\n","    r = df_consolidated.loc[bid]\n","    print(f\"\\n  â”Œâ”€ {bid} {'â”€'*40}\")\n","    print(f\"  â”‚  CN={r['CN_mean']:.1f} | Tc={r['Tc_Avg_min']:.1f} min | \"\n","          f\"Q25yr={r['Q_25yr_mm']:.1f}mm | Qp25={r['Qp_25yr_m3s']:.2f}mÂ³/s\")\n","    print(f\"  â”‚  Soil loss={r['A_mean_t_ha_yr']:.1f} t/ha/yr ({r['Loss_Class_Mode']}) | \"\n","          f\"Sed.Yield={r['Sed_Yield_t_yr']:.0f} t/yr\")\n","    print(f\"  â”‚  WHP={r['WHP_25yr_Mm3']:.4f}MmÂ³ | ~{r['Potential_CheckDams_N']} check dams | \"\n","          f\"SWC priority: {r['SWC_Priority']}\")\n","    print(f\"  â”‚  Bankfull Q={r['Q_bankfull_m3s']:.2f}mÂ³/s | \"\n","          f\"Ï„={r['Shear_Stress_Pa']:.1f}Pa | Ï‰={r['Stream_Power_spec_Wm2']:.1f}W/mÂ² | \"\n","          f\"Stability: {r['Channel_Stability']}\")\n","    print(f\"  â””â”€ UH: tp={r['tp_hr']:.2f}hr | Qp(1mm)={r['Qp_1mm_m3s']:.4f}mÂ³/s | \"\n","          f\"W50={r['W50_hr']:.2f}hr | tb={r['tb_hr']:.2f}hr\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"ALL SECTIONS 14â€“18 COMPLETE\")\n","print(\"=\" * 70)\n","print(f\"\\n  Output files:\")\n","all_new_files = (\n","    [(HYD_DIR,  f) for f in os.listdir(HYD_DIR)] +\n","    [(SWC_DIR,  f) for f in os.listdir(SWC_DIR)] +\n","    [(UHG_DIR,  f) for f in os.listdir(UHG_DIR)] +\n","    [(HYD_MAPS, f) for f in os.listdir(HYD_MAPS) if os.path.exists(HYD_MAPS)] +\n","    [(SWC_MAPS, f) for f in os.listdir(SWC_MAPS) if os.path.exists(SWC_MAPS)]\n",")\n","for d, f in sorted(all_new_files):\n","    fpath = os.path.join(d, f)\n","    size  = os.path.getsize(fpath) / 1024 if os.path.exists(fpath) else 0\n","    print(f\"    {fpath.replace(OUT_DIR,''):<60s}  {size:>8.1f} KB\")\n","\n","print(f\"\\n  Total new maps   : 9 (14a, 14b, 15a, 15b, 16a, 16b, 18a, 18b)\")\n","print(f\"  Total new CSVs   : 9\")\n","print(f\"  Plotly HTML      : 12 interactive charts\")\n","print(f\"  Shapefile        : checkdam_suitability.shp\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFk4trTkRd2L","executionInfo":{"status":"ok","timestamp":1771998371967,"user_tz":-330,"elapsed":60050,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"2e17481e-c9f8-4f03-919a-e3fc8ba90864"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Output directories created.\n","\n","======================================================================\n","SECTION 14 â€” RUNOFF ESTIMATION (SCS-CN + RATIONAL METHOD)\n","======================================================================\n","\n","[14-A] Rainfall Frequency Analysis (Gumbel EV-I)...\n","  T=   2-yr: Annual = 719 mm | P24hr = 158.2 mm\n","  T=   5-yr: Annual = 885 mm | P24hr = 194.6 mm\n","  T=  10-yr: Annual = 994 mm | P24hr = 218.7 mm\n","  T=  25-yr: Annual = 1132 mm | P24hr = 249.1 mm\n","  T=  50-yr: Annual = 1235 mm | P24hr = 271.6 mm\n","  T= 100-yr: Annual = 1337 mm | P24hr = 294.0 mm\n","\n","[14-B] Computing Curve Number raster...\n","  CN range: 70â€“85 | Mean: 76.2\n","\n","[14-C] SCS-CN Direct Runoff calculation...\n","  SB1: CN=76.6 | S=77.7 mm | Q(25yr)=175.2 mm | Vol(25yr)=20.5011 MmÂ³\n","  SB2: CN=75.8 | S=81.0 mm | Q(25yr)=172.8 mm | Vol(25yr)=7.8090 MmÂ³\n","  SB3: CN=76.2 | S=79.4 mm | Q(25yr)=174.0 mm | Vol(25yr)=26.0952 MmÂ³\n","\n","[14-D] Time of Concentration (Tc) calculations...\n","  SB1: Tc_Kirpich=59.2 min | Tc_SCS=117.6 min | Qp(25yr)=1524.90 mÂ³/s\n","  SB2: Tc_Kirpich=34.2 min | Tc_SCS=81.9 min | Qp(25yr)=768.75 mÂ³/s\n","  SB3: Tc_Kirpich=68.3 min | Tc_SCS=140.7 min | Qp(25yr)=1736.12 mÂ³/s\n","\n","[14-E] Generating runoff maps...\n","  âœ… Saved: /content/morphometric_outputs/maps/14a_CN_map.png\n","  âœ… Saved: /content/morphometric_outputs/maps/14b_runoff_volume_25yr.png\n","  âœ… 14c_flood_frequency_curves.html\n","\n","âœ… SECTION 14 complete.\n","\n","======================================================================\n","SECTION 15 â€” RUSLE SOIL EROSION ESTIMATION\n","======================================================================\n","\n","[15-A] R-Factor (Rainfall Erosivity)...\n","  R-factor range: 594â€“807 MJÂ·mm/(haÂ·hrÂ·yr) | Mean: 650\n","\n","[15-B] K-Factor (Soil Erodibility)...\n","  K-factor range: 0.05â€“0.25 tÂ·haÂ·hr/(haÂ·MJÂ·mm) | Mean: 0.153\n","\n","[15-C] LS-Factor (Slope-Length Gradient, Moore et al. 1991)...\n","  LS-factor range: 0.00â€“50.00 | Mean: 10.87\n","\n","[15-D] C-Factor (Cover-Management)...\n","  C-factor range: 0.15â€“0.55 | Mean: 0.356\n","\n","[15-E] P-Factor (Support Practice)...\n","  P-factor range: 0.55â€“1.00 | Mean: 0.737\n","\n","[15-F] Computing Annual Soil Loss raster A = RÂ·KÂ·LSÂ·CÂ·P ...\n","  Annual soil loss range: 0.0â€“500 t/ha/yr\n","  Basin-wide mean: 166.4 t/ha/yr\n","\n","[15-G] Sediment Delivery Ratio & Annual Sediment Yield...\n","  SB1: A_mean=159.7 t/ha/yr | SDR=0.232 | Sed.Yield=432585 t/yr | Class: Severe (>60)\n","  SB2: A_mean=175.1 t/ha/yr | SDR=0.261 | Sed.Yield=206386 t/yr | Class: Severe (>60)\n","  SB3: A_mean=169.8 t/ha/yr | SDR=0.225 | Sed.Yield=571624 t/yr | Class: Severe (>60)\n","\n","[15-H] Generating RUSLE maps...\n","  âœ… Saved: /content/morphometric_outputs/maps/15a_LS_factor.png\n","  âœ… Saved: /content/morphometric_outputs/maps/15b_RUSLE_soil_loss.png\n","  âœ… 15c_RUSLE_erosion_bars.html\n","  âœ… 15d_RUSLE_radar.html\n","\n","âœ… SECTION 15 complete.\n","\n","======================================================================\n","SECTION 16 â€” WATERSHED TREATMENT PLANNING\n","(Check Dams, Percolation Tanks, Contour Trenches, Priority Zones)\n","======================================================================\n","\n","[16-A] Computing Check Dam Suitability Index...\n","  Sampling flow accumulation and slope at stream segments...\n","  CDSI distribution:\n","CDSI_class\n","Suitable               2666\n","Moderately Suitable     669\n","Poorly Suitable         223\n","Very Suitable            52\n","\n","[16-B] Percolation Pond & Groundwater Recharge Zones...\n","  Percolation potential range: 0.000â€“1.000\n","\n","[16-C] Contour Trench Suitability...\n","  Contour trench suitability range: 0.000â€“1.000\n","\n","[16-D] Per-basin conservation statistics & Water Harvesting Potential...\n","  SB1: WHP=8.2002 MmÂ³ | CT_suit%=37.2% | Est. check dams=1078\n","  SB2: WHP=3.1237 MmÂ³ | CT_suit%=46.3% | Est. check dams=1078\n","  SB3: WHP=10.4379 MmÂ³ | CT_suit%=53.6% | Est. check dams=1078\n","\n","[16-E] Generating conservation maps...\n","  âœ… Saved: /content/morphometric_outputs/maps/16a_checkdam_suitability.png\n","  âœ… Saved: /content/morphometric_outputs/maps/16b_SWC_treatment_zones.png\n","  âœ… 16c_SWC_potential_bars.html\n","\n","âœ… SECTION 16 complete.\n","\n","======================================================================\n","SECTION 17 â€” SYNTHETIC UNIT HYDROGRAPH (Snyder's & SCS Methods)\n","======================================================================\n","\n","[17-A] Snyder's Synthetic Unit Hydrograph parameters...\n","  SB1: tL=6.22hr | tp=6.78hr | Qp(1mm)=31.056 mÂ³/s | W50=8.96hr | W75=5.11hr\n","  SB2: tL=4.67hr | tp=5.10hr | Qp(1mm)=15.959 mÂ³/s | W50=6.59hr | W75=3.75hr\n","  SB3: tL=6.70hr | tp=7.30hr | Qp(1mm)=36.954 mÂ³/s | W50=9.71hr | W75=5.54hr\n","\n","[17-B] SCS Dimensionless Unit Hydrograph...\n","\n","[17-C] Generating unit hydrograph plots...\n","  âœ… Hydrograph plot saved\n","  âœ… 17b_synthetic_unit_hydrographs.html\n","  âœ… 17c_UH_parameter_table.html\n","\n","âœ… SECTION 17 complete.\n","\n","======================================================================\n","SECTION 18 â€” STREAM CHANNEL HYDRAULICS & STABILITY\n","(Bankfull Discharge, Shear Stress, Stream Power, Stability Index)\n","======================================================================\n","\n","[18-A] Bankfull Discharge & Hydraulic Geometry...\n","  SB1: Q_bf=692.48 mÂ³/s | W=84.2m | D=3.83m | Ï„=2578.9Pa | Ï‰=7549.2 W/mÂ² | Highly Unstable\n","  SB2: Q_bf=345.87 mÂ³/s | W=59.5m | D=2.90m | Ï„=3124.5Pa | Ï‰=8584.0 W/mÂ² | Highly Unstable\n","  SB3: Q_bf=784.95 mÂ³/s | W=89.7m | D=4.03m | Ï„=2397.3Pa | Ï‰=7098.8 W/mÂ² | Highly Unstable\n","\n","[18-B] Stream power analysis per Strahler order...\n","  Order 1: N=1828 | L_tot=510.6 km | S_mean=9.83Â° | Ï‰â‰ˆ11.83 W/mÂ²\n","  Order 2: N= 809 | L_tot=218.4 km | S_mean=7.13Â° | Ï‰â‰ˆ48.35 W/mÂ²\n","  Order 3: N= 462 | L_tot=118.0 km | S_mean=4.31Â° | Ï‰â‰ˆ53.86 W/mÂ²\n","  Order 4: N= 286 | L_tot=65.2 km | S_mean=2.89Â° | Ï‰â‰ˆ51.63 W/mÂ²\n","  Order 5: N= 120 | L_tot=28.2 km | S_mean=3.36Â° | Ï‰â‰ˆ79.44 W/mÂ²\n","  Order 6: N= 105 | L_tot=28.5 km | S_mean=6.36Â° | Ï‰â‰ˆ189.30 W/mÂ²\n","\n","[18-C] Generating hydraulics maps and charts...\n","  âœ… Saved: /content/morphometric_outputs/maps/18a_bankfull_hydraulics.png\n","  âœ… Saved: /content/morphometric_outputs/maps/18b_channel_stability.png\n","  âœ… 18c_stream_power_hydraulics.html\n","  âœ… 18d_hydraulic_geometry_loglog.html\n","\n","âœ… SECTION 18 complete.\n","\n","======================================================================\n","CONSOLIDATED HYDROLOGY & SWC RESULTS TABLE\n","======================================================================\n","\n","CONSOLIDATED RESULTS:\n","          CN_mean  Q_10yr_mm  Q_25yr_mm  Q_100yr_mm  Vol_25yr_Mm3  Tc_Avg_min  Tc_hr  Qp_10yr_m3s  Qp_25yr_m3s  Qp_100yr_m3s  A_mean_t_ha_yr    SDR  Sed_Yield_t_yr Loss_Class_Mode  WHP_25yr_Mm3  Potential_CheckDams_N SWC_Priority  tp_hr  Qp_1mm_m3s  W50_hr  W75_hr   tb_hr  Q_bankfull_m3s  W_bankfull_m  D_bankfull_m  Shear_Stress_Pa  Stream_Power_spec_Wm2 Channel_Stability\n","basin_id                                                                                                                                                                                                                                                                                                                                                                              \n","SB1       76.5700   146.9400   175.2400    217.7000       20.5011     88.4000 1.4730    1278.6400    1524.8970     1894.3200        159.6600 0.2320     432585.0000    Severe (>60)        8.2002                   1078         High 6.7800     31.0564  8.9630  5.1100 33.9020        692.4810       84.2100        3.8300        2578.9210              7549.2170   Highly Unstable\n","SB2       75.8200   144.6400   172.8000    215.0800        7.8090     58.1000 0.9680     643.4800     768.7530      956.8680        175.0900 0.2610     206386.0000    Severe (>60)        3.1237                   1078         High 5.0970     15.9589  6.5860  3.7550 25.4860        345.8700       59.5100        2.9000        3124.5070              8584.0450   Highly Unstable\n","SB3       76.1900   145.7700   174.0000    216.3700       26.0952    104.5000 1.7410    1454.4650    1736.1170     2158.8490        169.7700 0.2250     571624.0000    Severe (>60)       10.4379                   1078         High 7.3050     36.9539  9.7150  5.5380 36.5250        784.9540       89.6500        4.0300        2397.3410              7098.8140   Highly Unstable\n","\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","SUMMARY OF KEY SOIL & WATER CONSERVATION METRICS\n","â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","  â”Œâ”€ SB1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","  â”‚  CN=76.6 | Tc=88.4 min | Q25yr=175.2mm | Qp25=1524.90mÂ³/s\n","  â”‚  Soil loss=159.7 t/ha/yr (Severe (>60)) | Sed.Yield=432585 t/yr\n","  â”‚  WHP=8.2002MmÂ³ | ~1078 check dams | SWC priority: High\n","  â”‚  Bankfull Q=692.48mÂ³/s | Ï„=2578.9Pa | Ï‰=7549.2W/mÂ² | Stability: Highly Unstable\n","  â””â”€ UH: tp=6.78hr | Qp(1mm)=31.0564mÂ³/s | W50=8.96hr | tb=33.90hr\n","\n","  â”Œâ”€ SB2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","  â”‚  CN=75.8 | Tc=58.1 min | Q25yr=172.8mm | Qp25=768.75mÂ³/s\n","  â”‚  Soil loss=175.1 t/ha/yr (Severe (>60)) | Sed.Yield=206386 t/yr\n","  â”‚  WHP=3.1237MmÂ³ | ~1078 check dams | SWC priority: High\n","  â”‚  Bankfull Q=345.87mÂ³/s | Ï„=3124.5Pa | Ï‰=8584.0W/mÂ² | Stability: Highly Unstable\n","  â””â”€ UH: tp=5.10hr | Qp(1mm)=15.9589mÂ³/s | W50=6.59hr | tb=25.49hr\n","\n","  â”Œâ”€ SB3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","  â”‚  CN=76.2 | Tc=104.5 min | Q25yr=174.0mm | Qp25=1736.12mÂ³/s\n","  â”‚  Soil loss=169.8 t/ha/yr (Severe (>60)) | Sed.Yield=571624 t/yr\n","  â”‚  WHP=10.4379MmÂ³ | ~1078 check dams | SWC priority: High\n","  â”‚  Bankfull Q=784.95mÂ³/s | Ï„=2397.3Pa | Ï‰=7098.8W/mÂ² | Stability: Highly Unstable\n","  â””â”€ UH: tp=7.30hr | Qp(1mm)=36.9539mÂ³/s | W50=9.71hr | tb=36.52hr\n","\n","======================================================================\n","ALL SECTIONS 14â€“18 COMPLETE\n","======================================================================\n","\n","  Output files:\n","    conservation/checkdam_suitability.csv                            215.5 KB\n","    conservation/conservation_potential.csv                            0.3 KB\n","    hydrology/RUSLE_soil_erosion.csv                                   0.5 KB\n","    hydrology/channel_hydraulics.csv                                   0.7 KB\n","    hydrology/rainfall_frequency.csv                                   0.1 KB\n","    hydrology/runoff_scscn.csv                                         0.8 KB\n","    hydrology/stream_order_power.csv                                   0.4 KB\n","    hydrology/time_of_concentration_peak_discharge.csv                 0.6 KB\n","    unit_hydrograph/17_unit_hydrographs.png                          439.1 KB\n","    unit_hydrograph/snyder_unit_hydrograph_params.csv                  0.5 KB\n","\n","  Total new maps   : 9 (14a, 14b, 15a, 15b, 16a, 16b, 18a, 18b)\n","  Total new CSVs   : 9\n","  Plotly HTML      : 12 interactive charts\n","  Shapefile        : checkdam_suitability.shp\n"]}]},{"cell_type":"markdown","source":["=============================================================================\n","EXPORT â€” Download all morphometric outputs from Colab\n","=============================================================================\n","Run this as the LAST cell in Colab.\n","It zips everything and triggers a browser download.\n","============================================================================="],"metadata":{"id":"RtO0Ai_OPrTz"}},{"cell_type":"code","source":["import os, zipfile, shutil\n","from google.colab import files\n","from datetime import datetime\n","\n","OUT_DIR     = \"/content/morphometric_outputs/\"\n","EXPORT_NAME = f\"morphometric_outputs_{datetime.now().strftime('%Y%m%d_%H%M')}.zip\"\n","EXPORT_PATH = f\"/content/{EXPORT_NAME}\"\n","\n","print(\"ğŸ“¦ Zipping all outputs...\")\n","with zipfile.ZipFile(EXPORT_PATH, 'w', zipfile.ZIP_DEFLATED) as zf:\n","    for root, dirs, fnames in os.walk(OUT_DIR):\n","        for fname in fnames:\n","            full_path = os.path.join(root, fname)\n","            arc_name  = os.path.relpath(full_path, \"/content/\")\n","            zf.write(full_path, arc_name)\n","\n","size_mb = os.path.getsize(EXPORT_PATH) / 1e6\n","print(f\"âœ… Zipped: {EXPORT_NAME}  ({size_mb:.1f} MB)\")\n","\n","# Print contents summary\n","print(\"\\nğŸ“‚ Contents:\")\n","with zipfile.ZipFile(EXPORT_PATH, 'r') as zf:\n","    for name in sorted(zf.namelist()):\n","        info = zf.getinfo(name)\n","        print(f\"  {name:<70s}  {info.file_size/1024:>8.1f} KB\")\n","\n","print(\"\\nâ¬‡ï¸  Starting download...\")\n","files.download(EXPORT_PATH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"idSGLyDhPn92","executionInfo":{"status":"ok","timestamp":1771998400775,"user_tz":-330,"elapsed":4262,"user":{"displayName":"satwik udupi","userId":"14067778218391256491"}},"outputId":"76d7cc9c-baa4-41fe-9950-8d1b68f96cd4"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“¦ Zipping all outputs...\n","âœ… Zipped: morphometric_outputs_20260225_0546.zip  (67.5 MB)\n","\n","ğŸ“‚ Contents:\n","  morphometric_outputs/CN.tif                                               2505.0 KB\n","  morphometric_outputs/FFPI.tif                                             2505.0 KB\n","  morphometric_outputs/GAI.tif                                              2505.0 KB\n","  morphometric_outputs/GAI_high_anomaly.tif                                 2505.0 KB\n","  morphometric_outputs/RUSLE_A.tif                                          2505.0 KB\n","  morphometric_outputs/RUSLE_C.tif                                          2505.0 KB\n","  morphometric_outputs/RUSLE_K.tif                                          2505.0 KB\n","  morphometric_outputs/RUSLE_LS.tif                                         2505.0 KB\n","  morphometric_outputs/RUSLE_P.tif                                          2505.0 KB\n","  morphometric_outputs/RUSLE_R.tif                                          2505.0 KB\n","  morphometric_outputs/aspect.tif                                           2505.0 KB\n","  morphometric_outputs/conservation/checkdam_suitability.csv                 215.5 KB\n","  morphometric_outputs/conservation/conservation_potential.csv                 0.3 KB\n","  morphometric_outputs/contour_trench_suitability.tif                       2505.0 KB\n","  morphometric_outputs/hydrology/RUSLE_soil_erosion.csv                        0.5 KB\n","  morphometric_outputs/hydrology/channel_hydraulics.csv                        0.7 KB\n","  morphometric_outputs/hydrology/rainfall_frequency.csv                        0.1 KB\n","  morphometric_outputs/hydrology/runoff_scscn.csv                              0.8 KB\n","  morphometric_outputs/hydrology/stream_order_power.csv                        0.4 KB\n","  morphometric_outputs/hydrology/time_of_concentration_peak_discharge.csv       0.6 KB\n","  morphometric_outputs/lineament_proxy.tif                                  2505.0 KB\n","  morphometric_outputs/maps/01_elevation.png                                1864.3 KB\n","  morphometric_outputs/maps/02_slope.png                                    2377.9 KB\n","  morphometric_outputs/maps/03_aspect.png                                   2634.9 KB\n","  morphometric_outputs/maps/04_flow_direction.png                           3113.3 KB\n","  morphometric_outputs/maps/05_flow_accumulation.png                        3048.2 KB\n","  morphometric_outputs/maps/06_stream_order.png                             1617.6 KB\n","  morphometric_outputs/maps/07_drainage_density.png                         1233.8 KB\n","  morphometric_outputs/maps/08_contour.png                                  2337.3 KB\n","  morphometric_outputs/maps/09_pour_points.png                              1856.9 KB\n","  morphometric_outputs/maps/10a_tectonic_IAT_map.png                        1602.7 KB\n","  morphometric_outputs/maps/12a_GAI_map.png                                 2780.6 KB\n","  morphometric_outputs/maps/12b_lineament_proxy_map.png                     1857.8 KB\n","  morphometric_outputs/maps/12c_sinuosity_map.png                           1447.4 KB\n","  morphometric_outputs/maps/13a_TWI_map.png                                 3040.9 KB\n","  morphometric_outputs/maps/13b_SPI_map.png                                 1485.7 KB\n","  morphometric_outputs/maps/13c_STI_map.png                                 1430.8 KB\n","  morphometric_outputs/maps/13d_FFPI_map.png                                2604.4 KB\n","  morphometric_outputs/maps/13e_flood_hazard_composite_map.png              1466.1 KB\n","  morphometric_outputs/maps/14a_CN_map.png                                  2287.5 KB\n","  morphometric_outputs/maps/14b_runoff_volume_25yr.png                      1142.2 KB\n","  morphometric_outputs/maps/15a_LS_factor.png                               2543.8 KB\n","  morphometric_outputs/maps/15b_RUSLE_soil_loss.png                         2692.1 KB\n","  morphometric_outputs/maps/16a_checkdam_suitability.png                    1658.1 KB\n","  morphometric_outputs/maps/16b_SWC_treatment_zones.png                     3372.7 KB\n","  morphometric_outputs/maps/18a_bankfull_hydraulics.png                     1341.5 KB\n","  morphometric_outputs/maps/18b_channel_stability.png                       1499.0 KB\n","  morphometric_outputs/percolation_potential.tif                            2505.0 KB\n","  morphometric_outputs/plots/correlation_heatmap.png                         364.0 KB\n","  morphometric_outputs/plots/hierarchical_dendrogram.png                      35.7 KB\n","  morphometric_outputs/plots/html/01_hortons_law_SB1.html                     12.8 KB\n","  morphometric_outputs/plots/html/01_hortons_law_SB2.html                     12.8 KB\n","  morphometric_outputs/plots/html/01_hortons_law_SB3.html                     12.8 KB\n","  morphometric_outputs/plots/html/02_radar_morphometric.html                   8.8 KB\n","  morphometric_outputs/plots/html/03_scatter_matrix.html                       9.8 KB\n","  morphometric_outputs/plots/html/04_3d_scatter.html                           9.1 KB\n","  morphometric_outputs/plots/html/05_histograms.html                          11.7 KB\n","  morphometric_outputs/plots/html/06_boxplots.html                            12.7 KB\n","  morphometric_outputs/plots/html/07_hypsometric_curves.html                  17.4 KB\n","  morphometric_outputs/plots/html/08_correlation_heatmap.html                 18.0 KB\n","  morphometric_outputs/plots/html/09_parallel_coordinates.html                 8.7 KB\n","  morphometric_outputs/plots/html/10_bubble_area_dd_relief.html                9.4 KB\n","  morphometric_outputs/plots/html/10b_tectonic_radar.html                      8.6 KB\n","  morphometric_outputs/plots/html/11_priority_map.html                       145.5 KB\n","  morphometric_outputs/plots/html/12_longitudinal_profiles.html               24.1 KB\n","  morphometric_outputs/plots/html/12d_geomorphic_anomaly_plotly.html           9.8 KB\n","  morphometric_outputs/plots/html/13f_flood_indices_bar.html                   9.8 KB\n","  morphometric_outputs/plots/html/13g_flood_bubble_plot.html                   9.7 KB\n","  morphometric_outputs/plots/html/13h_flood_susceptibility_ranking.html        8.2 KB\n","  morphometric_outputs/plots/html/14c_flood_frequency_curves.html             10.4 KB\n","  morphometric_outputs/plots/html/15c_RUSLE_erosion_bars.html                 11.0 KB\n","  morphometric_outputs/plots/html/15d_RUSLE_radar.html                         8.5 KB\n","  morphometric_outputs/plots/html/16c_SWC_potential_bars.html                  9.7 KB\n","  morphometric_outputs/plots/html/17b_synthetic_unit_hydrographs.html         40.9 KB\n","  morphometric_outputs/plots/html/17c_UH_parameter_table.html                  8.3 KB\n","  morphometric_outputs/plots/html/18c_stream_power_hydraulics.html            10.5 KB\n","  morphometric_outputs/plots/html/18d_hydraulic_geometry_loglog.html          17.3 KB\n","  morphometric_outputs/plots/kmeans_clusters.png                              55.0 KB\n","  morphometric_outputs/plots/pca_scree_biplot.png                            135.9 KB\n","  morphometric_outputs/plots/prioritization_comparison.png                    72.7 KB\n","  morphometric_outputs/report/advanced_analysis_interpretation.txt             4.8 KB\n","  morphometric_outputs/report/morphometric_analysis_report.txt                 6.7 KB\n","  morphometric_outputs/shapefiles/checkdam_suitability.cpg                     0.0 KB\n","  morphometric_outputs/shapefiles/checkdam_suitability.dbf                  1661.1 KB\n","  morphometric_outputs/shapefiles/checkdam_suitability.prj                     0.4 KB\n","  morphometric_outputs/shapefiles/checkdam_suitability.shp                   373.3 KB\n","  morphometric_outputs/shapefiles/checkdam_suitability.shx                    28.3 KB\n","  morphometric_outputs/shapefiles/lineament_proxy.cpg                          0.0 KB\n","  morphometric_outputs/shapefiles/lineament_proxy.dbf                          0.8 KB\n","  morphometric_outputs/shapefiles/lineament_proxy.prj                          0.4 KB\n","  morphometric_outputs/shapefiles/lineament_proxy.shp                          3.7 KB\n","  morphometric_outputs/shapefiles/lineament_proxy.shx                          0.4 KB\n","  morphometric_outputs/shapefiles/pour_points_snapped.cpg                      0.0 KB\n","  morphometric_outputs/shapefiles/pour_points_snapped.dbf                      0.2 KB\n","  morphometric_outputs/shapefiles/pour_points_snapped.prj                      0.4 KB\n","  morphometric_outputs/shapefiles/pour_points_snapped.shp                      0.2 KB\n","  morphometric_outputs/shapefiles/pour_points_snapped.shx                      0.1 KB\n","  morphometric_outputs/shapefiles/streams_sl_anomaly.cpg                       0.0 KB\n","  morphometric_outputs/shapefiles/streams_sl_anomaly.dbf                    1026.5 KB\n","  morphometric_outputs/shapefiles/streams_sl_anomaly.prj                       0.4 KB\n","  morphometric_outputs/shapefiles/streams_sl_anomaly.shp                     373.4 KB\n","  morphometric_outputs/shapefiles/streams_sl_anomaly.shx                      28.3 KB\n","  morphometric_outputs/shapefiles/subbasins_priority.cpg                       0.0 KB\n","  morphometric_outputs/shapefiles/subbasins_priority.dbf                       3.3 KB\n","  morphometric_outputs/shapefiles/subbasins_priority.prj                       0.4 KB\n","  morphometric_outputs/shapefiles/subbasins_priority.shp                      59.6 KB\n","  morphometric_outputs/shapefiles/subbasins_priority.shx                       0.1 KB\n","  morphometric_outputs/slope.tif                                            2505.0 KB\n","  morphometric_outputs/spi.tif                                              2505.0 KB\n","  morphometric_outputs/sti.tif                                              2505.0 KB\n","  morphometric_outputs/tables/GAI_per_basin.csv                                0.1 KB\n","  morphometric_outputs/tables/correlation_pearson.csv                          6.1 KB\n","  morphometric_outputs/tables/correlation_spearman.csv                         2.0 KB\n","  morphometric_outputs/tables/descriptive_statistics.csv                       3.8 KB\n","  morphometric_outputs/tables/flood_hazard_indices.csv                         0.5 KB\n","  morphometric_outputs/tables/hydrology_SWC_consolidated.csv                   1.0 KB\n","  morphometric_outputs/tables/kendall_tau.csv                                  0.2 KB\n","  morphometric_outputs/tables/morphometric_master_table.csv                    1.7 KB\n","  morphometric_outputs/tables/pca_loadings.csv                                 1.4 KB\n","  morphometric_outputs/tables/pca_scores.csv                                   0.2 KB\n","  morphometric_outputs/tables/prioritization_ranking.csv                       0.3 KB\n","  morphometric_outputs/tables/sinuosity_per_basin.csv                          0.1 KB\n","  morphometric_outputs/tables/sl_anomaly_per_basin.csv                         0.1 KB\n","  morphometric_outputs/tables/spi_per_basin.csv                                0.1 KB\n","  morphometric_outputs/tables/sti_per_basin.csv                                0.1 KB\n","  morphometric_outputs/tables/stream_order_summary.csv                         1.3 KB\n","  morphometric_outputs/tables/tectonic_activity_indices.csv                    0.5 KB\n","  morphometric_outputs/tables/twi_per_basin.csv                                0.1 KB\n","  morphometric_outputs/tri.tif                                              2505.0 KB\n","  morphometric_outputs/twi.tif                                              2505.0 KB\n","  morphometric_outputs/unit_hydrograph/17_unit_hydrographs.png               439.1 KB\n","  morphometric_outputs/unit_hydrograph/snyder_unit_hydrograph_params.csv       0.5 KB\n","\n","â¬‡ï¸  Starting download...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_b7f9726f-6fa9-4bcd-b977-342165a57925\", \"morphometric_outputs_20260225_0546.zip\", 67547610)"]},"metadata":{}}]}]}